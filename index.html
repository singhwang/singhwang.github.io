<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  
  <title>Singh Wang</title>

  <!-- keywords -->
  

  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Singh Wang">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Singh Wang">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Singh Wang">
  
    <link rel="alternative" href="/atom.xml" title="Singh Wang" type="application/atom+xml">
  
  
    <link rel="icon" href="http://7xkj1z.com1.z0.glb.clouddn.com/head.jpg">
  
  <link rel="stylesheet" href="/css/style.css">
  
  

  <script src="//cdn.bootcss.com/require.js/2.3.2/require.min.js"></script>
  <script src="//cdn.bootcss.com/jquery/3.1.1/jquery.min.js"></script>

  
</head></html>
<body>
  <div id="container">
    <div id="particles-js"></div>
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			
			<img lazy-src="https://avatars0.githubusercontent.com/u/17465385?s=400&amp;u=cea56ed1710ec6ebab160c1ce1e068317e05b025&amp;v=4" class="js-avatar">
			
		</a>

		<hgroup>
		  <h1 class="header-author"><a href="/">Singh Wang</a></h1>
		</hgroup>

		

		
			<div class="switch-btn">
				<div class="icon">
					<div class="icon-ctn">
						<div class="icon-wrap icon-house" data-idx="0">
							<div class="birdhouse"></div>
							<div class="birdhouse_holes"></div>
						</div>
						<div class="icon-wrap icon-ribbon hide" data-idx="1">
							<div class="ribbon"></div>
						</div>
						
						
					</div>
					
				</div>
				<div class="tips-box hide">
					<div class="tips-arrow"></div>
					<ul class="tips-inner">
						<li>菜单</li>
						<li>标签</li>
						
						
					</ul>
				</div>
			</div>
		

		<div class="switch-area">
			<div class="switch-wrap">
				<section class="switch-part switch-part1">
					<nav class="header-menu">
						<ul>
						
							<li><a href="/archives">所有文章</a></li>
				        
							<li><a href="/categories/容器云技术/">容器云技术</a></li>
				        
						</ul>
					</nav>
					<nav class="header-nav">
						<div class="social">
							
								<a class="github" target="_blank" href="https://github.com/singhwang" title="github">github</a>
					        
						</div>
					</nav>
				</section>
				
				
				<section class="switch-part switch-part2">
					<div class="widget tagcloud" id="js-tagcloud">
						<a href="/tags/Calico/" style="font-size: 11.11px;">Calico</a> <a href="/tags/Ceph/" style="font-size: 12.22px;">Ceph</a> <a href="/tags/Common/" style="font-size: 10px;">Common</a> <a href="/tags/DNS/" style="font-size: 10px;">DNS</a> <a href="/tags/Dashboard/" style="font-size: 11.11px;">Dashboard</a> <a href="/tags/Docker/" style="font-size: 20px;">Docker</a> <a href="/tags/Dragonfly/" style="font-size: 10px;">Dragonfly</a> <a href="/tags/Elasticsearch/" style="font-size: 10px;">Elasticsearch</a> <a href="/tags/Fluentd/" style="font-size: 11.11px;">Fluentd</a> <a href="/tags/GlusterFS/" style="font-size: 13.33px;">GlusterFS</a> <a href="/tags/HAProxy/" style="font-size: 11.11px;">HAProxy</a> <a href="/tags/Harbor/" style="font-size: 10px;">Harbor</a> <a href="/tags/Highly-Available/" style="font-size: 12.22px;">Highly Available</a> <a href="/tags/Ingress/" style="font-size: 10px;">Ingress</a> <a href="/tags/Kubeadm/" style="font-size: 12.22px;">Kubeadm</a> <a href="/tags/Kubernetes/" style="font-size: 18.89px;">Kubernetes</a> <a href="/tags/Label/" style="font-size: 10px;">Label</a> <a href="/tags/Logging/" style="font-size: 12.22px;">Logging</a> <a href="/tags/Monitoring/" style="font-size: 13.33px;">Monitoring</a> <a href="/tags/Network/" style="font-size: 14.44px;">Network</a> <a href="/tags/Nginx/" style="font-size: 10px;">Nginx</a> <a href="/tags/Open-Falcon/" style="font-size: 10px;">Open Falcon</a> <a href="/tags/P2P/" style="font-size: 10px;">P2P</a> <a href="/tags/Prometheus/" style="font-size: 11.11px;">Prometheus</a> <a href="/tags/Setup/" style="font-size: 17.78px;">Setup</a> <a href="/tags/Smartping/" style="font-size: 10px;">Smartping</a> <a href="/tags/Source-Build/" style="font-size: 10px;">Source Build</a> <a href="/tags/Storage/" style="font-size: 15.56px;">Storage</a> <a href="/tags/TimeZone/" style="font-size: 10px;">TimeZone</a> <a href="/tags/Trouble-Shooting/" style="font-size: 16.67px;">Trouble Shooting</a>
					</div>
				</section>
				
				
				

				
			</div>
		</div>
	</header>				
</div>
    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
  	<div class="overlay">
  		<div class="slider-trigger"></div>
  		<h1 class="header-author js-mobile-header hide">Singh Wang</h1>
  	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
				<img lazy-src="https://avatars0.githubusercontent.com/u/17465385?s=400&amp;u=cea56ed1710ec6ebab160c1ce1e068317e05b025&amp;v=4" class="js-avatar">
			</div>
			<hgroup>
			  <h1 class="header-author">Singh Wang</h1>
			</hgroup>
			
			<nav class="header-menu">
				<ul>
				
					<li><a href="/archives">所有文章</a></li>
		        
					<li><a href="/categories/容器云技术/">容器云技术</a></li>
		        
		        <div class="clearfix"></div>
				</ul>
			</nav>
			<nav class="header-nav">
				<div class="social">
					
						<a class="github" target="_blank" href="https://github.com/singhwang" title="github">github</a>
			        
				</div>
			</nav>
		</header>				
	</div>
</nav>
      <div class="body-wrap">
  
    <article id="post-nginx_examples" class="article article-type-post" itemscope="" itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2020/06/16/nginx_examples/" class="article-date">
  	<time datetime="2020-06-16T07:02:53.125Z" itemprop="datePublished">2020-06-16</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/06/16/nginx_examples/">
        CentOS 7 Nginx 使用示例
        
      </a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="1-使用yum安装Nginx"><a href="#1-使用yum安装Nginx" class="headerlink" title="1. 使用yum安装Nginx"></a>1. 使用yum安装Nginx</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">yum install -y epel-release</span><br><span class="line">yum makecache fast</span><br><span class="line">yum install -y nginx</span><br></pre></td></tr></table></figure>
<h2 id="2-配置Nginx，这里仅提供一个七层HTTP代理的示例，实际中请根据需要修改"><a href="#2-配置Nginx，这里仅提供一个七层HTTP代理的示例，实际中请根据需要修改" class="headerlink" title="2. 配置Nginx，这里仅提供一个七层HTTP代理的示例，实际中请根据需要修改"></a>2. 配置Nginx，这里仅提供一个七层HTTP代理的示例，实际中请根据需要修改</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"># （1）HTTP代理</span><br><span class="line"># 新建配置文件 /etc/nginx/conf.d/remote_xxx.conf</span><br><span class="line"></span><br><span class="line">upstream remote-xxx &#123;</span><br><span class="line">    server x.x.x.x:43747;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">server &#123;</span><br><span class="line">    listen 43747;</span><br><span class="line">    server_name 111.206.120.158;</span><br><span class="line">    access_log  /var/log/nginx/remote-xxx-access.log  main;</span><br><span class="line">    error_log /var/log/nginx/remote-xxx-error.log;</span><br><span class="line">    add_header Cache-Control no-cache;</span><br><span class="line"></span><br><span class="line">    location / &#123;</span><br><span class="line">        proxy_pass http://remote-xxx/;</span><br><span class="line">        proxy_http_version 1.1;</span><br><span class="line">        proxy_connect_timeout 30m;</span><br><span class="line">        proxy_send_timeout 30m;</span><br><span class="line">        proxy_read_timeout 30m;</span><br><span class="line">        proxy_set_header Upgrade $http_upgrade;</span><br><span class="line">        proxy_set_header Connection $http_connection;</span><br><span class="line">        proxy_buffering off;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"># （2）HTTPS代理</span><br><span class="line"># 在 /etc/nginx/nginx.conf 中配置SSL证书</span><br><span class="line">。。。。。。</span><br><span class="line">http &#123;</span><br><span class="line">    log_format  main  &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos;</span><br><span class="line">                      &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos;</span><br><span class="line">                      &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;;</span><br><span class="line"></span><br><span class="line">    access_log  /var/log/nginx/access.log  main;</span><br><span class="line"></span><br><span class="line">    sendfile            on;</span><br><span class="line">    tcp_nopush          on;</span><br><span class="line">    tcp_nodelay         on;</span><br><span class="line">    keepalive_timeout   65;</span><br><span class="line">    types_hash_max_size 2048;</span><br><span class="line">    ssl_certificate /data/demo/ssl/3838460__xesv5.com.pem;  # 指定证书的位置，绝对路径</span><br><span class="line">    ssl_certificate_key /data/demo/ssl/3838460__xesv5.com.key;  # 绝对路径，同上</span><br><span class="line">    ssl_session_timeout 5m;</span><br><span class="line">    ssl_protocols TLSv1 TLSv1.1 TLSv1.2; #按照这个协议配置</span><br><span class="line">    ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE;#按照这个套件配置</span><br><span class="line">    ssl_prefer_server_ciphers on;</span><br><span class="line"></span><br><span class="line">    include             /etc/nginx/mime.types;</span><br><span class="line">    default_type        application/octet-stream;</span><br><span class="line"></span><br><span class="line">    # Load modular configuration files from the /etc/nginx/conf.d directory.</span><br><span class="line">    # See http://nginx.org/en/docs/ngx_core_module.html#include</span><br><span class="line">    # for more information.</span><br><span class="line">    include /etc/nginx/conf.d/*.conf;</span><br><span class="line">。。。。。。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 新建配置文件 /etc/nginx/conf.d/xxx_xx_ssl.conf</span><br><span class="line">upstream xxx-xx &#123;</span><br><span class="line">    server x.x.x.x:6088;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">server &#123;</span><br><span class="line">    listen 0.0.0.0:9606 ssl;</span><br><span class="line">    server_name xxx-xx;</span><br><span class="line">    access_log  /var/log/nginx/xxx-xx-access.log  main;</span><br><span class="line">    error_log /var/log/nginx/xxx-xx-error.log;</span><br><span class="line"></span><br><span class="line">    location / &#123;</span><br><span class="line">        proxy_pass http://xxx-xx/;</span><br><span class="line">        proxy_http_version 1.1;</span><br><span class="line">        proxy_connect_timeout 30m;</span><br><span class="line">        proxy_send_timeout 30m;</span><br><span class="line">        proxy_read_timeout 30m;</span><br><span class="line">        proxy_set_header Upgrade $http_upgrade;</span><br><span class="line">        proxy_set_header Connection $http_connection;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="4-启动Nginx"><a href="#4-启动Nginx" class="headerlink" title="4. 启动Nginx"></a>4. 启动Nginx</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl start nginx.service</span><br><span class="line">systemctl status nginx.service</span><br></pre></td></tr></table></figure>
      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Docker/">Docker</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Nginx/">Nginx</a></li></ul>
	</div>

      
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/容器云技术/">容器云技术</a>
	</div>


      
      <div class="clearfix"></div>
    </div>
      
    
  </div>
  
</article>







  
    <article id="post-haproxy_examples" class="article article-type-post" itemscope="" itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2020/06/16/haproxy_examples/" class="article-date">
  	<time datetime="2020-06-16T06:38:57.441Z" itemprop="datePublished">2020-06-16</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/06/16/haproxy_examples/">
        CentOS 7 HAProxy 使用示例
        
      </a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="1-使用yum安装HAProxy"><a href="#1-使用yum安装HAProxy" class="headerlink" title="1. 使用yum安装HAProxy"></a>1. 使用yum安装HAProxy</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">yum makecache fast</span><br><span class="line">yum install -y haproxy</span><br></pre></td></tr></table></figure>
<h2 id="2-借助rsyslog配置HAProxy输出日志到文件"><a href="#2-借助rsyslog配置HAProxy输出日志到文件" class="headerlink" title="2. 借助rsyslog配置HAProxy输出日志到文件"></a>2. 借助rsyslog配置HAProxy输出日志到文件</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 编辑/etc/rsyslog.conf</span><br><span class="line"># 启用在udp 514端口接收日志消息</span><br><span class="line">$ModLoad imudp</span><br><span class="line">$UDPServerRun 514</span><br><span class="line"></span><br><span class="line"># 以下内容追加到配置文件最后</span><br><span class="line"></span><br><span class="line"># Save haproxy log to haproxy.log</span><br><span class="line">local0.*                                                /var/log/haproxy.log</span><br></pre></td></tr></table></figure>
<h2 id="3-配置HAProxy，这里仅提供一个四层TCP代理的示例，实际中请根据需要修改"><a href="#3-配置HAProxy，这里仅提供一个四层TCP代理的示例，实际中请根据需要修改" class="headerlink" title="3. 配置HAProxy，这里仅提供一个四层TCP代理的示例，实际中请根据需要修改"></a>3. 配置HAProxy，这里仅提供一个四层TCP代理的示例，实际中请根据需要修改</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"># 备份/etc/haproxy/haproxy.cfg</span><br><span class="line">cp /etc/haproxy/haproxy.cfg /etc/haproxy/haproxy.cfg.bak</span><br><span class="line"></span><br><span class="line"># 编辑/etc/haproxy/haproxy.cfg</span><br><span class="line">global</span><br><span class="line">  log 127.0.0.1 local0 debug</span><br><span class="line">  maxconn 50000</span><br><span class="line">  uid 99</span><br><span class="line">  gid 99</span><br><span class="line">  #daemon</span><br><span class="line">  nbproc 1</span><br><span class="line">  pidfile haproxy.pid</span><br><span class="line"></span><br><span class="line">defaults</span><br><span class="line">  mode tcp</span><br><span class="line">  log global</span><br><span class="line">  maxconn 50000</span><br><span class="line">  retries 3</span><br><span class="line">  timeout connect 10s</span><br><span class="line">  timeout client 60m</span><br><span class="line">  timeout server 60m</span><br><span class="line"></span><br><span class="line">listen stats</span><br><span class="line">  mode http</span><br><span class="line">  bind 0.0.0.0:9090</span><br><span class="line">  log  global</span><br><span class="line">  stats refresh 30s</span><br><span class="line">  stats uri     /haproxy-status</span><br><span class="line">  stats realm   Haproxy\ Statistics</span><br><span class="line">  stats auth    admin:12345678</span><br><span class="line">  stats hide-version</span><br><span class="line">  stats admin if TRUE</span><br><span class="line"></span><br><span class="line">frontend remote-tools-xxx-frontend</span><br><span class="line">   mode tcp</span><br><span class="line">   bind :43745</span><br><span class="line">   default_backend remote-tools-xxx-backend</span><br><span class="line"></span><br><span class="line">backend remote-tools-xxx-backend</span><br><span class="line">    mode tcp</span><br><span class="line">    balance roundrobin</span><br><span class="line">    server node01 x.x.x.x:43745 weight 3 minconn 100 maxconn 50000 check inter 5000 rise 2 fall 5</span><br></pre></td></tr></table></figure>
<h2 id="4-启动HAProxy"><a href="#4-启动HAProxy" class="headerlink" title="4. 启动HAProxy"></a>4. 启动HAProxy</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl start haproxy.service</span><br><span class="line">systemctl status haproxy.service</span><br></pre></td></tr></table></figure>
<h2 id="5-参考资料"><a href="#5-参考资料" class="headerlink" title="5. 参考资料"></a>5. 参考资料</h2><p><a href="https://blog.51cto.com/yanconggod/2062213" target="_blank" rel="noopener">https://blog.51cto.com/yanconggod/2062213</a></p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Docker/">Docker</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/HAProxy/">HAProxy</a></li></ul>
	</div>

      
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/容器云技术/">容器云技术</a>
	</div>


      
      <div class="clearfix"></div>
    </div>
      
    
  </div>
  
</article>







  
    <article id="post-binary_kubernetes_ha_cluster_000" class="article article-type-post" itemscope="" itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2020/03/15/binary_kubernetes_ha_cluster_000/" class="article-date">
  	<time datetime="2020-03-15T01:17:34.541Z" itemprop="datePublished">2020-03-15</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/03/15/binary_kubernetes_ha_cluster_000/">
        使用二进制文件安装高可用Kubernetes v1.17.0集群（Stacked Control Plane Nodes For Baremetal）
        
      </a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="一、高可用部署的实现方式介绍"><a href="#一、高可用部署的实现方式介绍" class="headerlink" title="一、高可用部署的实现方式介绍"></a>一、高可用部署的实现方式介绍</h1><p>本方案演变自 Kubeadm Highly Available v1.17.0（Stacked etcd topology）部署方案。</p>
<h1 id="二、实验环境版本信息"><a href="#二、实验环境版本信息" class="headerlink" title="二、实验环境版本信息"></a>二、实验环境版本信息</h1><h2 id="1-高可用工具的版本（这里记录的是docker镜像的版本）"><a href="#1-高可用工具的版本（这里记录的是docker镜像的版本）" class="headerlink" title="1. 高可用工具的版本（这里记录的是docker镜像的版本）"></a>1. 高可用工具的版本（这里记录的是docker镜像的版本）</h2><p>keepalived-1.3.5-16.el7<br>haproxy-1.5.18-9.el7 </p>
<h2 id="2-Kubernetes各个组件的版本"><a href="#2-Kubernetes各个组件的版本" class="headerlink" title="2. Kubernetes各个组件的版本"></a>2. Kubernetes各个组件的版本</h2><p>etcd v3.4.3<br>kube-apiserver v1.17.0<br>kube-controller-manager v1.17.0<br>kube-scheduler v1.17.0<br>kubectl v1.17.0<br>coredns 1.6.5</p>
<p>docker 18.09.9<br>kube-proxy v1.17.0<br>kubelet v1.17.0<br>calico v3.11.1 （calico/node:v3.11.1 calico/pod2daemon-flexvol:v3.11.1 calico/cni:v3.11.1 calico/kube-controllers:v3.11.1）</p>
<h1 id="三、部署架构介绍"><a href="#三、部署架构介绍" class="headerlink" title="三、部署架构介绍"></a>三、部署架构介绍</h1><p><img src="/2020/03/15/binary_kubernetes_ha_cluster_000/stacked_etcd_topology.png" alt="stacked_etcd_topology"></p>
<h2 id="1-Kubernetes-Master（Control-Plane）"><a href="#1-Kubernetes-Master（Control-Plane）" class="headerlink" title="1. Kubernetes Master（Control Plane）"></a>1. Kubernetes Master（Control Plane）</h2><p>192.168.112.128 master01 -&gt; docker kubelet keepalived haproxy etcd kube-apiserver kube-controller-manager kube-scheduler kube-proxy calico<br>192.168.112.129 master02 -&gt; docker kubelet keepalived haproxy etcd kube-apiserver kube-controller-manager kube-scheduler kube-proxy calico<br>192.168.112.130 master03 -&gt; docker kubelet keepalived haproxy etcd kube-apiserver kube-controller-manager kube-scheduler kube-proxy calico</p>
<h2 id="2-Kubernetes-Node"><a href="#2-Kubernetes-Node" class="headerlink" title="2. Kubernetes Node"></a>2. Kubernetes Node</h2><p>192.168.112.131 node01 -&gt; docker kubelet kube-proxy calico（calico-node）<br>192.168.112.132 node02 -&gt; docker kubelet kube-proxy calico（calico-node）</p>
<h1 id="四、实现过程记录"><a href="#四、实现过程记录" class="headerlink" title="四、实现过程记录"></a>四、实现过程记录</h1><h2 id="1-在Kubernetes-Control-Plane上的所有Node上部署HAProxy做为负载均衡器（由Systemd管理以启动二进制文件的方式实现）"><a href="#1-在Kubernetes-Control-Plane上的所有Node上部署HAProxy做为负载均衡器（由Systemd管理以启动二进制文件的方式实现）" class="headerlink" title="1. 在Kubernetes Control Plane上的所有Node上部署HAProxy做为负载均衡器（由Systemd管理以启动二进制文件的方式实现）"></a>1. 在Kubernetes Control Plane上的所有Node上部署HAProxy做为负载均衡器（由Systemd管理以启动二进制文件的方式实现）</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line">## 在控制平面的所有Node上执行，即master01、master02和master03上都执行</span><br><span class="line">yum install -y haproxy</span><br><span class="line">cp /etc/haproxy/haproxy.cfg /etc/haproxy/haproxy.cfg.bak</span><br><span class="line">cat &lt;&lt;EOF &gt; /etc/haproxy/haproxy.cfg</span><br><span class="line">global</span><br><span class="line">  log 127.0.0.1 local0 err</span><br><span class="line">  maxconn 50000</span><br><span class="line">  uid 99</span><br><span class="line">  gid 99</span><br><span class="line">  #daemon</span><br><span class="line">  nbproc 1</span><br><span class="line">  pidfile haproxy.pid</span><br><span class="line"></span><br><span class="line">defaults</span><br><span class="line">  mode tcp</span><br><span class="line">  log 127.0.0.1 local0 err</span><br><span class="line">  maxconn 50000</span><br><span class="line">  retries 3</span><br><span class="line">  timeout connect 10s</span><br><span class="line">  timeout client 10m</span><br><span class="line">  timeout server 10m</span><br><span class="line"></span><br><span class="line">listen stats</span><br><span class="line">  mode http</span><br><span class="line">  bind 0.0.0.0:9090</span><br><span class="line">  log 127.0.0.1 local0 err</span><br><span class="line">  stats refresh 30s</span><br><span class="line">  stats uri     /haproxy-status</span><br><span class="line">  stats realm   Haproxy\ Statistics</span><br><span class="line">  stats auth    admin:12345678</span><br><span class="line">  stats hide-version</span><br><span class="line">  stats admin if TRUE</span><br><span class="line"></span><br><span class="line">frontend kube-apiserver-https</span><br><span class="line">   mode tcp</span><br><span class="line">   bind :8443</span><br><span class="line">   default_backend kube-apiserver-backend</span><br><span class="line"></span><br><span class="line">backend kube-apiserver-backend</span><br><span class="line">    mode tcp</span><br><span class="line">    balance roundrobin</span><br><span class="line">    server master01 192.168.112.128:6443 weight 3 minconn 100 maxconn 50000 check inter 5000 rise 2 fall 5</span><br><span class="line">    server master02 192.168.112.129:6443 weight 3 minconn 100 maxconn 50000 check inter 5000 rise 2 fall 5</span><br><span class="line">    server master03 192.168.112.130:6443 weight 3 minconn 100 maxconn 50000 check inter 5000 rise 2 fall 5</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable haproxy.service</span><br><span class="line">systemctl start haproxy.service</span><br><span class="line">systemctl status haproxy.service</span><br><span class="line">------------------------------------------------------------------------------------------------------------------------------------------------</span><br><span class="line">● haproxy.service - HAProxy Load Balancer</span><br><span class="line">   Loaded: loaded (/usr/lib/systemd/system/haproxy.service; enabled; vendor preset: disabled)</span><br><span class="line">   Active: active (running) since Sun 2020-03-15 12:42:17 CST; 34s ago</span><br><span class="line"> Main PID: 3273 (haproxy-systemd)</span><br><span class="line">    Tasks: 3</span><br><span class="line">   Memory: 2.3M</span><br><span class="line">。。。。。。</span><br></pre></td></tr></table></figure>
<h2 id="2-在Kubernetes-Control-Plane的所有Node上部署Keepalived（由Systemd管理以启动二进制文件的方式实现）"><a href="#2-在Kubernetes-Control-Plane的所有Node上部署Keepalived（由Systemd管理以启动二进制文件的方式实现）" class="headerlink" title="2. 在Kubernetes Control Plane的所有Node上部署Keepalived（由Systemd管理以启动二进制文件的方式实现）"></a>2. 在Kubernetes Control Plane的所有Node上部署Keepalived（由Systemd管理以启动二进制文件的方式实现）</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br></pre></td><td class="code"><pre><span class="line"># 在控制平面的所有Node上执行，即master01、master02和master03上都执行</span><br><span class="line">yum install -y keepalived</span><br><span class="line">cp /etc/keepalived/keepalived.conf /etc/keepalived/keepalived.conf.bak</span><br><span class="line"></span><br><span class="line"># 在控制平面的master01上执行</span><br><span class="line">cat &lt;&lt;EOF &gt; /etc/keepalived/keepalived.conf</span><br><span class="line">! Configuration File for keepalived</span><br><span class="line"></span><br><span class="line">global_defs &#123;</span><br><span class="line">   router_id k8s-1</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp_script CheckK8sMaster &#123;</span><br><span class="line">    script &quot;curl -k https://127.0.0.1:6443/api&quot;</span><br><span class="line">    interval 3</span><br><span class="line">    timeout 9</span><br><span class="line">    fall 2</span><br><span class="line">    rise 2</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line">    state MASTER</span><br><span class="line">    interface  ens33</span><br><span class="line">    virtual_router_id 51</span><br><span class="line">    priority 200</span><br><span class="line">    advert_int 1</span><br><span class="line">    mcast_src_ip 192.168.112.128</span><br><span class="line">    nopreempt</span><br><span class="line">    authentication &#123;</span><br><span class="line">        auth_type PASS</span><br><span class="line">        auth_pass 378378</span><br><span class="line">    &#125;</span><br><span class="line">    unicast_peer &#123;</span><br><span class="line">        192.168.112.129</span><br><span class="line">        192.168.112.130</span><br><span class="line">    &#125;</span><br><span class="line">    virtual_ipaddress &#123;</span><br><span class="line">        192.168.112.136</span><br><span class="line">    &#125;</span><br><span class="line">    track_script &#123;</span><br><span class="line">        CheckK8sMaster</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"># 在控制平面的master02上执行</span><br><span class="line">cat &lt;&lt;EOF &gt; /etc/keepalived/keepalived.conf</span><br><span class="line">! Configuration File for keepalived</span><br><span class="line"></span><br><span class="line">global_defs &#123;</span><br><span class="line">   router_id k8s-2</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp_script CheckK8sMaster &#123;</span><br><span class="line">    script &quot;curl -k https://127.0.0.1:6443/api&quot;</span><br><span class="line">    interval 3</span><br><span class="line">    timeout 9</span><br><span class="line">    fall 2</span><br><span class="line">    rise 2</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line">    state BACKUP</span><br><span class="line">    interface  ens33</span><br><span class="line">    virtual_router_id 51</span><br><span class="line">    priority 150</span><br><span class="line">    advert_int 1</span><br><span class="line">    mcast_src_ip 192.168.112.129</span><br><span class="line">    nopreempt</span><br><span class="line">    authentication &#123;</span><br><span class="line">        auth_type PASS</span><br><span class="line">        auth_pass 378378</span><br><span class="line">    &#125;</span><br><span class="line">    unicast_peer &#123;</span><br><span class="line">        192.168.112.128</span><br><span class="line">        192.168.112.130</span><br><span class="line">    &#125;</span><br><span class="line">    virtual_ipaddress &#123;</span><br><span class="line">        192.168.112.136</span><br><span class="line">    &#125;</span><br><span class="line">    track_script &#123;</span><br><span class="line">        CheckK8sMaster</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"># 在控制平面的master03上执行</span><br><span class="line">cat &lt;&lt;EOF &gt; /etc/keepalived/keepalived.conf</span><br><span class="line">! Configuration File for keepalived</span><br><span class="line"></span><br><span class="line">global_defs &#123;</span><br><span class="line">   router_id k8s-3</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp_script CheckK8sMaster &#123;</span><br><span class="line">    script &quot;curl -k https://127.0.0.1:6443/api&quot;</span><br><span class="line">    interval 3</span><br><span class="line">    timeout 9</span><br><span class="line">    fall 2</span><br><span class="line">    rise 2</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line">    state BACKUP</span><br><span class="line">    interface  ens33</span><br><span class="line">    virtual_router_id 51</span><br><span class="line">    priority 150</span><br><span class="line">    advert_int 1</span><br><span class="line">    mcast_src_ip 192.168.112.130</span><br><span class="line">    nopreempt</span><br><span class="line">    authentication &#123;</span><br><span class="line">        auth_type PASS</span><br><span class="line">        auth_pass 378378</span><br><span class="line">    &#125;</span><br><span class="line">    unicast_peer &#123;</span><br><span class="line">        192.168.112.128</span><br><span class="line">        192.168.112.129</span><br><span class="line">    &#125;</span><br><span class="line">    virtual_ipaddress &#123;</span><br><span class="line">        192.168.112.136</span><br><span class="line">    &#125;</span><br><span class="line">    track_script &#123;</span><br><span class="line">        CheckK8sMaster</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"># 在控制平面的所有Node上执行，即master01、master02和master03上都执行</span><br><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable keepalived.service</span><br><span class="line">systemctl start keepalived.service</span><br><span class="line">systemctl status keepalived.service</span><br><span class="line">------------------------------------------------------------------------------------------------------------------------------------------------</span><br><span class="line">● keepalived.service - LVS and VRRP High Availability Monitor</span><br><span class="line">   Loaded: loaded (/usr/lib/systemd/system/keepalived.service; enabled; vendor preset: disabled)</span><br><span class="line">   Active: active (running) since Sun 2020-03-15 12:49:45 CST; 16s ago</span><br><span class="line">  Process: 3632 ExecStart=/usr/sbin/keepalived $KEEPALIVED_OPTIONS (code=exited, status=0/SUCCESS)</span><br><span class="line"> Main PID: 3633 (keepalived)</span><br><span class="line">    Tasks: 3</span><br><span class="line">   Memory: 6.5M</span><br><span class="line">。。。。。。</span><br></pre></td></tr></table></figure>
<h2 id="3-复制所有二进制文件到操作系统-usr-bin-目录下"><a href="#3-复制所有二进制文件到操作系统-usr-bin-目录下" class="headerlink" title="3. 复制所有二进制文件到操作系统/usr/bin/目录下"></a>3. 复制所有二进制文件到操作系统/usr/bin/目录下</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># master01、master02和master03上分别执行</span><br><span class="line">tar -zxvf etcd-v3.4.3-linux-amd64.tar.gz</span><br><span class="line">tar -zxvf kubernetes-server-linux-amd64.tar.gz</span><br><span class="line"></span><br><span class="line">cp etcd-v3.4.3-linux-amd64/etcd /usr/bin/</span><br><span class="line">cp etcd-v3.4.3-linux-amd64/etcdctl /usr/bin/</span><br><span class="line">cp kubernetes/server/bin/kube-apiserver /usr/bin/</span><br><span class="line">cp kubernetes/server/bin/kube-controller-manager /usr/bin/</span><br><span class="line">cp kubernetes/server/bin/kube-scheduler /usr/bin/</span><br><span class="line">cp kubernetes/server/bin/kubectl /usr/bin/</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># node01和node02上分别执行</span><br><span class="line">tar -zxvf kubernetes-server-linux-amd64.tar.gz</span><br><span class="line"></span><br><span class="line">cp kubernetes/server/bin/kubelet /usr/bin/</span><br><span class="line">cp kubernetes/server/bin/kube-proxy /usr/bin/</span><br></pre></td></tr></table></figure>
<h2 id="4-Kubernetes-Control-Plane的第一个Node上生成根证书、RSA秘钥和kubectl的访问配置文件"><a href="#4-Kubernetes-Control-Plane的第一个Node上生成根证书、RSA秘钥和kubectl的访问配置文件" class="headerlink" title="4. Kubernetes Control Plane的第一个Node上生成根证书、RSA秘钥和kubectl的访问配置文件"></a>4. Kubernetes Control Plane的第一个Node上生成根证书、RSA秘钥和kubectl的访问配置文件</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"># 创建证书和配置文件的存放目录</span><br><span class="line">mkdir -p /etc/kubernetes/pki/etcd/</span><br><span class="line"></span><br><span class="line"># 生成etcd的相关证书</span><br><span class="line">cd /etc/kubernetes/pki/etcd/</span><br><span class="line">openssl genrsa -out ca.key 2048</span><br><span class="line">openssl req -x509 -new -nodes -key ca.key -subj &quot;/CN=etcd-ca&quot; -days 5000 -out ca.crt</span><br><span class="line"></span><br><span class="line"># 生成rsa的公钥和私钥</span><br><span class="line">cd /etc/kubernetes/pki/</span><br><span class="line">openssl genrsa -out sa.key 2048</span><br><span class="line">openssl rsa -in sa.key -pubout -out sa.pub</span><br><span class="line"></span><br><span class="line"># 生成根证书</span><br><span class="line">cd /etc/kubernetes/pki/</span><br><span class="line">openssl genrsa -out ca.key 2048</span><br><span class="line">openssl req -x509 -new -nodes -key ca.key -subj &quot;/CN=kubernetes&quot; -days 5000 -out ca.crt</span><br><span class="line"></span><br><span class="line">openssl genrsa -out front-proxy-ca.key 2048</span><br><span class="line">openssl req -x509 -new -nodes -key front-proxy-ca.key -subj &quot;/CN=front-proxy-ca&quot; -days 5000 -out front-proxy-ca.crt</span><br><span class="line"></span><br><span class="line"># 为kubectl生成相关的证书和配置文件</span><br><span class="line">openssl genrsa -out kubectl.key 2048</span><br><span class="line">openssl req -new -key kubectl.key -subj &quot;/O=system:masters/CN=kubernetes-admin&quot; -out kubectl.csr</span><br><span class="line">openssl x509 -req -in kubectl.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out kubectl.crt -days 5000</span><br><span class="line"></span><br><span class="line">export KUBECONFIG=/etc/kubernetes/admin.conf</span><br><span class="line">kubectl config set-cluster kubernetes --server=https://192.168.112.136:8443 --certificate-authority=/etc/kubernetes/pki/ca.crt --embed-certs=true</span><br><span class="line">kubectl config set-credentials kubernetes-admin --client-certificate=/etc/kubernetes/pki/kubectl.crt --client-key=/etc/kubernetes/pki/kubectl.key --embed-certs=true</span><br><span class="line">kubectl config set-context kubernetes-admin@kubernetes --cluster=kubernetes --user=kubernetes-admin</span><br><span class="line">kubectl config use-context kubernetes-admin@kubernetes</span><br><span class="line">unset KUBECONFIG</span><br><span class="line"></span><br><span class="line">## 为kube-proxy生成相关的证书和配置文件</span><br><span class="line">## kubernetes内置的为kube-proxy而生的clusterrole，可以使用kubectl get clusterrole system:node-proxier -o yaml进行查看</span><br><span class="line">## kubernetes内置的为kube-proxy而生的clusterrolebinding，绑定到了用户system:kube-proxy，可以使用kubectl get clusterrolebinding system:node-proxier -o yaml进行查看</span><br><span class="line">openssl genrsa -out proxy.key 2048</span><br><span class="line">openssl req -new -key proxy.key -subj &quot;/CN=system:kube-proxy&quot; -out proxy.csr</span><br><span class="line">openssl x509 -req -in proxy.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out proxy.crt -days 5000</span><br><span class="line"></span><br><span class="line">export KUBECONFIG=/etc/kubernetes/proxy.conf</span><br><span class="line">kubectl config set-cluster kubernetes --server=https://192.168.112.136:8443 --certificate-authority=/etc/kubernetes/pki/ca.crt --embed-certs=true</span><br><span class="line">kubectl config set-credentials system:kube-proxy --client-certificate=/etc/kubernetes/pki/proxy.crt --client-key=/etc/kubernetes/pki/proxy.key --embed-certs=true</span><br><span class="line">kubectl config set-context system:kube-proxy@kubernetes --cluster=kubernetes --user=system:kube-proxy</span><br><span class="line">kubectl config use-context system:kube-proxy@kubernetes</span><br><span class="line">unset KUBECONFIG</span><br><span class="line"></span><br><span class="line">## 为Bootstrap Token生成配置文件，一旦这里的 --token 参数值做了修改，后面用于开启Bootstrap Token的Secret配置需要同步修改，其对应赢规律如下：</span><br><span class="line">## 1. token为abcdef.0123456789abcdef，其对应了后面启用Bootstrap Token的Secret中的 &lt;token-id&gt;.&lt;token-secret&gt;</span><br><span class="line">## 2. 后面用于启用Bootstrap Token的Secret的名字为bootstrap-token-abcdef，其严格对应了格式：bootstrap-token-&lt;token-id&gt;</span><br><span class="line">export KUBECONFIG=/etc/kubernetes/bootstrap-kubelet.conf</span><br><span class="line">kubectl config set-cluster kubernetes --server=https://192.168.112.136:8443 --certificate-authority=/etc/kubernetes/pki/ca.crt --embed-certs=true</span><br><span class="line">kubectl config set-credentials system:bootstrap:abcdef --token=abcdef.0123456789abcdef</span><br><span class="line">kubectl config set-context system:bootstrap:abcdef@kubernetes --cluster=kubernetes --user=system:bootstrap:abcdef</span><br><span class="line">kubectl config use-context system:bootstrap:abcdef@kubernetes</span><br><span class="line">unset KUBECONFIG</span><br></pre></td></tr></table></figure>
<h2 id="5-分发根证书、RSA秘钥和kubectl的访问配置文件到Kubernetes-Control-Plane的剩余两个Node上"><a href="#5-分发根证书、RSA秘钥和kubectl的访问配置文件到Kubernetes-Control-Plane的剩余两个Node上" class="headerlink" title="5. 分发根证书、RSA秘钥和kubectl的访问配置文件到Kubernetes Control Plane的剩余两个Node上"></a>5. 分发根证书、RSA秘钥和kubectl的访问配置文件到Kubernetes Control Plane的剩余两个Node上</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"># 在master01上执行</span><br><span class="line"># 配置master01到master02和master03的ssh免密登录</span><br><span class="line">ssh-keygen</span><br><span class="line">ssh-copy-id -i .ssh/id_rsa.pub root@master02</span><br><span class="line">ssh-copy-id -i .ssh/id_rsa.pub root@master03</span><br><span class="line"></span><br><span class="line">## 验证master01到master02和master03的ssh免密登录</span><br><span class="line">ssh master02</span><br><span class="line">ssh master03</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt; kubernetes-master-transfer.sh</span><br><span class="line">USER=root</span><br><span class="line">CONTROL_PLANE_IPS=&quot;192.168.112.129 192.168.112.130&quot;</span><br><span class="line">for host in \$&#123;CONTROL_PLANE_IPS&#125;; do</span><br><span class="line">    ssh \$&#123;USER&#125;@\$host &apos;mkdir -p /etc/kubernetes/pki/etcd/&apos;</span><br><span class="line">    scp /etc/kubernetes/pki/ca.crt \$&#123;USER&#125;@\$host:/etc/kubernetes/pki/</span><br><span class="line">    scp /etc/kubernetes/pki/ca.key \$&#123;USER&#125;@\$host:/etc/kubernetes/pki/</span><br><span class="line">    scp /etc/kubernetes/pki/sa.key \$&#123;USER&#125;@\$host:/etc/kubernetes/pki/</span><br><span class="line">    scp /etc/kubernetes/pki/sa.pub \$&#123;USER&#125;@\$host:/etc/kubernetes/pki/</span><br><span class="line">    scp /etc/kubernetes/pki/front-proxy-ca.crt \$&#123;USER&#125;@\$host:/etc/kubernetes/pki/</span><br><span class="line">    scp /etc/kubernetes/pki/front-proxy-ca.key \$&#123;USER&#125;@\$host:/etc/kubernetes/pki/</span><br><span class="line">    scp /etc/kubernetes/pki/etcd/ca.crt \$&#123;USER&#125;@\$host:/etc/kubernetes/pki/etcd/</span><br><span class="line">    scp /etc/kubernetes/pki/etcd/ca.key \$&#123;USER&#125;@\$host:/etc/kubernetes/pki/etcd/</span><br><span class="line">    scp /etc/kubernetes/admin.conf \$&#123;USER&#125;@\$host:/etc/kubernetes/</span><br><span class="line">    scp /etc/kubernetes/proxy.conf \$&#123;USER&#125;@\$host:/etc/kubernetes/</span><br><span class="line">    scp /etc/kubernetes/bootstrap-kubelet.conf \$&#123;USER&#125;@\$host:/etc/kubernetes/</span><br><span class="line">done</span><br><span class="line">EOF</span><br><span class="line">chmod 0755 kubernetes-master-transfer.sh</span><br><span class="line">./kubernetes-master-transfer.sh</span><br></pre></td></tr></table></figure>
<h2 id="6-利用根证书签发各个Master节点上需要的所有证书"><a href="#6-利用根证书签发各个Master节点上需要的所有证书" class="headerlink" title="6. 利用根证书签发各个Master节点上需要的所有证书"></a>6. 利用根证书签发各个Master节点上需要的所有证书</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br></pre></td><td class="code"><pre><span class="line"># 仅在master01上执行</span><br><span class="line">## 生成etcd的相关证书</span><br><span class="line">cd /etc/kubernetes/pki/etcd/</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt; server_ssl.cnf</span><br><span class="line">[req]</span><br><span class="line">req_extensions = v3_req</span><br><span class="line">distinguished_name = req_distinguished_name</span><br><span class="line"></span><br><span class="line">[req_distinguished_name]</span><br><span class="line">[v3_req]</span><br><span class="line">basicConstraints = CA:FALSE</span><br><span class="line">keyUsage = nonRepudiation,digitalSignature,keyEncipherment</span><br><span class="line">subjectAltName = @alt_names</span><br><span class="line">[alt_names]</span><br><span class="line">DNS.1 = master01</span><br><span class="line">DNS.2 = localhost</span><br><span class="line">IP.1 = 192.168.112.128</span><br><span class="line">IP.2 = 127.0.0.1</span><br><span class="line">EOF</span><br><span class="line">openssl genrsa -out server.key 2048</span><br><span class="line">openssl req -new -key server.key -subj &quot;/CN=master01&quot; -config server_ssl.cnf -out server.csr</span><br><span class="line">openssl x509 -req -in server.csr -CA ca.crt -CAkey ca.key -CAcreateserial -days 5000 -extensions v3_req -extfile server_ssl.cnf -out server.crt</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt; peer_ssl.cnf</span><br><span class="line">[req]</span><br><span class="line">req_extensions = v3_req</span><br><span class="line">distinguished_name = req_distinguished_name</span><br><span class="line"></span><br><span class="line">[req_distinguished_name]</span><br><span class="line">[v3_req]</span><br><span class="line">basicConstraints = CA:FALSE</span><br><span class="line">keyUsage = nonRepudiation,digitalSignature,keyEncipherment</span><br><span class="line">subjectAltName = @alt_names</span><br><span class="line">[alt_names]</span><br><span class="line">DNS.1 = master01</span><br><span class="line">DNS.2 = localhost</span><br><span class="line">IP.1 = 192.168.112.128</span><br><span class="line">IP.2 = 127.0.0.1</span><br><span class="line">EOF</span><br><span class="line">openssl genrsa -out peer.key 2048</span><br><span class="line">openssl req -new -key peer.key -subj &quot;/CN=master01&quot; -config peer_ssl.cnf -out peer.csr</span><br><span class="line">openssl x509 -req -in peer.csr -CA ca.crt -CAkey ca.key -CAcreateserial -days 5000 -extensions v3_req -extfile peer_ssl.cnf -out peer.crt</span><br><span class="line"></span><br><span class="line">openssl genrsa -out healthcheck-client.key 2048</span><br><span class="line">openssl req -new -key healthcheck-client.key -subj &quot;/O=system:masters/CN=kube-etcd-healthcheck-client&quot; -out healthcheck-client.csr</span><br><span class="line">openssl x509 -req -in healthcheck-client.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out healthcheck-client.crt -days 5000</span><br><span class="line"></span><br><span class="line">cd /etc/kubernetes/pki/</span><br><span class="line">openssl genrsa -out apiserver-etcd-client.key 2048</span><br><span class="line">openssl req -new -key apiserver-etcd-client.key -subj &quot;/O=system:masters/CN=kube-apiserver-etcd-client&quot; -out apiserver-etcd-client.csr</span><br><span class="line">openssl x509 -req -in apiserver-etcd-client.csr -CA /etc/kubernetes/pki/etcd/ca.crt -CAkey /etc/kubernetes/pki/etcd/ca.key -CAcreateserial -out apiserver-etcd-client.crt -days 5000</span><br><span class="line"></span><br><span class="line">## 为kube-apiserver生成相关的证书和配置文件</span><br><span class="line">cat &lt;&lt;EOF &gt; master_ssl.cnf</span><br><span class="line">[req]</span><br><span class="line">req_extensions = v3_req</span><br><span class="line">distinguished_name = req_distinguished_name</span><br><span class="line"></span><br><span class="line">[req_distinguished_name]</span><br><span class="line">[v3_req]</span><br><span class="line">basicConstraints = CA:FALSE</span><br><span class="line">keyUsage = nonRepudiation,digitalSignature,keyEncipherment</span><br><span class="line">subjectAltName = @alt_names</span><br><span class="line">[alt_names]</span><br><span class="line">DNS.1 = master</span><br><span class="line">DNS.2 = kubernetes</span><br><span class="line">DNS.3 = kubernetes.default</span><br><span class="line">DNS.4 = kubernetes.default.svc</span><br><span class="line">DNS.5 = kubernetes.default.svc.cluster.local</span><br><span class="line">IP.1 = 10.96.0.1</span><br><span class="line">IP.2 = 192.168.112.128</span><br><span class="line">IP.3 = 192.168.112.136</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">openssl genrsa -out apiserver.key 2048</span><br><span class="line">openssl req -new -key apiserver.key -subj &quot;/CN=kube-apiserver&quot; -config master_ssl.cnf -out apiserver.csr</span><br><span class="line">openssl x509 -req -in apiserver.csr -CA ca.crt -CAkey ca.key -CAcreateserial -days 5000 -extensions v3_req -extfile master_ssl.cnf -out apiserver.crt</span><br><span class="line"></span><br><span class="line">openssl genrsa -out front-proxy-client.key 2048</span><br><span class="line">openssl req -new -key front-proxy-client.key -subj &quot;/CN=front-proxy-client&quot; -out front-proxy-client.csr</span><br><span class="line">openssl x509 -req -in front-proxy-client.csr -CA front-proxy-ca.crt -CAkey front-proxy-ca.key -CAcreateserial -out front-proxy-client.crt -days 5000</span><br><span class="line"></span><br><span class="line">openssl genrsa -out apiserver-kubelet-client.key 2048</span><br><span class="line">openssl req -new -key apiserver-kubelet-client.key -subj &quot;/O=system:masters/CN=kube-apiserver-kubelet-client&quot; -out apiserver-kubelet-client.csr</span><br><span class="line">openssl x509 -req -in apiserver-kubelet-client.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out apiserver-kubelet-client.crt -days 5000</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 仅在master02上执行</span><br><span class="line">## 生成etcd的相关证书</span><br><span class="line">cd /etc/kubernetes/pki/etcd/</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt; server_ssl.cnf</span><br><span class="line">[req]</span><br><span class="line">req_extensions = v3_req</span><br><span class="line">distinguished_name = req_distinguished_name</span><br><span class="line"></span><br><span class="line">[req_distinguished_name]</span><br><span class="line">[v3_req]</span><br><span class="line">basicConstraints = CA:FALSE</span><br><span class="line">keyUsage = nonRepudiation,digitalSignature,keyEncipherment</span><br><span class="line">subjectAltName = @alt_names</span><br><span class="line">[alt_names]</span><br><span class="line">DNS.1 = master02</span><br><span class="line">DNS.2 = localhost</span><br><span class="line">IP.1 = 192.168.112.129</span><br><span class="line">IP.2 = 127.0.0.1</span><br><span class="line">EOF</span><br><span class="line">openssl genrsa -out server.key 2048</span><br><span class="line">openssl req -new -key server.key -subj &quot;/CN=master02&quot; -config server_ssl.cnf -out server.csr</span><br><span class="line">openssl x509 -req -in server.csr -CA ca.crt -CAkey ca.key -CAcreateserial -days 5000 -extensions v3_req -extfile server_ssl.cnf -out server.crt</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt; peer_ssl.cnf</span><br><span class="line">[req]</span><br><span class="line">req_extensions = v3_req</span><br><span class="line">distinguished_name = req_distinguished_name</span><br><span class="line"></span><br><span class="line">[req_distinguished_name]</span><br><span class="line">[v3_req]</span><br><span class="line">basicConstraints = CA:FALSE</span><br><span class="line">keyUsage = nonRepudiation,digitalSignature,keyEncipherment</span><br><span class="line">subjectAltName = @alt_names</span><br><span class="line">[alt_names]</span><br><span class="line">DNS.1 = master02</span><br><span class="line">DNS.2 = localhost</span><br><span class="line">IP.1 = 192.168.112.129</span><br><span class="line">IP.2 = 127.0.0.1</span><br><span class="line">EOF</span><br><span class="line">openssl genrsa -out peer.key 2048</span><br><span class="line">openssl req -new -key peer.key -subj &quot;/CN=master02&quot; -config peer_ssl.cnf -out peer.csr</span><br><span class="line">openssl x509 -req -in peer.csr -CA ca.crt -CAkey ca.key -CAcreateserial -days 5000 -extensions v3_req -extfile peer_ssl.cnf -out peer.crt</span><br><span class="line"></span><br><span class="line">openssl genrsa -out healthcheck-client.key 2048</span><br><span class="line">openssl req -new -key healthcheck-client.key -subj &quot;/O=system:masters/CN=kube-etcd-healthcheck-client&quot; -out healthcheck-client.csr</span><br><span class="line">openssl x509 -req -in healthcheck-client.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out healthcheck-client.crt -days 5000</span><br><span class="line"></span><br><span class="line">cd /etc/kubernetes/pki/</span><br><span class="line">openssl genrsa -out apiserver-etcd-client.key 2048</span><br><span class="line">openssl req -new -key apiserver-etcd-client.key -subj &quot;/O=system:masters/CN=kube-apiserver-etcd-client&quot; -out apiserver-etcd-client.csr</span><br><span class="line">openssl x509 -req -in apiserver-etcd-client.csr -CA /etc/kubernetes/pki/etcd/ca.crt -CAkey /etc/kubernetes/pki/etcd/ca.key -CAcreateserial -out apiserver-etcd-client.crt -days 5000</span><br><span class="line"></span><br><span class="line">## 为kube-apiserver生成相关的证书和配置文件</span><br><span class="line">cat &lt;&lt;EOF &gt; master_ssl.cnf</span><br><span class="line">[req]</span><br><span class="line">req_extensions = v3_req</span><br><span class="line">distinguished_name = req_distinguished_name</span><br><span class="line"></span><br><span class="line">[req_distinguished_name]</span><br><span class="line">[v3_req]</span><br><span class="line">basicConstraints = CA:FALSE</span><br><span class="line">keyUsage = nonRepudiation,digitalSignature,keyEncipherment</span><br><span class="line">subjectAltName = @alt_names</span><br><span class="line">[alt_names]</span><br><span class="line">DNS.1 = master</span><br><span class="line">DNS.2 = kubernetes</span><br><span class="line">DNS.3 = kubernetes.default</span><br><span class="line">DNS.4 = kubernetes.default.svc</span><br><span class="line">DNS.5 = kubernetes.default.svc.cluster.local</span><br><span class="line">IP.1 = 10.96.0.1</span><br><span class="line">IP.2 = 192.168.112.129</span><br><span class="line">IP.3 = 192.168.112.136</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">openssl genrsa -out apiserver.key 2048</span><br><span class="line">openssl req -new -key apiserver.key -subj &quot;/CN=kube-apiserver&quot; -config master_ssl.cnf -out apiserver.csr</span><br><span class="line">openssl x509 -req -in apiserver.csr -CA ca.crt -CAkey ca.key -CAcreateserial -days 5000 -extensions v3_req -extfile master_ssl.cnf -out apiserver.crt</span><br><span class="line"></span><br><span class="line">openssl genrsa -out front-proxy-client.key 2048</span><br><span class="line">openssl req -new -key front-proxy-client.key -subj &quot;/CN=front-proxy-client&quot; -out front-proxy-client.csr</span><br><span class="line">openssl x509 -req -in front-proxy-client.csr -CA front-proxy-ca.crt -CAkey front-proxy-ca.key -CAcreateserial -out front-proxy-client.crt -days 5000</span><br><span class="line"></span><br><span class="line">openssl genrsa -out apiserver-kubelet-client.key 2048</span><br><span class="line">openssl req -new -key apiserver-kubelet-client.key -subj &quot;/O=system:masters/CN=kube-apiserver-kubelet-client&quot; -out apiserver-kubelet-client.csr</span><br><span class="line">openssl x509 -req -in apiserver-kubelet-client.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out apiserver-kubelet-client.crt -days 5000</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 仅在master03上执行</span><br><span class="line">## 生成etcd的相关证书</span><br><span class="line">cd /etc/kubernetes/pki/etcd/</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt; server_ssl.cnf</span><br><span class="line">[req]</span><br><span class="line">req_extensions = v3_req</span><br><span class="line">distinguished_name = req_distinguished_name</span><br><span class="line"></span><br><span class="line">[req_distinguished_name]</span><br><span class="line">[v3_req]</span><br><span class="line">basicConstraints = CA:FALSE</span><br><span class="line">keyUsage = nonRepudiation,digitalSignature,keyEncipherment</span><br><span class="line">subjectAltName = @alt_names</span><br><span class="line">[alt_names]</span><br><span class="line">DNS.1 = master03</span><br><span class="line">DNS.2 = localhost</span><br><span class="line">IP.1 = 192.168.112.130</span><br><span class="line">IP.2 = 127.0.0.1</span><br><span class="line">EOF</span><br><span class="line">openssl genrsa -out server.key 2048</span><br><span class="line">openssl req -new -key server.key -subj &quot;/CN=master03&quot; -config server_ssl.cnf -out server.csr</span><br><span class="line">openssl x509 -req -in server.csr -CA ca.crt -CAkey ca.key -CAcreateserial -days 5000 -extensions v3_req -extfile server_ssl.cnf -out server.crt</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt; peer_ssl.cnf</span><br><span class="line">[req]</span><br><span class="line">req_extensions = v3_req</span><br><span class="line">distinguished_name = req_distinguished_name</span><br><span class="line"></span><br><span class="line">[req_distinguished_name]</span><br><span class="line">[v3_req]</span><br><span class="line">basicConstraints = CA:FALSE</span><br><span class="line">keyUsage = nonRepudiation,digitalSignature,keyEncipherment</span><br><span class="line">subjectAltName = @alt_names</span><br><span class="line">[alt_names]</span><br><span class="line">DNS.1 = master03</span><br><span class="line">DNS.2 = localhost</span><br><span class="line">IP.1 = 192.168.112.130</span><br><span class="line">IP.2 = 127.0.0.1</span><br><span class="line">EOF</span><br><span class="line">openssl genrsa -out peer.key 2048</span><br><span class="line">openssl req -new -key peer.key -subj &quot;/CN=master03&quot; -config peer_ssl.cnf -out peer.csr</span><br><span class="line">openssl x509 -req -in peer.csr -CA ca.crt -CAkey ca.key -CAcreateserial -days 5000 -extensions v3_req -extfile peer_ssl.cnf -out peer.crt</span><br><span class="line"></span><br><span class="line">openssl genrsa -out healthcheck-client.key 2048</span><br><span class="line">openssl req -new -key healthcheck-client.key -subj &quot;/O=system:masters/CN=kube-etcd-healthcheck-client&quot; -out healthcheck-client.csr</span><br><span class="line">openssl x509 -req -in healthcheck-client.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out healthcheck-client.crt -days 5000</span><br><span class="line"></span><br><span class="line">cd /etc/kubernetes/pki/</span><br><span class="line">openssl genrsa -out apiserver-etcd-client.key 2048</span><br><span class="line">openssl req -new -key apiserver-etcd-client.key -subj &quot;/O=system:masters/CN=kube-apiserver-etcd-client&quot; -out apiserver-etcd-client.csr</span><br><span class="line">openssl x509 -req -in apiserver-etcd-client.csr -CA /etc/kubernetes/pki/etcd/ca.crt -CAkey /etc/kubernetes/pki/etcd/ca.key -CAcreateserial -out apiserver-etcd-client.crt -days 5000</span><br><span class="line"></span><br><span class="line">## 为kube-apiserver生成相关的证书和配置文件</span><br><span class="line">cat &lt;&lt;EOF &gt; master_ssl.cnf</span><br><span class="line">[req]</span><br><span class="line">req_extensions = v3_req</span><br><span class="line">distinguished_name = req_distinguished_name</span><br><span class="line"></span><br><span class="line">[req_distinguished_name]</span><br><span class="line">[v3_req]</span><br><span class="line">basicConstraints = CA:FALSE</span><br><span class="line">keyUsage = nonRepudiation,digitalSignature,keyEncipherment</span><br><span class="line">subjectAltName = @alt_names</span><br><span class="line">[alt_names]</span><br><span class="line">DNS.1 = master</span><br><span class="line">DNS.2 = kubernetes</span><br><span class="line">DNS.3 = kubernetes.default</span><br><span class="line">DNS.4 = kubernetes.default.svc</span><br><span class="line">DNS.5 = kubernetes.default.svc.cluster.local</span><br><span class="line">IP.1 = 10.96.0.1</span><br><span class="line">IP.2 = 192.168.112.130</span><br><span class="line">IP.3 = 192.168.112.136</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">openssl genrsa -out apiserver.key 2048</span><br><span class="line">openssl req -new -key apiserver.key -subj &quot;/CN=kube-apiserver&quot; -config master_ssl.cnf -out apiserver.csr</span><br><span class="line">openssl x509 -req -in apiserver.csr -CA ca.crt -CAkey ca.key -CAcreateserial -days 5000 -extensions v3_req -extfile master_ssl.cnf -out apiserver.crt</span><br><span class="line"></span><br><span class="line">openssl genrsa -out front-proxy-client.key 2048</span><br><span class="line">openssl req -new -key front-proxy-client.key -subj &quot;/CN=front-proxy-client&quot; -out front-proxy-client.csr</span><br><span class="line">openssl x509 -req -in front-proxy-client.csr -CA front-proxy-ca.crt -CAkey front-proxy-ca.key -CAcreateserial -out front-proxy-client.crt -days 5000</span><br><span class="line"></span><br><span class="line">openssl genrsa -out apiserver-kubelet-client.key 2048</span><br><span class="line">openssl req -new -key apiserver-kubelet-client.key -subj &quot;/O=system:masters/CN=kube-apiserver-kubelet-client&quot; -out apiserver-kubelet-client.csr</span><br><span class="line">openssl x509 -req -in apiserver-kubelet-client.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out apiserver-kubelet-client.crt -days 5000</span><br><span class="line"></span><br><span class="line"># 分别在master01、master02和master03上执行</span><br><span class="line">## 为kube-controller-manager生成相关的证书和配置文件</span><br><span class="line">openssl genrsa -out controller-manager.key 2048</span><br><span class="line">openssl req -new -key controller-manager.key -subj &quot;/CN=system:kube-controller-manager&quot; -out controller-manager.csr</span><br><span class="line">openssl x509 -req -in controller-manager.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out controller-manager.crt -days 5000</span><br><span class="line"></span><br><span class="line">export KUBECONFIG=/etc/kubernetes/controller-manager.conf</span><br><span class="line">kubectl config set-cluster kubernetes --server=https://192.168.112.136:8443 --certificate-authority=/etc/kubernetes/pki/ca.crt --embed-certs=true</span><br><span class="line">kubectl config set-credentials system:kube-controller-manager --client-certificate=/etc/kubernetes/pki/controller-manager.crt --client-key=/etc/kubernetes/pki/controller-manager.key --embed-certs=true</span><br><span class="line">kubectl config set-context system:kube-controller-manager@kubernetes --cluster=kubernetes --user=system:kube-controller-manager</span><br><span class="line">kubectl config use-context system:kube-controller-manager@kubernetes</span><br><span class="line">unset KUBECONFIG</span><br><span class="line"></span><br><span class="line">## 为kube-scheduler生成相关的证书和配置文件</span><br><span class="line">openssl genrsa -out scheduler.key 2048</span><br><span class="line">openssl req -new -key scheduler.key -subj &quot;/CN=system:kube-scheduler&quot; -out scheduler.csr</span><br><span class="line">openssl x509 -req -in scheduler.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out scheduler.crt -days 5000</span><br><span class="line"></span><br><span class="line">export KUBECONFIG=/etc/kubernetes/scheduler.conf</span><br><span class="line">kubectl config set-cluster kubernetes --server=https://192.168.112.136:8443 --certificate-authority=/etc/kubernetes/pki/ca.crt --embed-certs=true</span><br><span class="line">kubectl config set-credentials system:kube-scheduler --client-certificate=/etc/kubernetes/pki/scheduler.crt --client-key=/etc/kubernetes/pki/scheduler.key --embed-certs=true</span><br><span class="line">kubectl config set-context system:kube-scheduler@kubernetes --cluster=kubernetes --user=system:kube-scheduler</span><br><span class="line">kubectl config use-context system:kube-scheduler@kubernetes</span><br><span class="line">unset KUBECONFIG</span><br></pre></td></tr></table></figure>
<h2 id="7-在所有Master上，分别配置和启动所有组件"><a href="#7-在所有Master上，分别配置和启动所有组件" class="headerlink" title="7. 在所有Master上，分别配置和启动所有组件"></a>7. 在所有Master上，分别配置和启动所有组件</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br></pre></td><td class="code"><pre><span class="line"># 仅在master01上执行</span><br><span class="line">## 配置和启动etcd服务</span><br><span class="line">mkdir -p /etc/etcd/</span><br><span class="line">mkdir -p /var/lib/etcd/</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt; /usr/lib/systemd/system/etcd.service</span><br><span class="line">[Unit]</span><br><span class="line">Description=Etcd Server </span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=simple</span><br><span class="line">WorkingDirectory=/var/lib/etcd/</span><br><span class="line">EnvironmentFile=-/etc/etcd/etcd.env</span><br><span class="line">ExecStart=/usr/bin/etcd \$ETCD_ARGS</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt; /etc/etcd/etcd.env</span><br><span class="line">ETCD_ARGS=&quot;--advertise-client-urls=https://192.168.112.128:2379 --cert-file=/etc/kubernetes/pki/etcd/server.crt --client-cert-auth=true --data-dir=/var/lib/etcd --initial-advertise-peer-urls=https://192.168.112.128:2380 --initial-cluster=master01=https://192.168.112.128:2380 --key-file=/etc/kubernetes/pki/etcd/server.key --listen-client-urls=https://127.0.0.1:2379,https://192.168.112.128:2379 --listen-metrics-urls=http://127.0.0.1:2381 --listen-peer-urls=https://192.168.112.128:2380 --name=master01 --peer-cert-file=/etc/kubernetes/pki/etcd/peer.crt --peer-client-cert-auth=true --peer-key-file=/etc/kubernetes/pki/etcd/peer.key --peer-trusted-ca-file=/etc/kubernetes/pki/etcd/ca.crt --snapshot-count=10000 --trusted-ca-file=/etc/kubernetes/pki/etcd/ca.crt&quot;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable etcd.service</span><br><span class="line">systemctl start etcd.service</span><br><span class="line">systemctl status etcd.service</span><br><span class="line"></span><br><span class="line">## 为etcd集群添加两个节点</span><br><span class="line">etcdctl --endpoints=https://127.0.0.1:2379 --cacert=/etc/kubernetes/pki/etcd/ca.crt --cert=/etc/kubernetes/pki/etcd/server.crt --key=/etc/kubernetes/pki/etcd/server.key member add master02 --peer-urls=&quot;https://192.168.112.129:2380&quot;</span><br><span class="line"></span><br><span class="line">etcdctl --endpoints=https://127.0.0.1:2379 --cacert=/etc/kubernetes/pki/etcd/ca.crt --cert=/etc/kubernetes/pki/etcd/server.crt --key=/etc/kubernetes/pki/etcd/server.key member add master03 --peer-urls=&quot;https://192.168.112.130:2380&quot;</span><br><span class="line"></span><br><span class="line">## 配置kube-apiserver服务</span><br><span class="line">cat &lt;&lt;EOF &gt; /usr/lib/systemd/system/kube-apiserver.service</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes API Server</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=etcd.service</span><br><span class="line">Wants=etcd.service</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">EnvironmentFile=-/etc/kubernetes/kube-apiserver.env</span><br><span class="line">ExecStart=/usr/bin/kube-apiserver \$KUBE_API_ARGS</span><br><span class="line">Restart=on-failure</span><br><span class="line">Type=notify</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt; /etc/kubernetes/kube-apiserver.env</span><br><span class="line">KUBE_API_ARGS=&quot;--advertise-address=192.168.112.128 --allow-privileged=true --authorization-mode=Node,RBAC --client-ca-file=/etc/kubernetes/pki/ca.crt --enable-admission-plugins=NodeRestriction --enable-bootstrap-token-auth=true --etcd-cafile=/etc/kubernetes/pki/etcd/ca.crt --etcd-certfile=/etc/kubernetes/pki/apiserver-etcd-client.crt --etcd-keyfile=/etc/kubernetes/pki/apiserver-etcd-client.key --etcd-servers=https://127.0.0.1:2379 --insecure-port=0 --kubelet-client-certificate=/etc/kubernetes/pki/apiserver-kubelet-client.crt --kubelet-client-key=/etc/kubernetes/pki/apiserver-kubelet-client.key --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.crt --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client.key --requestheader-allowed-names=front-proxy-client --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt --requestheader-extra-headers-prefix=X-Remote-Extra- --requestheader-group-headers=X-Remote-Group --requestheader-username-headers=X-Remote-User --secure-port=6443 --service-account-key-file=/etc/kubernetes/pki/sa.pub --service-cluster-ip-range=10.96.0.0/16 --tls-cert-file=/etc/kubernetes/pki/apiserver.crt --tls-private-key-file=/etc/kubernetes/pki/apiserver.key&quot;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"># 仅在master02上执行</span><br><span class="line">## 配置和启动etcd服务</span><br><span class="line">mkdir -p /etc/etcd/</span><br><span class="line">mkdir -p /var/lib/etcd/</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt; /usr/lib/systemd/system/etcd.service</span><br><span class="line">[Unit]</span><br><span class="line">Description=Etcd Server </span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=simple</span><br><span class="line">WorkingDirectory=/var/lib/etcd/</span><br><span class="line">EnvironmentFile=-/etc/etcd/etcd.env</span><br><span class="line">ExecStart=/usr/bin/etcd \$ETCD_ARGS</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt; /etc/etcd/etcd.env</span><br><span class="line">ETCD_ARGS=&quot;--advertise-client-urls=https://192.168.112.129:2379 --cert-file=/etc/kubernetes/pki/etcd/server.crt --client-cert-auth=true --data-dir=/var/lib/etcd --initial-advertise-peer-urls=https://192.168.112.129:2380 --initial-cluster=master01=https://192.168.112.128:2380,master02=https://192.168.112.129:2380 --initial-cluster-state=existing --key-file=/etc/kubernetes/pki/etcd/server.key --listen-client-urls=https://127.0.0.1:2379,https://192.168.112.129:2379 --listen-metrics-urls=http://127.0.0.1:2381 --listen-peer-urls=https://192.168.112.129:2380 --name=master02 --peer-cert-file=/etc/kubernetes/pki/etcd/peer.crt --peer-client-cert-auth=true --peer-key-file=/etc/kubernetes/pki/etcd/peer.key --peer-trusted-ca-file=/etc/kubernetes/pki/etcd/ca.crt --snapshot-count=10000 --trusted-ca-file=/etc/kubernetes/pki/etcd/ca.crt&quot;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable etcd.service</span><br><span class="line">systemctl start etcd.service</span><br><span class="line">systemctl status etcd.service</span><br><span class="line"></span><br><span class="line">## 配置kube-apiserver服务</span><br><span class="line">cat &lt;&lt;EOF &gt; /usr/lib/systemd/system/kube-apiserver.service</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes API Server</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=etcd.service</span><br><span class="line">Wants=etcd.service</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">EnvironmentFile=-/etc/kubernetes/kube-apiserver.env</span><br><span class="line">ExecStart=/usr/bin/kube-apiserver \$KUBE_API_ARGS</span><br><span class="line">Restart=on-failure</span><br><span class="line">Type=notify</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt; /etc/kubernetes/kube-apiserver.env</span><br><span class="line">KUBE_API_ARGS=&quot;--advertise-address=192.168.112.129 --allow-privileged=true --authorization-mode=Node,RBAC --client-ca-file=/etc/kubernetes/pki/ca.crt --enable-admission-plugins=NodeRestriction --enable-bootstrap-token-auth=true --etcd-cafile=/etc/kubernetes/pki/etcd/ca.crt --etcd-certfile=/etc/kubernetes/pki/apiserver-etcd-client.crt --etcd-keyfile=/etc/kubernetes/pki/apiserver-etcd-client.key --etcd-servers=https://127.0.0.1:2379 --insecure-port=0 --kubelet-client-certificate=/etc/kubernetes/pki/apiserver-kubelet-client.crt --kubelet-client-key=/etc/kubernetes/pki/apiserver-kubelet-client.key --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.crt --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client.key --requestheader-allowed-names=front-proxy-client --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt --requestheader-extra-headers-prefix=X-Remote-Extra- --requestheader-group-headers=X-Remote-Group --requestheader-username-headers=X-Remote-User --secure-port=6443 --service-account-key-file=/etc/kubernetes/pki/sa.pub --service-cluster-ip-range=10.96.0.0/16 --tls-cert-file=/etc/kubernetes/pki/apiserver.crt --tls-private-key-file=/etc/kubernetes/pki/apiserver.key&quot;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 仅在master03上执行</span><br><span class="line">## 配置和启动etcd服务</span><br><span class="line">mkdir -p /etc/etcd/</span><br><span class="line">mkdir -p /var/lib/etcd/</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt; /usr/lib/systemd/system/etcd.service</span><br><span class="line">[Unit]</span><br><span class="line">Description=Etcd Server </span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=simple</span><br><span class="line">WorkingDirectory=/var/lib/etcd/</span><br><span class="line">EnvironmentFile=-/etc/etcd/etcd.env</span><br><span class="line">ExecStart=/usr/bin/etcd \$ETCD_ARGS</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt; /etc/etcd/etcd.env</span><br><span class="line">ETCD_ARGS=&quot;--advertise-client-urls=https://192.168.112.130:2379 --cert-file=/etc/kubernetes/pki/etcd/server.crt --client-cert-auth=true --data-dir=/var/lib/etcd --initial-advertise-peer-urls=https://192.168.112.130:2380 --initial-cluster=master01=https://192.168.112.128:2380,master03=https://192.168.112.130:2380,master02=https://192.168.112.129:2380 --initial-cluster-state=existing --key-file=/etc/kubernetes/pki/etcd/server.key --listen-client-urls=https://127.0.0.1:2379,https://192.168.112.130:2379 --listen-metrics-urls=http://127.0.0.1:2381 --listen-peer-urls=https://192.168.112.130:2380 --name=master03 --peer-cert-file=/etc/kubernetes/pki/etcd/peer.crt --peer-client-cert-auth=true --peer-key-file=/etc/kubernetes/pki/etcd/peer.key --peer-trusted-ca-file=/etc/kubernetes/pki/etcd/ca.crt --snapshot-count=10000 --trusted-ca-file=/etc/kubernetes/pki/etcd/ca.crt&quot;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable etcd.service</span><br><span class="line">systemctl start etcd.service</span><br><span class="line">systemctl status etcd.service</span><br><span class="line"></span><br><span class="line">## 配置kube-apiserver服务</span><br><span class="line">cat &lt;&lt;EOF &gt; /usr/lib/systemd/system/kube-apiserver.service</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes API Server</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=etcd.service</span><br><span class="line">Wants=etcd.service</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">EnvironmentFile=-/etc/kubernetes/kube-apiserver.env</span><br><span class="line">ExecStart=/usr/bin/kube-apiserver \$KUBE_API_ARGS</span><br><span class="line">Restart=on-failure</span><br><span class="line">Type=notify</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt; /etc/kubernetes/kube-apiserver.env</span><br><span class="line">KUBE_API_ARGS=&quot;--advertise-address=192.168.112.130 --allow-privileged=true --authorization-mode=Node,RBAC --client-ca-file=/etc/kubernetes/pki/ca.crt --enable-admission-plugins=NodeRestriction --enable-bootstrap-token-auth=true --etcd-cafile=/etc/kubernetes/pki/etcd/ca.crt --etcd-certfile=/etc/kubernetes/pki/apiserver-etcd-client.crt --etcd-keyfile=/etc/kubernetes/pki/apiserver-etcd-client.key --etcd-servers=https://127.0.0.1:2379 --insecure-port=0 --kubelet-client-certificate=/etc/kubernetes/pki/apiserver-kubelet-client.crt --kubelet-client-key=/etc/kubernetes/pki/apiserver-kubelet-client.key --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.crt --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client.key --requestheader-allowed-names=front-proxy-client --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt --requestheader-extra-headers-prefix=X-Remote-Extra- --requestheader-group-headers=X-Remote-Group --requestheader-username-headers=X-Remote-User --secure-port=6443 --service-account-key-file=/etc/kubernetes/pki/sa.pub --service-cluster-ip-range=10.96.0.0/16 --tls-cert-file=/etc/kubernetes/pki/apiserver.crt --tls-private-key-file=/etc/kubernetes/pki/apiserver.key&quot;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 分别在master01、master02和master03上执行</span><br><span class="line"></span><br><span class="line">## 启动kube-apiserver服务</span><br><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable kube-apiserver.service</span><br><span class="line">systemctl start kube-apiserver.service</span><br><span class="line">systemctl status kube-apiserver.service</span><br><span class="line"></span><br><span class="line">## 配置和启动kube-controller-manager服务</span><br><span class="line">cat &lt;&lt;EOF &gt; /usr/lib/systemd/system/kube-controller-manager.service</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Controller Manager</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=kube-apiserver.service</span><br><span class="line">Requires=kube-apiserver.service</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">EnvironmentFile=-/etc/kubernetes/kube-controller-manager.env</span><br><span class="line">ExecStart=/usr/bin/kube-controller-manager \$KUBE_CONTROLLER_MANAGER_ARGS</span><br><span class="line">Restart=on-failure</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt; /etc/kubernetes/kube-controller-manager.env</span><br><span class="line">KUBE_CONTROLLER_MANAGER_ARGS=&quot;--allocate-node-cidrs=true --authentication-kubeconfig=/etc/kubernetes/controller-manager.conf --authorization-kubeconfig=/etc/kubernetes/controller-manager.conf --bind-address=127.0.0.1 --client-ca-file=/etc/kubernetes/pki/ca.crt --cluster-cidr=10.211.0.0/16 --cluster-signing-cert-file=/etc/kubernetes/pki/ca.crt --cluster-signing-key-file=/etc/kubernetes/pki/ca.key --controllers=*,bootstrapsigner,tokencleaner --kubeconfig=/etc/kubernetes/controller-manager.conf --leader-elect=true --node-cidr-mask-size=24 --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt --root-ca-file=/etc/kubernetes/pki/ca.crt --service-account-private-key-file=/etc/kubernetes/pki/sa.key --service-cluster-ip-range=10.96.0.0/16 --use-service-account-credentials=true&quot;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable kube-controller-manager.service</span><br><span class="line">systemctl start kube-controller-manager.service</span><br><span class="line">systemctl status kube-controller-manager.service</span><br><span class="line"></span><br><span class="line">## 配置和启动kube-scheduler服务</span><br><span class="line">cat &lt;&lt;EOF &gt; /usr/lib/systemd/system/kube-scheduler.service</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Scheduler</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=kube-apiserver.service</span><br><span class="line">Requires=kube-apiserver.service</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">EnvironmentFile=-/etc/kubernetes/kube-scheduler.env</span><br><span class="line">ExecStart=/usr/bin/kube-scheduler \$KUBE_SCHEDULER_ARGS</span><br><span class="line">Restart=on-failure</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt; /etc/kubernetes/kube-scheduler.env</span><br><span class="line">KUBE_SCHEDULER_ARGS=&quot; --authentication-kubeconfig=/etc/kubernetes/scheduler.conf --authorization-kubeconfig=/etc/kubernetes/scheduler.conf --bind-address=127.0.0.1 --kubeconfig=/etc/kubernetes/scheduler.conf --leader-elect=true&quot;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable kube-scheduler.service</span><br><span class="line">systemctl start kube-scheduler.service</span><br><span class="line">systemctl status kube-scheduler.service</span><br></pre></td></tr></table></figure>
<h2 id="8-集群中配置启用Bootstrap-Token"><a href="#8-集群中配置启用Bootstrap-Token" class="headerlink" title="8. 集群中配置启用Bootstrap Token"></a>8. 集群中配置启用Bootstrap Token</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"># 仅在master01上执行</span><br><span class="line">## 注意：expiration必须要在当前日期以后，否则会出现token创建后，kubernetes就会自动删除</span><br><span class="line">export KUBECONFIG=/etc/kubernetes/admin.conf</span><br><span class="line">cat &lt;&lt;EOF &gt; /etc/kubernetes/bootstrap-token-abcdef.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Secret</span><br><span class="line">metadata:</span><br><span class="line">  name: bootstrap-token-abcdef</span><br><span class="line">  namespace: kube-system</span><br><span class="line">type: bootstrap.kubernetes.io/token</span><br><span class="line">stringData:</span><br><span class="line">  auth-extra-groups: system:bootstrappers:default-node-token</span><br><span class="line">  expiration: 2020-12-31T00:00:00+08:00</span><br><span class="line">  token-id: abcdef</span><br><span class="line">  token-secret: 0123456789abcdef</span><br><span class="line">  usage-bootstrap-authentication: &quot;true&quot;</span><br><span class="line">  usage-bootstrap-signing: &quot;true&quot;</span><br><span class="line">EOF</span><br><span class="line">kubectl create -f /etc/kubernetes/bootstrap-token-abcdef.yaml</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt; /etc/kubernetes/create-csrs-for-bootstrapping.yaml</span><br><span class="line"># enable bootstrapping nodes to create CSR</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: create-csrs-for-bootstrapping</span><br><span class="line">subjects:</span><br><span class="line">- kind: Group</span><br><span class="line">  name: system:bootstrappers</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">roleRef:</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: system:node-bootstrapper</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">EOF</span><br><span class="line">kubectl create -f /etc/kubernetes/create-csrs-for-bootstrapping.yaml</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt; /etc/kubernetes/auto-approve-csrs-for-group.yaml</span><br><span class="line"># Approve all CSRs for the group &quot;system:bootstrappers&quot;</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: auto-approve-csrs-for-group</span><br><span class="line">subjects:</span><br><span class="line">- kind: Group</span><br><span class="line">  name: system:bootstrappers</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">roleRef:</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: system:certificates.k8s.io:certificatesigningrequests:nodeclient</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">EOF</span><br><span class="line">kubectl create -f /etc/kubernetes/auto-approve-csrs-for-group.yaml</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt; /etc/kubernetes/auto-approve-renewals-for-nodes.yaml</span><br><span class="line"># Approve renewal CSRs for the group &quot;system:nodes&quot;</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: auto-approve-renewals-for-nodes</span><br><span class="line">subjects:</span><br><span class="line">- kind: Group</span><br><span class="line">  name: system:nodes</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">roleRef:</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: system:certificates.k8s.io:certificatesigningrequests:selfnodeclient</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">EOF</span><br><span class="line">kubectl create -f /etc/kubernetes/auto-approve-renewals-for-nodes.yaml</span><br></pre></td></tr></table></figure>
<h2 id="9-分发bootstrap-kubelet-conf和proxy-conf到所有Master和Node上"><a href="#9-分发bootstrap-kubelet-conf和proxy-conf到所有Master和Node上" class="headerlink" title="9. 分发bootstrap-kubelet.conf和proxy.conf到所有Master和Node上"></a>9. 分发bootstrap-kubelet.conf和proxy.conf到所有Master和Node上</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"># 在master01上执行</span><br><span class="line"># 配置master01到master02和master03的ssh免密登录</span><br><span class="line">ssh-keygen</span><br><span class="line">ssh-copy-id -i .ssh/id_rsa.pub root@node01</span><br><span class="line">ssh-copy-id -i .ssh/id_rsa.pub root@node02</span><br><span class="line"></span><br><span class="line">## 验证master01到node01和node02的ssh免密登录</span><br><span class="line">ssh node01</span><br><span class="line">ssh node02</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt; kubernetes-node-transfer.sh</span><br><span class="line">USER=root</span><br><span class="line">CONTROL_PLANE_IPS=&quot;192.168.112.129 192.168.112.130 192.168.112.131 192.168.112.132&quot;</span><br><span class="line">for host in \$&#123;CONTROL_PLANE_IPS&#125;; do</span><br><span class="line">    scp /etc/kubernetes/pki/ca.crt \$&#123;USER&#125;@\$host:/etc/kubernetes/pki/</span><br><span class="line">    scp /etc/kubernetes/bootstrap-kubelet.conf \$&#123;USER&#125;@\$host:/etc/kubernetes/</span><br><span class="line">    scp /etc/kubernetes/proxy.conf \$&#123;USER&#125;@\$host:/etc/kubernetes/</span><br><span class="line">done</span><br><span class="line">EOF</span><br><span class="line">chmod 0755 kubernetes-node-transfer.sh</span><br><span class="line">./kubernetes-node-transfer.sh</span><br></pre></td></tr></table></figure>
<h2 id="8-在所有Node上，分别配置和启动所有组件"><a href="#8-在所有Node上，分别配置和启动所有组件" class="headerlink" title="8. 在所有Node上，分别配置和启动所有组件"></a>8. 在所有Node上，分别配置和启动所有组件</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br></pre></td><td class="code"><pre><span class="line"># 在node01和node02上执行，如果master01、master02和master03也需要具备Node的功能，那么其上也需要执行</span><br><span class="line">## 创建配置目录和工作目录</span><br><span class="line">mkdir -p /etc/kubernetes/manifests</span><br><span class="line">mkdir -p /etc/kubernetes/pki/</span><br><span class="line">mkdir -p /var/lib/kubelet/</span><br><span class="line">mkdir -p /var/lib/kube-proxy/</span><br><span class="line"></span><br><span class="line">## 创建kubelet的配置文件</span><br><span class="line">cat &lt;&lt;EOF &gt; /var/lib/kubelet/config.yaml</span><br><span class="line">apiVersion: kubelet.config.k8s.io/v1beta1</span><br><span class="line">authentication:</span><br><span class="line">  anonymous:</span><br><span class="line">    enabled: true</span><br><span class="line">  webhook:</span><br><span class="line">    cacheTTL: 0s</span><br><span class="line">    enabled: true</span><br><span class="line">  x509:</span><br><span class="line">    clientCAFile: /etc/kubernetes/pki/ca.crt</span><br><span class="line">authorization:</span><br><span class="line">  mode: Webhook</span><br><span class="line">  webhook:</span><br><span class="line">    cacheAuthorizedTTL: 0s</span><br><span class="line">    cacheUnauthorizedTTL: 0s</span><br><span class="line">clusterDNS:</span><br><span class="line">- 10.96.0.10</span><br><span class="line">clusterDomain: cluster.local</span><br><span class="line">cpuManagerReconcilePeriod: 0s</span><br><span class="line">evictionPressureTransitionPeriod: 0s</span><br><span class="line">fileCheckFrequency: 0s</span><br><span class="line">healthzBindAddress: 127.0.0.1</span><br><span class="line">healthzPort: 10248</span><br><span class="line">httpCheckFrequency: 0s</span><br><span class="line">imageMinimumGCAge: 0s</span><br><span class="line">kind: KubeletConfiguration</span><br><span class="line">nodeStatusReportFrequency: 0s</span><br><span class="line">nodeStatusUpdateFrequency: 0s</span><br><span class="line">rotateCertificates: true</span><br><span class="line">runtimeRequestTimeout: 0s</span><br><span class="line">staticPodPath: /etc/kubernetes/manifests</span><br><span class="line">streamingConnectionIdleTimeout: 0s</span><br><span class="line">syncFrequency: 0s</span><br><span class="line">volumeStatsAggPeriod: 0s</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">## 配置和启动kubelet服务</span><br><span class="line">cat &lt;&lt;EOF &gt; /usr/lib/systemd/system/kubelet.service</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Kubelet Server</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=docker.service</span><br><span class="line">Requires=docker.service</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">WorkingDirectory=/var/lib/kubelet</span><br><span class="line">EnvironmentFile=-/etc/kubernetes/kubelet.env</span><br><span class="line">ExecStart=/usr/bin/kubelet \$KUBELET_ARGS</span><br><span class="line">Restart=on-failure</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt; /etc/kubernetes/kubelet.env</span><br><span class="line">KUBELET_ARGS=&quot;--bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubernetes/kubelet.conf --config=/var/lib/kubelet/config.yaml --cgroup-driver=systemd --network-plugin=cni --pod-infra-container-image=registry.cn-hangzhou.aliyuncs.com/google_containers/pause-amd64:3.1&quot;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable kubelet.service</span><br><span class="line">systemctl start kubelet.service</span><br><span class="line">systemctl status kubelet.service</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">## 创建kube-proxy的配置文件</span><br><span class="line">cat &lt;&lt;EOF &gt; /var/lib/kube-proxy/config.conf</span><br><span class="line">apiVersion: kubeproxy.config.k8s.io/v1alpha1</span><br><span class="line">bindAddress: 0.0.0.0</span><br><span class="line">clientConnection:</span><br><span class="line">  acceptContentTypes: &quot;&quot;</span><br><span class="line">  burst: 0</span><br><span class="line">  contentType: &quot;&quot;</span><br><span class="line">  kubeconfig: /etc/kubernetes/proxy.conf</span><br><span class="line">  qps: 0</span><br><span class="line">clusterCIDR: 10.211.0.0/16</span><br><span class="line">configSyncPeriod: 0s</span><br><span class="line">conntrack:</span><br><span class="line">  maxPerCore: null</span><br><span class="line">  min: null</span><br><span class="line">  tcpCloseWaitTimeout: null</span><br><span class="line">  tcpEstablishedTimeout: null</span><br><span class="line">enableProfiling: false</span><br><span class="line">healthzBindAddress: &quot;&quot;</span><br><span class="line">hostnameOverride: &quot;&quot;</span><br><span class="line">iptables:</span><br><span class="line">  masqueradeAll: false</span><br><span class="line">  masqueradeBit: null</span><br><span class="line">  minSyncPeriod: 0s</span><br><span class="line">  syncPeriod: 0s</span><br><span class="line">ipvs:</span><br><span class="line">  excludeCIDRs: null</span><br><span class="line">  minSyncPeriod: 0s</span><br><span class="line">  scheduler: &quot;&quot;</span><br><span class="line">  strictARP: false</span><br><span class="line">  syncPeriod: 0s</span><br><span class="line">kind: KubeProxyConfiguration</span><br><span class="line">metricsBindAddress: &quot;&quot;</span><br><span class="line">mode: &quot;&quot;</span><br><span class="line">nodePortAddresses: null</span><br><span class="line">oomScoreAdj: null</span><br><span class="line">portRange: &quot;&quot;</span><br><span class="line">udpIdleTimeout: 0s</span><br><span class="line">winkernel:</span><br><span class="line">  enableDSR: false</span><br><span class="line">  networkName: &quot;&quot;</span><br><span class="line">  sourceVip: &quot;&quot;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">## 配置和启动kube-proxy服务</span><br><span class="line">cat &lt;&lt;EOF &gt; /usr/lib/systemd/system/kube-proxy.service</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Proxy Server</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=network.target</span><br><span class="line">Requires=network.service</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">EnvironmentFile=-/etc/kubernetes/kube-proxy.env</span><br><span class="line">ExecStart=/usr/bin/kube-proxy \$KUBE_PROXY_ARGS</span><br><span class="line">Restart=on-failure</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt; /etc/kubernetes/kube-proxy.env</span><br><span class="line">KUBE_PROXY_ARGS=&quot;--config=/var/lib/kube-proxy/config.conf --hostname-override=node01&quot;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">yum install -y conntrack</span><br><span class="line"></span><br><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable kube-proxy.service</span><br><span class="line">systemctl start kube-proxy.service</span><br><span class="line">systemctl status kube-proxy.service</span><br></pre></td></tr></table></figure>
<h2 id="9-让master01、master02和master03节点具备Node节点的功能"><a href="#9-让master01、master02和master03节点具备Node节点的功能" class="headerlink" title="9. 让master01、master02和master03节点具备Node节点的功能"></a>9. 让master01、master02和master03节点具备Node节点的功能</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">## 如果master01、master02和master03节点需要具备node节点的功能，需要参考8中的步骤，先分别在master01、master02和master03节点上完成kubelet和kube-proxy的安装后，再分别给master01、master02和master03节点打上下面的标签和污点</span><br><span class="line">kubectl label node master01 node-role.kubernetes.io/master=</span><br><span class="line">kubectl taint node master01 node-role.kubernetes.io/master=:NoSchedule</span><br><span class="line"></span><br><span class="line">kubectl label node master02 node-role.kubernetes.io/master=</span><br><span class="line">kubectl taint node master02 node-role.kubernetes.io/master=:NoSchedule</span><br><span class="line"></span><br><span class="line">kubectl label node master03 node-role.kubernetes.io/master=</span><br><span class="line">kubectl taint node master03 node-role.kubernetes.io/master=:NoSchedule</span><br></pre></td></tr></table></figure>
<h2 id="10-配置和安装网络插件（calico和core-dns）"><a href="#10-配置和安装网络插件（calico和core-dns）" class="headerlink" title="10. 配置和安装网络插件（calico和core-dns）"></a>10. 配置和安装网络插件（calico和core-dns）</h2><p>请参考单点二进制Kubernetes集群的配置和安装方法，这里不再赘述。</p>
<h2 id="11-确认集群各组件的健康状况"><a href="#11-确认集群各组件的健康状况" class="headerlink" title="11. 确认集群各组件的健康状况"></a>11. 确认集群各组件的健康状况</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"># 确认etcd的健康状况</span><br><span class="line">etcdctl --endpoints=https://127.0.0.1:2379 --cacert=/etc/kubernetes/pki/etcd/ca.crt --cert=/etc/kubernetes/pki/etcd/server.crt --key=/etc/kubernetes/pki/etcd/server.key member list</span><br><span class="line">------------------------------------------------------------------------------------------------------------------------------------------------</span><br><span class="line">70b95c7dc2a3de1e, started, master03, https://192.168.112.130:2380, https://192.168.112.130:2379, false</span><br><span class="line">71611ba7f1e4ff79, started, master02, https://192.168.112.129:2380, https://192.168.112.129:2379, false</span><br><span class="line">ade36780a0899522, started, master01, https://192.168.112.128:2380, https://192.168.112.128:2379, false</span><br><span class="line">------------------------------------------------------------------------------------------------------------------------------------------------</span><br><span class="line"></span><br><span class="line"># 确认所有节点（Master和Node）的健康状况</span><br><span class="line">kubectl get node -o wide</span><br><span class="line">------------------------------------------------------------------------------------------------------------------------------------------------</span><br><span class="line">NAME       STATUS   ROLES    AGE    VERSION   INTERNAL-IP       EXTERNAL-IP   OS-IMAGE                KERNEL-VERSION                CONTAINER-RUNTIME</span><br><span class="line">master01   Ready    master   130m   v1.17.0   192.168.112.128   &lt;none&gt;        CentOS Linux 7 (Core)   3.10.0-1062.12.1.el7.x86_64   docker://18.9.9</span><br><span class="line">master02   Ready    master   130m   v1.17.0   192.168.112.129   &lt;none&gt;        CentOS Linux 7 (Core)   3.10.0-1062.12.1.el7.x86_64   docker://18.9.9</span><br><span class="line">master03   Ready    master   130m   v1.17.0   192.168.112.130   &lt;none&gt;        CentOS Linux 7 (Core)   3.10.0-957.21.3.el7.x86_64    docker://18.9.9</span><br><span class="line">------------------------------------------------------------------------------------------------------------------------------------------------</span><br><span class="line"></span><br><span class="line"># 确认calico和core dns的运行状况</span><br><span class="line">kubectl get pod --all-namespaces -o wide</span><br><span class="line">------------------------------------------------------------------------------------------------------------------------------------------------</span><br><span class="line">NAMESPACE     NAME                                       READY   STATUS    RESTARTS   AGE    IP                NODE       NOMINATED NODE   READINESS GATES</span><br><span class="line">kube-system   calico-kube-controllers-648f4868b8-ldgrw   1/1     Running   1          121m   10.211.241.66     master01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   calico-node-2dtf2                          1/1     Running   0          121m   192.168.112.130   master03   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   calico-node-2z8nv                          1/1     Running   1          121m   192.168.112.128   master01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   calico-node-tvs2j                          1/1     Running   1          121m   192.168.112.129   master02   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   coredns-7f9c544f75-s26rt                   1/1     Running   1          115m   10.211.59.194     master02   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   coredns-7f9c544f75-zfst9                   1/1     Running   0          115m   10.211.235.1      master03   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">------------------------------------------------------------------------------------------------------------------------------------------------</span><br></pre></td></tr></table></figure>
<h2 id="12-为高可用集群添加两个Node"><a href="#12-为高可用集群添加两个Node" class="headerlink" title="12. 为高可用集群添加两个Node"></a>12. 为高可用集群添加两个Node</h2><p>因高可用二进制Kubernetes集群添加Node的方法与单点二进制Kubernetes集群添加Node的方法完全一直，故请参考单点二进制Kubernetes集群的添加Node方法。</p>
<h1 id="五、参考资料"><a href="#五、参考资料" class="headerlink" title="五、参考资料"></a>五、参考资料</h1><h2 id="1-官方资料（官方最新版本v1-17）"><a href="#1-官方资料（官方最新版本v1-17）" class="headerlink" title="1. 官方资料（官方最新版本v1.17）"></a>1. 官方资料（官方最新版本v1.17）</h2><p><a href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/ha-topology/" target="_blank" rel="noopener">https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/ha-topology/</a><br><a href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/high-availability/" target="_blank" rel="noopener">https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/high-availability/</a></p>
<h2 id="2-第三方资料（因Kubernetes-从v1-15开始到v1-17，kubeadm的安装方式和二进制安装方式基本相同，故v1-15的资料可以供v1-17参考）"><a href="#2-第三方资料（因Kubernetes-从v1-15开始到v1-17，kubeadm的安装方式和二进制安装方式基本相同，故v1-15的资料可以供v1-17参考）" class="headerlink" title="2. 第三方资料（因Kubernetes 从v1.15开始到v1.17，kubeadm的安装方式和二进制安装方式基本相同，故v1.15的资料可以供v1.17参考）"></a>2. 第三方资料（因Kubernetes 从v1.15开始到v1.17，kubeadm的安装方式和二进制安装方式基本相同，故v1.15的资料可以供v1.17参考）</h2><p><a href="https://www.cnblogs.com/lingfenglian/p/11753590.html" target="_blank" rel="noopener">https://www.cnblogs.com/lingfenglian/p/11753590.html</a><br><a href="https://blog.51cto.com/fengwan/2426528?source=dra" target="_blank" rel="noopener">https://blog.51cto.com/fengwan/2426528?source=dra</a><br><a href="https://my.oschina.net/beyondken/blog/1935402" target="_blank" rel="noopener">https://my.oschina.net/beyondken/blog/1935402</a><br><a href="https://www.cnblogs.com/shenlinken/p/9968274.html" target="_blank" rel="noopener">https://www.cnblogs.com/shenlinken/p/9968274.html</a> </p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Docker/">Docker</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Highly-Available/">Highly Available</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Kubernetes/">Kubernetes</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Setup/">Setup</a></li></ul>
	</div>

      
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/容器云技术/">容器云技术</a>
	</div>


      
      <div class="clearfix"></div>
    </div>
      
    
  </div>
  
</article>







  
    <article id="post-kubeadm_ha_clusters_001" class="article article-type-post" itemscope="" itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2020/03/15/kubeadm_ha_clusters_001/" class="article-date">
  	<time datetime="2020-03-15T01:13:30.383Z" itemprop="datePublished">2020-03-15</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/03/15/kubeadm_ha_clusters_001/">
        使用Kubeadm安装高可用Kubernetes v1.17.0集群（Stacked Control Plane Nodes For Baremetal）
        
      </a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="一、高可用部署的实现方式介绍"><a href="#一、高可用部署的实现方式介绍" class="headerlink" title="一、高可用部署的实现方式介绍"></a>一、高可用部署的实现方式介绍</h1><p>官方文档介绍了使用Kbeadm设置高可用性Kubernetes集群的两种不同方法：</p>
<h2 id="1-堆叠master的方式（with-stacked-masters）"><a href="#1-堆叠master的方式（with-stacked-masters）" class="headerlink" title="1. 堆叠master的方式（with stacked masters）"></a>1. 堆叠master的方式（with stacked masters）</h2><p>这种方法需要较少的基础设施。控制平面节点和etcd成员位于同一位置。</p>
<h2 id="2-使用外部etcd集群的方式（with-an-external-etcd-cluster）"><a href="#2-使用外部etcd集群的方式（with-an-external-etcd-cluster）" class="headerlink" title="2. 使用外部etcd集群的方式（with an external etcd cluster）"></a>2. 使用外部etcd集群的方式（with an external etcd cluster）</h2><p>这种方法需要更多的基础设施。控制平面节点和etcd成员是分开的。<br>这里重点介绍第一种方式，即堆叠master的方式。官方文档链接详见参考资料。</p>
<h1 id="二、实验环境版本信息"><a href="#二、实验环境版本信息" class="headerlink" title="二、实验环境版本信息"></a>二、实验环境版本信息</h1><h2 id="1-高可用工具的版本（这里记录的是docker镜像的版本）"><a href="#1-高可用工具的版本（这里记录的是docker镜像的版本）" class="headerlink" title="1. 高可用工具的版本（这里记录的是docker镜像的版本）"></a>1. 高可用工具的版本（这里记录的是docker镜像的版本）</h2><p>haproxy:1.7-alpine<br>osixia/keepalived:1.4.5</p>
<h2 id="2-Kubernetes各个组件的版本"><a href="#2-Kubernetes各个组件的版本" class="headerlink" title="2. Kubernetes各个组件的版本"></a>2. Kubernetes各个组件的版本</h2><p>etcd v3.4.3<br>kube-apiserver v1.17.0<br>kube-controller-manager v1.17.0<br>kube-scheduler v1.17.0<br>kubectl v1.17.0<br>coredns 1.6.5</p>
<p>docker 18.09.9<br>kube-proxy v1.17.0<br>kubelet v1.17.0<br>calico v3.11.1 （calico/node:v3.11.1 calico/pod2daemon-flexvol:v3.11.1 calico/cni:v3.11.1 calico/kube-controllers:v3.11.1）</p>
<h1 id="三、部署架构介绍"><a href="#三、部署架构介绍" class="headerlink" title="三、部署架构介绍"></a>三、部署架构介绍</h1><p><img src="/2020/03/15/kubeadm_ha_clusters_001/stacked_etcd_topology.png" alt="stacked_etcd_topology"></p>
<h2 id="1-Kubernetes-Master（Control-Plane）"><a href="#1-Kubernetes-Master（Control-Plane）" class="headerlink" title="1. Kubernetes Master（Control Plane）"></a>1. Kubernetes Master（Control Plane）</h2><p>192.168.112.128 master01 -&gt; docker kubelet keepalived haproxy etcd kube-apiserver kube-controller-manager kube-scheduler kube-proxy calico<br>192.168.112.129 master02 -&gt; docker kubelet keepalived haproxy etcd kube-apiserver kube-controller-manager kube-scheduler kube-proxy calico<br>192.168.112.130 master03 -&gt; docker kubelet keepalived haproxy etcd kube-apiserver kube-controller-manager kube-scheduler kube-proxy calico</p>
<h2 id="2-Kubernetes-Node"><a href="#2-Kubernetes-Node" class="headerlink" title="2. Kubernetes Node"></a>2. Kubernetes Node</h2><p>192.168.112.131 node01 -&gt; docker kubelet kube-proxy calico（calico-node）<br>192.168.112.132 node02 -&gt; docker kubelet kube-proxy calico（calico-node）</p>
<h1 id="四、实现过程记录"><a href="#四、实现过程记录" class="headerlink" title="四、实现过程记录"></a>四、实现过程记录</h1><h2 id="1-在Kubernetes-Control-Plane上的所有Node上部署HAProxy做为负载均衡器（由Kubelet管理以静态Pod的方式实现）"><a href="#1-在Kubernetes-Control-Plane上的所有Node上部署HAProxy做为负载均衡器（由Kubelet管理以静态Pod的方式实现）" class="headerlink" title="1. 在Kubernetes Control Plane上的所有Node上部署HAProxy做为负载均衡器（由Kubelet管理以静态Pod的方式实现）"></a>1. 在Kubernetes Control Plane上的所有Node上部署HAProxy做为负载均衡器（由Kubelet管理以静态Pod的方式实现）</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line">## 在控制平面的所有Node上执行</span><br><span class="line">mkdir -p /etc/haproxy/</span><br><span class="line">cat &lt;&lt;EOF &gt; /etc/haproxy/haproxy.cfg</span><br><span class="line">global</span><br><span class="line">  log 127.0.0.1 local0 err</span><br><span class="line">  maxconn 50000</span><br><span class="line">  uid 99</span><br><span class="line">  gid 99</span><br><span class="line">  #daemon</span><br><span class="line">  nbproc 1</span><br><span class="line">  pidfile haproxy.pid</span><br><span class="line"></span><br><span class="line">defaults</span><br><span class="line">  mode tcp</span><br><span class="line">  log 127.0.0.1 local0 err</span><br><span class="line">  maxconn 50000</span><br><span class="line">  retries 3</span><br><span class="line">  timeout connect 10s</span><br><span class="line">  timeout client 10m</span><br><span class="line">  timeout server 10m</span><br><span class="line"></span><br><span class="line">listen stats</span><br><span class="line">  mode http</span><br><span class="line">  bind 0.0.0.0:9090</span><br><span class="line">  log 127.0.0.1 local0 err</span><br><span class="line">  stats refresh 30s</span><br><span class="line">  stats uri     /haproxy-status</span><br><span class="line">  stats realm   Haproxy\ Statistics</span><br><span class="line">  stats auth    admin:12345678</span><br><span class="line">  stats hide-version</span><br><span class="line">  stats admin if TRUE</span><br><span class="line"></span><br><span class="line">frontend kube-apiserver-https</span><br><span class="line">   mode tcp</span><br><span class="line">   bind :8443</span><br><span class="line">   default_backend kube-apiserver-backend</span><br><span class="line"></span><br><span class="line">backend kube-apiserver-backend</span><br><span class="line">    mode tcp</span><br><span class="line">    balance roundrobin</span><br><span class="line">    server server01 192.168.112.128:6443 weight 3 minconn 100 maxconn 50000 check inter 5000 rise 2 fall 5</span><br><span class="line">    server server02 192.168.112.129:6443 weight 3 minconn 100 maxconn 50000 check inter 5000 rise 2 fall 5</span><br><span class="line">    server server03 192.168.112.130:6443 weight 3 minconn 100 maxconn 50000 check inter 5000 rise 2 fall 5</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">## 仅在master01上执行</span><br><span class="line">mkdir -p /etc/kubernetes/manifests/</span><br><span class="line"></span><br><span class="line">## 在master01上需要先执行，在master02和master03上需先做完kubeadm join后再执行</span><br><span class="line">cat &lt;&lt;EOF &gt; /etc/kubernetes/manifests/haproxy.yaml</span><br><span class="line">kind: Pod</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    scheduler.alpha.kubernetes.io/critical-pod: &quot;&quot;</span><br><span class="line">  labels:</span><br><span class="line">    component: haproxy</span><br><span class="line">    tier: control-plane</span><br><span class="line">  name: kube-haproxy</span><br><span class="line">  namespace: kube-system</span><br><span class="line">spec:</span><br><span class="line">  hostNetwork: true</span><br><span class="line">  containers:</span><br><span class="line">  - name: kube-haproxy</span><br><span class="line">    image: haproxy:1.7-alpine</span><br><span class="line">    resources:</span><br><span class="line">      requests:</span><br><span class="line">        cpu: 100m</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - name: haproxy-cfg</span><br><span class="line">      readOnly: true</span><br><span class="line">      mountPath: /usr/local/etc/haproxy/haproxy.cfg</span><br><span class="line">  volumes:</span><br><span class="line">  - name: haproxy-cfg</span><br><span class="line">    hostPath:</span><br><span class="line">      path: /etc/haproxy/haproxy.cfg</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>
<h2 id="2-在Kubernetes-Control-Plane的所有Node上部署Keepalived（由Kubelet管理以静态Pod的方式实现）"><a href="#2-在Kubernetes-Control-Plane的所有Node上部署Keepalived（由Kubelet管理以静态Pod的方式实现）" class="headerlink" title="2. 在Kubernetes Control Plane的所有Node上部署Keepalived（由Kubelet管理以静态Pod的方式实现）"></a>2. 在Kubernetes Control Plane的所有Node上部署Keepalived（由Kubelet管理以静态Pod的方式实现）</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">## 仅在master01上执行</span><br><span class="line">mkdir -p /etc/kubernetes/manifests/</span><br><span class="line"></span><br><span class="line">## 在master01上需要在kubeadm init前先执行，在master02和master03上需先做完kubeadm join后再执行</span><br><span class="line">cat &lt;&lt;EOF &gt; /etc/kubernetes/manifests/keepalived.yaml</span><br><span class="line">kind: Pod</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    scheduler.alpha.kubernetes.io/critical-pod: &quot;&quot;</span><br><span class="line">  labels:</span><br><span class="line">    component: keepalived</span><br><span class="line">    tier: control-plane</span><br><span class="line">  name: kube-keepalived</span><br><span class="line">  namespace: kube-system</span><br><span class="line">spec:</span><br><span class="line">  hostNetwork: true</span><br><span class="line">  containers:</span><br><span class="line">  - name: kube-keepalived</span><br><span class="line">    image: osixia/keepalived:1.4.5</span><br><span class="line">    env:</span><br><span class="line">    - name: KEEPALIVED_VIRTUAL_IPS</span><br><span class="line">      value: 192.168.112.136</span><br><span class="line">    - name: KEEPALIVED_INTERFACE</span><br><span class="line">      value: ens33</span><br><span class="line">    - name: KEEPALIVED_UNICAST_PEERS</span><br><span class="line">      value: &quot;#PYTHON2BASH:[&apos;192.168.112.128&apos;, &apos;192.168.112.129&apos;, &apos;192.168.112.130&apos;]&quot;</span><br><span class="line">    - name: KEEPALIVED_PASSWORD</span><br><span class="line">      value: docker</span><br><span class="line">    - name: KEEPALIVED_PRIORITY</span><br><span class="line">      value: &quot;200&quot;</span><br><span class="line">    - name: KEEPALIVED_ROUTER_ID</span><br><span class="line">      value: &quot;51&quot;</span><br><span class="line">    resources:</span><br><span class="line">      requests:</span><br><span class="line">        cpu: 100m</span><br><span class="line">    securityContext:</span><br><span class="line">      privileged: true</span><br><span class="line">      capabilities:</span><br><span class="line">        add:</span><br><span class="line">        - NET_ADMIN</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>
<h2 id="3-在Kubernetes-Control-Plane-的第一个Node（master01）上操作："><a href="#3-在Kubernetes-Control-Plane-的第一个Node（master01）上操作：" class="headerlink" title="3. 在Kubernetes Control Plane 的第一个Node（master01）上操作："></a>3. 在Kubernetes Control Plane 的第一个Node（master01）上操作：</h2><p>（1）生成kubeadm配置文件，并拉取相关的docker镜像<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line">## 生成Kubeadm初始化需要使用的配置文件</span><br><span class="line">mkdir -p kubeadm/config/</span><br><span class="line">cat &lt;&lt;EOF &gt; kubeadm/config/kubeadm-config.yaml</span><br><span class="line">apiVersion: kubeadm.k8s.io/v1beta2</span><br><span class="line">bootstrapTokens:</span><br><span class="line">- groups:</span><br><span class="line">  - system:bootstrappers:kubeadm:default-node-token</span><br><span class="line">  token: abcdef.0123456789abcdef</span><br><span class="line">  ttl: 24h0m0s</span><br><span class="line">  usages:</span><br><span class="line">  - signing</span><br><span class="line">  - authentication</span><br><span class="line">kind: InitConfiguration</span><br><span class="line">localAPIEndpoint:</span><br><span class="line">  advertiseAddress: 192.168.112.128</span><br><span class="line">  bindPort: 6443</span><br><span class="line">nodeRegistration:</span><br><span class="line">  criSocket: /var/run/dockershim.sock</span><br><span class="line">  name: master01</span><br><span class="line">  taints:</span><br><span class="line">  - effect: NoSchedule</span><br><span class="line">    key: node-role.kubernetes.io/master</span><br><span class="line">---</span><br><span class="line">apiServer:</span><br><span class="line">  timeoutForControlPlane: 4m0s</span><br><span class="line">apiVersion: kubeadm.k8s.io/v1beta2</span><br><span class="line">certificatesDir: /etc/kubernetes/pki</span><br><span class="line">clusterName: kubernetes</span><br><span class="line">controllerManager: &#123;&#125;</span><br><span class="line">controlPlaneEndpoint: 192.168.112.136:8443</span><br><span class="line">dns:</span><br><span class="line">  type: CoreDNS</span><br><span class="line">etcd:</span><br><span class="line">  local:</span><br><span class="line">    dataDir: /var/lib/etcd</span><br><span class="line">imageRepository: registry.cn-hangzhou.aliyuncs.com/google_containers</span><br><span class="line">kind: ClusterConfiguration</span><br><span class="line">kubernetesVersion: v1.17.0</span><br><span class="line">networking:</span><br><span class="line">  podSubnet: 10.211.0.0/16</span><br><span class="line">  dnsDomain: cluster.local</span><br><span class="line">  serviceSubnet: 10.96.0.0/16</span><br><span class="line">scheduler: &#123;&#125;</span><br><span class="line"></span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">## 拉取Kubeadm初始化需要使用的docker镜像</span><br><span class="line">kubeadm config images pull --config kubeadm/config/kubeadm-config.yaml</span><br><span class="line">------------------------------------------------------------------------------------------------------------------------------------------------</span><br><span class="line">W0315 10:52:16.188454    5239 validation.go:28] Cannot validate kube-proxy config - no validator is available</span><br><span class="line">W0315 10:52:16.188503    5239 validation.go:28] Cannot validate kubelet config - no validator is available</span><br><span class="line">[config/images] Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/kube-apiserver:v1.17.0</span><br><span class="line">[config/images] Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/kube-controller-manager:v1.17.0</span><br><span class="line">[config/images] Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/kube-scheduler:v1.17.0</span><br><span class="line">[config/images] Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy:v1.17.0</span><br><span class="line">[config/images] Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.1</span><br><span class="line">[config/images] Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/etcd:3.4.3-0</span><br><span class="line">[config/images] Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:1.6.5</span><br><span class="line">------------------------------------------------------------------------------------------------------------------------------------------------</span><br><span class="line">。。。。。。</span><br></pre></td></tr></table></figure></p>
<p>（2）初始化集群（千万注意A和B任选一种方法即可，不可以同时使用）</p>
<p>A. 使用自动分发根证书的方式初始化<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br></pre></td><td class="code"><pre><span class="line"># 执行Kubeadm的初始化操作（自动分发根证书）</span><br><span class="line">kubeadm init --config kubeadm/config/kubeadm-config.yaml --upload-certs</span><br><span class="line">------------------------------------------------------------------------------------------------------------------------------------------------</span><br><span class="line">W0315 10:53:05.509978    5340 validation.go:28] Cannot validate kube-proxy config - no validator is available</span><br><span class="line">W0315 10:53:05.510016    5340 validation.go:28] Cannot validate kubelet config - no validator is available</span><br><span class="line">[init] Using Kubernetes version: v1.17.0</span><br><span class="line">[preflight] Running pre-flight checks</span><br><span class="line">[preflight] Pulling images required for setting up a Kubernetes cluster</span><br><span class="line">[preflight] This might take a minute or two, depending on the speed of your internet connection</span><br><span class="line">[preflight] You can also perform this action in beforehand using &apos;kubeadm config images pull&apos;</span><br><span class="line">[kubelet-start] Writing kubelet environment file with flags to file &quot;/var/lib/kubelet/kubeadm-flags.env&quot;</span><br><span class="line">[kubelet-start] Writing kubelet configuration to file &quot;/var/lib/kubelet/config.yaml&quot;</span><br><span class="line">[kubelet-start] Starting the kubelet</span><br><span class="line">[certs] Using certificateDir folder &quot;/etc/kubernetes/pki&quot;</span><br><span class="line">[certs] Generating &quot;ca&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;apiserver&quot; certificate and key</span><br><span class="line">[certs] apiserver serving cert is signed for DNS names [master01 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.112.128 192.168.112.136]</span><br><span class="line">[certs] Generating &quot;apiserver-kubelet-client&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;front-proxy-ca&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;front-proxy-client&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;etcd/ca&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;etcd/server&quot; certificate and key</span><br><span class="line">[certs] etcd/server serving cert is signed for DNS names [master01 localhost] and IPs [192.168.112.128 127.0.0.1 ::1]</span><br><span class="line">[certs] Generating &quot;etcd/peer&quot; certificate and key</span><br><span class="line">[certs] etcd/peer serving cert is signed for DNS names [master01 localhost] and IPs [192.168.112.128 127.0.0.1 ::1]</span><br><span class="line">[certs] Generating &quot;etcd/healthcheck-client&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;apiserver-etcd-client&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;sa&quot; key and public key</span><br><span class="line">[kubeconfig] Using kubeconfig folder &quot;/etc/kubernetes&quot;</span><br><span class="line">[endpoint] WARNING: port specified in controlPlaneEndpoint overrides bindPort in the controlplane address</span><br><span class="line">[kubeconfig] Writing &quot;admin.conf&quot; kubeconfig file</span><br><span class="line">[endpoint] WARNING: port specified in controlPlaneEndpoint overrides bindPort in the controlplane address</span><br><span class="line">[kubeconfig] Writing &quot;kubelet.conf&quot; kubeconfig file</span><br><span class="line">[endpoint] WARNING: port specified in controlPlaneEndpoint overrides bindPort in the controlplane address</span><br><span class="line">[kubeconfig] Writing &quot;controller-manager.conf&quot; kubeconfig file</span><br><span class="line">[endpoint] WARNING: port specified in controlPlaneEndpoint overrides bindPort in the controlplane address</span><br><span class="line">[kubeconfig] Writing &quot;scheduler.conf&quot; kubeconfig file</span><br><span class="line">[control-plane] Using manifest folder &quot;/etc/kubernetes/manifests&quot;</span><br><span class="line">[control-plane] Creating static Pod manifest for &quot;kube-apiserver&quot;</span><br><span class="line">[control-plane] Creating static Pod manifest for &quot;kube-controller-manager&quot;</span><br><span class="line">W0315 10:53:08.283605    5340 manifests.go:214] the default kube-apiserver authorization-mode is &quot;Node,RBAC&quot;; using &quot;Node,RBAC&quot;</span><br><span class="line">[control-plane] Creating static Pod manifest for &quot;kube-scheduler&quot;</span><br><span class="line">W0315 10:53:08.284727    5340 manifests.go:214] the default kube-apiserver authorization-mode is &quot;Node,RBAC&quot;; using &quot;Node,RBAC&quot;</span><br><span class="line">[etcd] Creating static Pod manifest for local etcd in &quot;/etc/kubernetes/manifests&quot;</span><br><span class="line">[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory &quot;/etc/kubernetes/manifests&quot;. This can take up to 4m0s</span><br><span class="line">[kubelet-check] Initial timeout of 40s passed.</span><br><span class="line">[apiclient] All control plane components are healthy after 42.019337 seconds</span><br><span class="line">[upload-config] Storing the configuration used in ConfigMap &quot;kubeadm-config&quot; in the &quot;kube-system&quot; Namespace</span><br><span class="line">[kubelet] Creating a ConfigMap &quot;kubelet-config-1.17&quot; in namespace kube-system with the configuration for the kubelets in the cluster</span><br><span class="line">[upload-certs] Storing the certificates in Secret &quot;kubeadm-certs&quot; in the &quot;kube-system&quot; Namespace</span><br><span class="line">[upload-certs] Using certificate key:</span><br><span class="line">16f06d3321fce089cad4b229da9b5d3ef94c08a246943e0f375b977f18bbab8e</span><br><span class="line">[mark-control-plane] Marking the node master01 as control-plane by adding the label &quot;node-role.kubernetes.io/master=&apos;&apos;&quot;</span><br><span class="line">[mark-control-plane] Marking the node master01 as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule]</span><br><span class="line">[bootstrap-token] Using token: abcdef.0123456789abcdef</span><br><span class="line">[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles</span><br><span class="line">[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials</span><br><span class="line">[bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token</span><br><span class="line">[bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster</span><br><span class="line">[bootstrap-token] Creating the &quot;cluster-info&quot; ConfigMap in the &quot;kube-public&quot; namespace</span><br><span class="line">[kubelet-finalize] Updating &quot;/etc/kubernetes/kubelet.conf&quot; to point to a rotatable kubelet client certificate and key</span><br><span class="line">[addons] Applied essential addon: CoreDNS</span><br><span class="line">[endpoint] WARNING: port specified in controlPlaneEndpoint overrides bindPort in the controlplane address</span><br><span class="line">[addons] Applied essential addon: kube-proxy</span><br><span class="line"></span><br><span class="line">Your Kubernetes control-plane has initialized successfully!</span><br><span class="line"></span><br><span class="line">To start using your cluster, you need to run the following as a regular user:</span><br><span class="line"></span><br><span class="line">  mkdir -p $HOME/.kube</span><br><span class="line">  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">  sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br><span class="line"></span><br><span class="line">You should now deploy a pod network to the cluster.</span><br><span class="line">Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at:</span><br><span class="line">  https://kubernetes.io/docs/concepts/cluster-administration/addons/</span><br><span class="line"></span><br><span class="line">You can now join any number of the control-plane node running the following command on each as root:</span><br><span class="line"></span><br><span class="line">  kubeadm join 192.168.112.136:8443 --token abcdef.0123456789abcdef \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:33a6370b4bb4a9385c1d878e9a7a085ad969d521e4b309b01be797c0d7867d69 \</span><br><span class="line">    --control-plane --certificate-key 16f06d3321fce089cad4b229da9b5d3ef94c08a246943e0f375b977f18bbab8e</span><br><span class="line"></span><br><span class="line">Please note that the certificate-key gives access to cluster sensitive data, keep it secret!</span><br><span class="line">As a safeguard, uploaded-certs will be deleted in two hours; If necessary, you can use</span><br><span class="line">&quot;kubeadm init phase upload-certs --upload-certs&quot; to reload certs afterward.</span><br><span class="line"></span><br><span class="line">Then you can join any number of worker nodes by running the following on each as root:</span><br><span class="line"></span><br><span class="line">kubeadm join 192.168.112.136:8443 --token abcdef.0123456789abcdef \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:33a6370b4bb4a9385c1d878e9a7a085ad969d521e4b309b01be797c0d7867d69</span><br><span class="line">------------------------------------------------------------------------------------------------------------------------------------------------</span><br><span class="line"></span><br><span class="line"># 保存输出中类似于下面的命令，供添加节点功能使用</span><br><span class="line">。。。。。。</span><br><span class="line">You can now join any number of the control-plane node running the following command on each as root:</span><br><span class="line"></span><br><span class="line">  kubeadm join 192.168.112.136:8443 --token abcdef.0123456789abcdef \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:33a6370b4bb4a9385c1d878e9a7a085ad969d521e4b309b01be797c0d7867d69 \</span><br><span class="line">    --control-plane --certificate-key 16f06d3321fce089cad4b229da9b5d3ef94c08a246943e0f375b977f18bbab8e</span><br><span class="line"></span><br><span class="line">Please note that the certificate-key gives access to cluster sensitive data, keep it secret!</span><br><span class="line">As a safeguard, uploaded-certs will be deleted in two hours; If necessary, you can use</span><br><span class="line">&quot;kubeadm init phase upload-certs --upload-certs&quot; to reload certs afterward.</span><br><span class="line"></span><br><span class="line">Then you can join any number of worker nodes by running the following on each as root:</span><br><span class="line"></span><br><span class="line">kubeadm join 192.168.112.136:8443 --token abcdef.0123456789abcdef \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:33a6370b4bb4a9385c1d878e9a7a085ad969d521e4b309b01be797c0d7867d69</span><br></pre></td></tr></table></figure></p>
<p>B. 使用手动分发根证书的方式初始化<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br></pre></td><td class="code"><pre><span class="line"># 执行Kubeadm的初始化操作（手动分发根证书）</span><br><span class="line">kubeadm init --config kubeadm/config/kubeadm-config.yaml</span><br><span class="line">------------------------------------------------------------------------------------------------------------------------------------------------</span><br><span class="line">W0315 11:37:50.200933    2834 validation.go:28] Cannot validate kubelet config - no validator is available</span><br><span class="line">W0315 11:37:50.201021    2834 validation.go:28] Cannot validate kube-proxy config - no validator is available</span><br><span class="line">[init] Using Kubernetes version: v1.17.0</span><br><span class="line">[preflight] Running pre-flight checks</span><br><span class="line">[preflight] Pulling images required for setting up a Kubernetes cluster</span><br><span class="line">[preflight] This might take a minute or two, depending on the speed of your internet connection</span><br><span class="line">[preflight] You can also perform this action in beforehand using &apos;kubeadm config images pull&apos;</span><br><span class="line">[kubelet-start] Writing kubelet environment file with flags to file &quot;/var/lib/kubelet/kubeadm-flags.env&quot;</span><br><span class="line">[kubelet-start] Writing kubelet configuration to file &quot;/var/lib/kubelet/config.yaml&quot;</span><br><span class="line">[kubelet-start] Starting the kubelet</span><br><span class="line">[certs] Using certificateDir folder &quot;/etc/kubernetes/pki&quot;</span><br><span class="line">[certs] Generating &quot;ca&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;apiserver&quot; certificate and key</span><br><span class="line">[certs] apiserver serving cert is signed for DNS names [master01 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.112.128 192.168.112.136]</span><br><span class="line">[certs] Generating &quot;apiserver-kubelet-client&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;front-proxy-ca&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;front-proxy-client&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;etcd/ca&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;etcd/server&quot; certificate and key</span><br><span class="line">[certs] etcd/server serving cert is signed for DNS names [master01 localhost] and IPs [192.168.112.128 127.0.0.1 ::1]</span><br><span class="line">[certs] Generating &quot;etcd/peer&quot; certificate and key</span><br><span class="line">[certs] etcd/peer serving cert is signed for DNS names [master01 localhost] and IPs [192.168.112.128 127.0.0.1 ::1]</span><br><span class="line">[certs] Generating &quot;etcd/healthcheck-client&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;apiserver-etcd-client&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;sa&quot; key and public key</span><br><span class="line">[kubeconfig] Using kubeconfig folder &quot;/etc/kubernetes&quot;</span><br><span class="line">[endpoint] WARNING: port specified in controlPlaneEndpoint overrides bindPort in the controlplane address</span><br><span class="line">[kubeconfig] Writing &quot;admin.conf&quot; kubeconfig file</span><br><span class="line">[endpoint] WARNING: port specified in controlPlaneEndpoint overrides bindPort in the controlplane address</span><br><span class="line">[kubeconfig] Writing &quot;kubelet.conf&quot; kubeconfig file</span><br><span class="line">[endpoint] WARNING: port specified in controlPlaneEndpoint overrides bindPort in the controlplane address</span><br><span class="line">[kubeconfig] Writing &quot;controller-manager.conf&quot; kubeconfig file</span><br><span class="line">[endpoint] WARNING: port specified in controlPlaneEndpoint overrides bindPort in the controlplane address</span><br><span class="line">[kubeconfig] Writing &quot;scheduler.conf&quot; kubeconfig file</span><br><span class="line">[control-plane] Using manifest folder &quot;/etc/kubernetes/manifests&quot;</span><br><span class="line">[control-plane] Creating static Pod manifest for &quot;kube-apiserver&quot;</span><br><span class="line">[control-plane] Creating static Pod manifest for &quot;kube-controller-manager&quot;</span><br><span class="line">W0315 11:37:52.884008    2834 manifests.go:214] the default kube-apiserver authorization-mode is &quot;Node,RBAC&quot;; using &quot;Node,RBAC&quot;</span><br><span class="line">[control-plane] Creating static Pod manifest for &quot;kube-scheduler&quot;</span><br><span class="line">W0315 11:37:52.885218    2834 manifests.go:214] the default kube-apiserver authorization-mode is &quot;Node,RBAC&quot;; using &quot;Node,RBAC&quot;</span><br><span class="line">[etcd] Creating static Pod manifest for local etcd in &quot;/etc/kubernetes/manifests&quot;</span><br><span class="line">[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory &quot;/etc/kubernetes/manifests&quot;. This can take up to 4m0s</span><br><span class="line">[apiclient] All control plane components are healthy after 36.521431 seconds</span><br><span class="line">[upload-config] Storing the configuration used in ConfigMap &quot;kubeadm-config&quot; in the &quot;kube-system&quot; Namespace</span><br><span class="line">[kubelet] Creating a ConfigMap &quot;kubelet-config-1.17&quot; in namespace kube-system with the configuration for the kubelets in the cluster</span><br><span class="line">[upload-certs] Skipping phase. Please see --upload-certs</span><br><span class="line">[mark-control-plane] Marking the node master01 as control-plane by adding the label &quot;node-role.kubernetes.io/master=&apos;&apos;&quot;</span><br><span class="line">[mark-control-plane] Marking the node master01 as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule]</span><br><span class="line">[bootstrap-token] Using token: abcdef.0123456789abcdef</span><br><span class="line">[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles</span><br><span class="line">[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials</span><br><span class="line">[bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token</span><br><span class="line">[bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster</span><br><span class="line">[bootstrap-token] Creating the &quot;cluster-info&quot; ConfigMap in the &quot;kube-public&quot; namespace</span><br><span class="line">[kubelet-finalize] Updating &quot;/etc/kubernetes/kubelet.conf&quot; to point to a rotatable kubelet client certificate and key</span><br><span class="line">[addons] Applied essential addon: CoreDNS</span><br><span class="line">[endpoint] WARNING: port specified in controlPlaneEndpoint overrides bindPort in the controlplane address</span><br><span class="line">[addons] Applied essential addon: kube-proxy</span><br><span class="line"></span><br><span class="line">Your Kubernetes control-plane has initialized successfully!</span><br><span class="line"></span><br><span class="line">To start using your cluster, you need to run the following as a regular user:</span><br><span class="line"></span><br><span class="line">  mkdir -p $HOME/.kube</span><br><span class="line">  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">  sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br><span class="line"></span><br><span class="line">You should now deploy a pod network to the cluster.</span><br><span class="line">Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at:</span><br><span class="line">  https://kubernetes.io/docs/concepts/cluster-administration/addons/</span><br><span class="line"></span><br><span class="line">You can now join any number of control-plane nodes by copying certificate authorities</span><br><span class="line">and service account keys on each node and then running the following as root:</span><br><span class="line"></span><br><span class="line">  kubeadm join 192.168.112.136:8443 --token abcdef.0123456789abcdef \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:05945a0dc7d9c5e45e196d8582de19a3df559d1f9f4e4cb52c77d3051db923b4 \</span><br><span class="line">    --control-plane</span><br><span class="line"></span><br><span class="line">Then you can join any number of worker nodes by running the following on each as root:</span><br><span class="line"></span><br><span class="line">kubeadm join 192.168.112.136:8443 --token abcdef.0123456789abcdef \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:05945a0dc7d9c5e45e196d8582de19a3df559d1f9f4e4cb52c77d3051db923b4</span><br><span class="line">------------------------------------------------------------------------------------------------------------------------------------------------</span><br><span class="line"></span><br><span class="line"># 保存输出中类似于下面的命令，供添加节点功能使用（后续Master节点的加入一定要在手动分发完根证书后再执行第一个命令进行加入）</span><br><span class="line"># 注意：控制Master节点的加入使用第一个命令，Node节点的加入使用第二个命令</span><br><span class="line">。。。。。。</span><br><span class="line">You should now deploy a pod network to the cluster.</span><br><span class="line">Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at:</span><br><span class="line">  https://kubernetes.io/docs/concepts/cluster-administration/addons/</span><br><span class="line"></span><br><span class="line">You can now join any number of control-plane nodes by copying certificate authorities</span><br><span class="line">and service account keys on each node and then running the following as root:</span><br><span class="line"></span><br><span class="line">  kubeadm join 192.168.112.136:8443 --token abcdef.0123456789abcdef \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:05945a0dc7d9c5e45e196d8582de19a3df559d1f9f4e4cb52c77d3051db923b4 \</span><br><span class="line">    --control-plane</span><br><span class="line"></span><br><span class="line">Then you can join any number of worker nodes by running the following on each as root:</span><br><span class="line"></span><br><span class="line">kubeadm join 192.168.112.136:8443 --token abcdef.0123456789abcdef \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:05945a0dc7d9c5e45e196d8582de19a3df559d1f9f4e4cb52c77d3051db923b4</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">## 配置master01到master02和master03的ssh免密登录</span><br><span class="line">ssh-keygen</span><br><span class="line">ssh-copy-id -i .ssh/id_rsa.pub root@master02</span><br><span class="line">ssh-copy-id -i .ssh/id_rsa.pub root@master03</span><br><span class="line"></span><br><span class="line">## 验证master01到master02和master03的ssh免密登录</span><br><span class="line">ssh master02</span><br><span class="line">ssh master03</span><br><span class="line"></span><br><span class="line">## 分发pki证书和admin.conf文件</span><br><span class="line">cat &lt;&lt;EOF &gt; kubeadm/config/scp-config.sh</span><br><span class="line">USER=root</span><br><span class="line">CONTROL_PLANE_IPS=&quot;192.168.112.129 192.168.112.130&quot;</span><br><span class="line">for host in \$&#123;CONTROL_PLANE_IPS&#125;; do</span><br><span class="line">    ssh \$&#123;USER&#125;@\$host &apos;mkdir -p /etc/kubernetes/pki/etcd/&apos;</span><br><span class="line">    scp /etc/kubernetes/pki/ca.crt \$&#123;USER&#125;@\$host:/etc/kubernetes/pki/</span><br><span class="line">    scp /etc/kubernetes/pki/ca.key \$&#123;USER&#125;@\$host:/etc/kubernetes/pki/</span><br><span class="line">    scp /etc/kubernetes/pki/sa.key \$&#123;USER&#125;@\$host:/etc/kubernetes/pki/</span><br><span class="line">    scp /etc/kubernetes/pki/sa.pub \$&#123;USER&#125;@\$host:/etc/kubernetes/pki/</span><br><span class="line">    scp /etc/kubernetes/pki/front-proxy-ca.crt \$&#123;USER&#125;@\$host:/etc/kubernetes/pki/</span><br><span class="line">    scp /etc/kubernetes/pki/front-proxy-ca.key \$&#123;USER&#125;@\$host:/etc/kubernetes/pki/</span><br><span class="line">    scp /etc/kubernetes/pki/etcd/ca.crt \$&#123;USER&#125;@\$host:/etc/kubernetes/pki/etcd/</span><br><span class="line">    scp /etc/kubernetes/pki/etcd/ca.key \$&#123;USER&#125;@\$host:/etc/kubernetes/pki/etcd/</span><br><span class="line">    scp /etc/kubernetes/admin.conf \$&#123;USER&#125;@\$host:/etc/kubernetes/</span><br><span class="line">done</span><br><span class="line">EOF</span><br><span class="line">chmod 0755 kubeadm/config/scp-config.sh</span><br><span class="line">./kubeadm/config/scp-config.sh</span><br></pre></td></tr></table></figure></p>
<h2 id="4-在Kubernetes-Control-Plane-的第二个Node（master02）上操作：（千万注意A和B任选一种方法即可，不可以同时使用）"><a href="#4-在Kubernetes-Control-Plane-的第二个Node（master02）上操作：（千万注意A和B任选一种方法即可，不可以同时使用）" class="headerlink" title="4. 在Kubernetes Control Plane 的第二个Node（master02）上操作：（千万注意A和B任选一种方法即可，不可以同时使用）"></a>4. 在Kubernetes Control Plane 的第二个Node（master02）上操作：（千万注意A和B任选一种方法即可，不可以同时使用）</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br></pre></td><td class="code"><pre><span class="line"># A. 使用自动分发根证书的方式初始化</span><br><span class="line">kubeadm join 192.168.112.136:8443 --token abcdef.0123456789abcdef \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:33a6370b4bb4a9385c1d878e9a7a085ad969d521e4b309b01be797c0d7867d69 \</span><br><span class="line">    --control-plane --certificate-key 16f06d3321fce089cad4b229da9b5d3ef94c08a246943e0f375b977f18bbab8e</span><br><span class="line">------------------------------------------------------------------------------------------------------------------------------------------------</span><br><span class="line">[preflight] Running pre-flight checks</span><br><span class="line">[preflight] Reading configuration from the cluster...</span><br><span class="line">[preflight] FYI: You can look at this config file with &apos;kubectl -n kube-system get cm kubeadm-config -oyaml&apos;</span><br><span class="line">[preflight] Running pre-flight checks before initializing the new control plane instance</span><br><span class="line">[preflight] Pulling images required for setting up a Kubernetes cluster</span><br><span class="line">[preflight] This might take a minute or two, depending on the speed of your internet connection</span><br><span class="line">[preflight] You can also perform this action in beforehand using &apos;kubeadm config images pull&apos;</span><br><span class="line">[download-certs] Downloading the certificates in Secret &quot;kubeadm-certs&quot; in the &quot;kube-system&quot; Namespace</span><br><span class="line">[certs] Using certificateDir folder &quot;/etc/kubernetes/pki&quot;</span><br><span class="line">[certs] Generating &quot;front-proxy-client&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;etcd/peer&quot; certificate and key</span><br><span class="line">[certs] etcd/peer serving cert is signed for DNS names [master02 localhost] and IPs [192.168.112.129 127.0.0.1 ::1]</span><br><span class="line">[certs] Generating &quot;apiserver-etcd-client&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;etcd/server&quot; certificate and key</span><br><span class="line">[certs] etcd/server serving cert is signed for DNS names [master02 localhost] and IPs [192.168.112.129 127.0.0.1 ::1]</span><br><span class="line">[certs] Generating &quot;etcd/healthcheck-client&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;apiserver&quot; certificate and key</span><br><span class="line">[certs] apiserver serving cert is signed for DNS names [master02 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.112.129 192.168.112.136]</span><br><span class="line">[certs] Generating &quot;apiserver-kubelet-client&quot; certificate and key</span><br><span class="line">[certs] Valid certificates and keys now exist in &quot;/etc/kubernetes/pki&quot;</span><br><span class="line">[certs] Using the existing &quot;sa&quot; key</span><br><span class="line">[kubeconfig] Generating kubeconfig files</span><br><span class="line">[kubeconfig] Using kubeconfig folder &quot;/etc/kubernetes&quot;</span><br><span class="line">[endpoint] WARNING: port specified in controlPlaneEndpoint overrides bindPort in the controlplane address</span><br><span class="line">[kubeconfig] Writing &quot;admin.conf&quot; kubeconfig file</span><br><span class="line">[kubeconfig] Writing &quot;controller-manager.conf&quot; kubeconfig file</span><br><span class="line">[kubeconfig] Writing &quot;scheduler.conf&quot; kubeconfig file</span><br><span class="line">[control-plane] Using manifest folder &quot;/etc/kubernetes/manifests&quot;</span><br><span class="line">[control-plane] Creating static Pod manifest for &quot;kube-apiserver&quot;</span><br><span class="line">W0315 10:59:52.640333    1546 manifests.go:214] the default kube-apiserver authorization-mode is &quot;Node,RBAC&quot;; using &quot;Node,RBAC&quot;</span><br><span class="line">[control-plane] Creating static Pod manifest for &quot;kube-controller-manager&quot;</span><br><span class="line">W0315 10:59:52.645116    1546 manifests.go:214] the default kube-apiserver authorization-mode is &quot;Node,RBAC&quot;; using &quot;Node,RBAC&quot;</span><br><span class="line">[control-plane] Creating static Pod manifest for &quot;kube-scheduler&quot;</span><br><span class="line">W0315 10:59:52.646387    1546 manifests.go:214] the default kube-apiserver authorization-mode is &quot;Node,RBAC&quot;; using &quot;Node,RBAC&quot;</span><br><span class="line">[check-etcd] Checking that the etcd cluster is healthy</span><br><span class="line">[kubelet-start] Downloading configuration for the kubelet from the &quot;kubelet-config-1.17&quot; ConfigMap in the kube-system namespace</span><br><span class="line">[kubelet-start] Writing kubelet configuration to file &quot;/var/lib/kubelet/config.yaml&quot;</span><br><span class="line">[kubelet-start] Writing kubelet environment file with flags to file &quot;/var/lib/kubelet/kubeadm-flags.env&quot;</span><br><span class="line">[kubelet-start] Starting the kubelet</span><br><span class="line">[kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap...</span><br><span class="line">[etcd] Announced new etcd member joining to the existing etcd cluster</span><br><span class="line">[etcd] Creating static Pod manifest for &quot;etcd&quot;</span><br><span class="line">[etcd] Waiting for the new etcd member to join the cluster. This can take up to 40s</span><br><span class="line">&#123;&quot;level&quot;:&quot;warn&quot;,&quot;ts&quot;:&quot;2020-03-15T11:00:28.875+0800&quot;,&quot;caller&quot;:&quot;clientv3/retry_interceptor.go:61&quot;,&quot;msg&quot;:&quot;retrying of unary invoker failed&quot;,&quot;target&quot;:&quot;passthrough:///https://192.168.112.129:2379&quot;,&quot;attempt&quot;:0,&quot;error&quot;:&quot;rpc error: code = DeadlineExceeded desc = context deadline exceeded&quot;&#125;</span><br><span class="line">[upload-config] Storing the configuration used in ConfigMap &quot;kubeadm-config&quot; in the &quot;kube-system&quot; Namespace</span><br><span class="line">[mark-control-plane] Marking the node master02 as control-plane by adding the label &quot;node-role.kubernetes.io/master=&apos;&apos;&quot;</span><br><span class="line">[mark-control-plane] Marking the node master02 as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule]</span><br><span class="line"></span><br><span class="line">This node has joined the cluster and a new control plane instance was created:</span><br><span class="line"></span><br><span class="line">* Certificate signing request was sent to apiserver and approval was received.</span><br><span class="line">* The Kubelet was informed of the new secure connection details.</span><br><span class="line">* Control plane (master) label and taint were applied to the new node.</span><br><span class="line">* The Kubernetes control plane instances scaled up.</span><br><span class="line">* A new etcd member was added to the local/stacked etcd cluster.</span><br><span class="line"></span><br><span class="line">To start administering your cluster from this node, you need to run the following as a regular user:</span><br><span class="line"></span><br><span class="line">	mkdir -p $HOME/.kube</span><br><span class="line">	sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">	sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br><span class="line"></span><br><span class="line">Run &apos;kubectl get nodes&apos; to see this node join the cluster.</span><br><span class="line"></span><br><span class="line">------------------------------------------------------------------------------------------------------------------------------------------------</span><br><span class="line"></span><br><span class="line"># B. 使用手动分发根证书的方式初始化</span><br><span class="line">kubeadm join 192.168.112.136:8443 --token abcdef.0123456789abcdef \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:05945a0dc7d9c5e45e196d8582de19a3df559d1f9f4e4cb52c77d3051db923b4 \</span><br><span class="line">    --control-plane</span><br><span class="line">------------------------------------------------------------------------------------------------------------------------------------------------</span><br><span class="line">[preflight] Running pre-flight checks</span><br><span class="line">[preflight] Reading configuration from the cluster...</span><br><span class="line">[preflight] FYI: You can look at this config file with &apos;kubectl -n kube-system get cm kubeadm-config -oyaml&apos;</span><br><span class="line">[preflight] Running pre-flight checks before initializing the new control plane instance</span><br><span class="line">[preflight] Pulling images required for setting up a Kubernetes cluster</span><br><span class="line">[preflight] This might take a minute or two, depending on the speed of your internet connection</span><br><span class="line">[preflight] You can also perform this action in beforehand using &apos;kubeadm config images pull&apos;</span><br><span class="line">[certs] Using certificateDir folder &quot;/etc/kubernetes/pki&quot;</span><br><span class="line">[certs] Generating &quot;apiserver&quot; certificate and key</span><br><span class="line">[certs] apiserver serving cert is signed for DNS names [master02 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.112.129 192.168.112.136]</span><br><span class="line">[certs] Generating &quot;apiserver-kubelet-client&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;front-proxy-client&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;etcd/server&quot; certificate and key</span><br><span class="line">[certs] etcd/server serving cert is signed for DNS names [master02 localhost] and IPs [192.168.112.129 127.0.0.1 ::1]</span><br><span class="line">[certs] Generating &quot;etcd/healthcheck-client&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;etcd/peer&quot; certificate and key</span><br><span class="line">[certs] etcd/peer serving cert is signed for DNS names [master02 localhost] and IPs [192.168.112.129 127.0.0.1 ::1]</span><br><span class="line">[certs] Generating &quot;apiserver-etcd-client&quot; certificate and key</span><br><span class="line">[certs] Valid certificates and keys now exist in &quot;/etc/kubernetes/pki&quot;</span><br><span class="line">[certs] Using the existing &quot;sa&quot; key</span><br><span class="line">[kubeconfig] Generating kubeconfig files</span><br><span class="line">[kubeconfig] Using kubeconfig folder &quot;/etc/kubernetes&quot;</span><br><span class="line">[endpoint] WARNING: port specified in controlPlaneEndpoint overrides bindPort in the controlplane address</span><br><span class="line">[kubeconfig] Using existing kubeconfig file: &quot;/etc/kubernetes/admin.conf&quot;</span><br><span class="line">[kubeconfig] Writing &quot;controller-manager.conf&quot; kubeconfig file</span><br><span class="line">[kubeconfig] Writing &quot;scheduler.conf&quot; kubeconfig file</span><br><span class="line">[control-plane] Using manifest folder &quot;/etc/kubernetes/manifests&quot;</span><br><span class="line">[control-plane] Creating static Pod manifest for &quot;kube-apiserver&quot;</span><br><span class="line">W0315 11:48:00.712980    2760 manifests.go:214] the default kube-apiserver authorization-mode is &quot;Node,RBAC&quot;; using &quot;Node,RBAC&quot;</span><br><span class="line">[control-plane] Creating static Pod manifest for &quot;kube-controller-manager&quot;</span><br><span class="line">W0315 11:48:00.717833    2760 manifests.go:214] the default kube-apiserver authorization-mode is &quot;Node,RBAC&quot;; using &quot;Node,RBAC&quot;</span><br><span class="line">[control-plane] Creating static Pod manifest for &quot;kube-scheduler&quot;</span><br><span class="line">W0315 11:48:00.718658    2760 manifests.go:214] the default kube-apiserver authorization-mode is &quot;Node,RBAC&quot;; using &quot;Node,RBAC&quot;</span><br><span class="line">[check-etcd] Checking that the etcd cluster is healthy</span><br><span class="line">[kubelet-start] Downloading configuration for the kubelet from the &quot;kubelet-config-1.17&quot; ConfigMap in the kube-system namespace</span><br><span class="line">[kubelet-start] Writing kubelet configuration to file &quot;/var/lib/kubelet/config.yaml&quot;</span><br><span class="line">[kubelet-start] Writing kubelet environment file with flags to file &quot;/var/lib/kubelet/kubeadm-flags.env&quot;</span><br><span class="line">[kubelet-start] Starting the kubelet</span><br><span class="line">[kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap...</span><br><span class="line">[etcd] Announced new etcd member joining to the existing etcd cluster</span><br><span class="line">[etcd] Creating static Pod manifest for &quot;etcd&quot;</span><br><span class="line">[etcd] Waiting for the new etcd member to join the cluster. This can take up to 40s</span><br><span class="line">&#123;&quot;level&quot;:&quot;warn&quot;,&quot;ts&quot;:&quot;2020-03-15T11:48:38.856+0800&quot;,&quot;caller&quot;:&quot;clientv3/retry_interceptor.go:61&quot;,&quot;msg&quot;:&quot;retrying of unary invoker failed&quot;,&quot;target&quot;:&quot;passthrough:///https://192.168.112.129:2379&quot;,&quot;attempt&quot;:0,&quot;error&quot;:&quot;rpc error: code = DeadlineExceeded desc = context deadline exceeded&quot;&#125;</span><br><span class="line">[upload-config] Storing the configuration used in ConfigMap &quot;kubeadm-config&quot; in the &quot;kube-system&quot; Namespace</span><br><span class="line">[kubelet-check] Initial timeout of 40s passed.</span><br><span class="line">[mark-control-plane] Marking the node master02 as control-plane by adding the label &quot;node-role.kubernetes.io/master=&apos;&apos;&quot;</span><br><span class="line">[mark-control-plane] Marking the node master02 as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule]</span><br><span class="line"></span><br><span class="line">This node has joined the cluster and a new control plane instance was created:</span><br><span class="line"></span><br><span class="line">* Certificate signing request was sent to apiserver and approval was received.</span><br><span class="line">* The Kubelet was informed of the new secure connection details.</span><br><span class="line">* Control plane (master) label and taint were applied to the new node.</span><br><span class="line">* The Kubernetes control plane instances scaled up.</span><br><span class="line">* A new etcd member was added to the local/stacked etcd cluster.</span><br><span class="line"></span><br><span class="line">To start administering your cluster from this node, you need to run the following as a regular user:</span><br><span class="line"></span><br><span class="line">	mkdir -p $HOME/.kube</span><br><span class="line">	sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">	sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br><span class="line"></span><br><span class="line">Run &apos;kubectl get nodes&apos; to see this node join the cluster.</span><br><span class="line"></span><br><span class="line">------------------------------------------------------------------------------------------------------------------------------------------------</span><br></pre></td></tr></table></figure>
<h2 id="5-在Kubernetes-Control-Plane-的第三个Node（master03）上操作：（千万注意A和B任选一种方法即可，不可以同时使用）"><a href="#5-在Kubernetes-Control-Plane-的第三个Node（master03）上操作：（千万注意A和B任选一种方法即可，不可以同时使用）" class="headerlink" title="5. 在Kubernetes Control Plane 的第三个Node（master03）上操作：（千万注意A和B任选一种方法即可，不可以同时使用）"></a>5. 在Kubernetes Control Plane 的第三个Node（master03）上操作：（千万注意A和B任选一种方法即可，不可以同时使用）</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br></pre></td><td class="code"><pre><span class="line"># A. 使用自动分发根证书的方式初始化</span><br><span class="line">kubeadm join 192.168.112.136:8443 --token abcdef.0123456789abcdef \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:33a6370b4bb4a9385c1d878e9a7a085ad969d521e4b309b01be797c0d7867d69 \</span><br><span class="line">    --control-plane --certificate-key 16f06d3321fce089cad4b229da9b5d3ef94c08a246943e0f375b977f18bbab8e</span><br><span class="line">------------------------------------------------------------------------------------------------------------------------------------------------</span><br><span class="line">[preflight] Running pre-flight checks</span><br><span class="line">[preflight] Reading configuration from the cluster...</span><br><span class="line">[preflight] FYI: You can look at this config file with &apos;kubectl -n kube-system get cm kubeadm-config -oyaml&apos;</span><br><span class="line">[preflight] Running pre-flight checks before initializing the new control plane instance</span><br><span class="line">[preflight] Pulling images required for setting up a Kubernetes cluster</span><br><span class="line">[preflight] This might take a minute or two, depending on the speed of your internet connection</span><br><span class="line">[preflight] You can also perform this action in beforehand using &apos;kubeadm config images pull&apos;</span><br><span class="line">[download-certs] Downloading the certificates in Secret &quot;kubeadm-certs&quot; in the &quot;kube-system&quot; Namespace</span><br><span class="line">[certs] Using certificateDir folder &quot;/etc/kubernetes/pki&quot;</span><br><span class="line">[certs] Generating &quot;front-proxy-client&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;etcd/server&quot; certificate and key</span><br><span class="line">[certs] etcd/server serving cert is signed for DNS names [master03 localhost] and IPs [192.168.112.130 127.0.0.1 ::1]</span><br><span class="line">[certs] Generating &quot;etcd/peer&quot; certificate and key</span><br><span class="line">[certs] etcd/peer serving cert is signed for DNS names [master03 localhost] and IPs [192.168.112.130 127.0.0.1 ::1]</span><br><span class="line">[certs] Generating &quot;etcd/healthcheck-client&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;apiserver-etcd-client&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;apiserver-kubelet-client&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;apiserver&quot; certificate and key</span><br><span class="line">[certs] apiserver serving cert is signed for DNS names [master03 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.112.130 192.168.112.136]</span><br><span class="line">[certs] Valid certificates and keys now exist in &quot;/etc/kubernetes/pki&quot;</span><br><span class="line">[certs] Using the existing &quot;sa&quot; key</span><br><span class="line">[kubeconfig] Generating kubeconfig files</span><br><span class="line">[kubeconfig] Using kubeconfig folder &quot;/etc/kubernetes&quot;</span><br><span class="line">[endpoint] WARNING: port specified in controlPlaneEndpoint overrides bindPort in the controlplane address</span><br><span class="line">[kubeconfig] Writing &quot;admin.conf&quot; kubeconfig file</span><br><span class="line">[kubeconfig] Writing &quot;controller-manager.conf&quot; kubeconfig file</span><br><span class="line">[kubeconfig] Writing &quot;scheduler.conf&quot; kubeconfig file</span><br><span class="line">[control-plane] Using manifest folder &quot;/etc/kubernetes/manifests&quot;</span><br><span class="line">[control-plane] Creating static Pod manifest for &quot;kube-apiserver&quot;</span><br><span class="line">W0315 11:02:05.176831    1648 manifests.go:214] the default kube-apiserver authorization-mode is &quot;Node,RBAC&quot;; using &quot;Node,RBAC&quot;</span><br><span class="line">[control-plane] Creating static Pod manifest for &quot;kube-controller-manager&quot;</span><br><span class="line">W0315 11:02:05.182344    1648 manifests.go:214] the default kube-apiserver authorization-mode is &quot;Node,RBAC&quot;; using &quot;Node,RBAC&quot;</span><br><span class="line">[control-plane] Creating static Pod manifest for &quot;kube-scheduler&quot;</span><br><span class="line">W0315 11:02:05.183197    1648 manifests.go:214] the default kube-apiserver authorization-mode is &quot;Node,RBAC&quot;; using &quot;Node,RBAC&quot;</span><br><span class="line">[check-etcd] Checking that the etcd cluster is healthy</span><br><span class="line">[kubelet-start] Downloading configuration for the kubelet from the &quot;kubelet-config-1.17&quot; ConfigMap in the kube-system namespace</span><br><span class="line">[kubelet-start] Writing kubelet configuration to file &quot;/var/lib/kubelet/config.yaml&quot;</span><br><span class="line">[kubelet-start] Writing kubelet environment file with flags to file &quot;/var/lib/kubelet/kubeadm-flags.env&quot;</span><br><span class="line">[kubelet-start] Starting the kubelet</span><br><span class="line">[kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap...</span><br><span class="line">[etcd] Announced new etcd member joining to the existing etcd cluster</span><br><span class="line">[etcd] Creating static Pod manifest for &quot;etcd&quot;</span><br><span class="line">[etcd] Waiting for the new etcd member to join the cluster. This can take up to 40s</span><br><span class="line">&#123;&quot;level&quot;:&quot;warn&quot;,&quot;ts&quot;:&quot;2020-03-15T11:02:32.084+0800&quot;,&quot;caller&quot;:&quot;clientv3/retry_interceptor.go:61&quot;,&quot;msg&quot;:&quot;retrying of unary invoker failed&quot;,&quot;target&quot;:&quot;passthrough:///https://192.168.112.130:2379&quot;,&quot;attempt&quot;:0,&quot;error&quot;:&quot;rpc error: code = DeadlineExceeded desc = context deadline exceeded&quot;&#125;</span><br><span class="line">[upload-config] Storing the configuration used in ConfigMap &quot;kubeadm-config&quot; in the &quot;kube-system&quot; Namespace</span><br><span class="line">[mark-control-plane] Marking the node master03 as control-plane by adding the label &quot;node-role.kubernetes.io/master=&apos;&apos;&quot;</span><br><span class="line">[mark-control-plane] Marking the node master03 as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule]</span><br><span class="line"></span><br><span class="line">This node has joined the cluster and a new control plane instance was created:</span><br><span class="line"></span><br><span class="line">* Certificate signing request was sent to apiserver and approval was received.</span><br><span class="line">* The Kubelet was informed of the new secure connection details.</span><br><span class="line">* Control plane (master) label and taint were applied to the new node.</span><br><span class="line">* The Kubernetes control plane instances scaled up.</span><br><span class="line">* A new etcd member was added to the local/stacked etcd cluster.</span><br><span class="line"></span><br><span class="line">To start administering your cluster from this node, you need to run the following as a regular user:</span><br><span class="line"></span><br><span class="line">	mkdir -p $HOME/.kube</span><br><span class="line">	sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">	sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br><span class="line"></span><br><span class="line">Run &apos;kubectl get nodes&apos; to see this node join the cluster.</span><br><span class="line"></span><br><span class="line">------------------------------------------------------------------------------------------------------------------------------------------------</span><br><span class="line"></span><br><span class="line"># B. 使用手动分发根证书的方式初始化</span><br><span class="line">kubeadm join 192.168.112.136:8443 --token abcdef.0123456789abcdef \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:05945a0dc7d9c5e45e196d8582de19a3df559d1f9f4e4cb52c77d3051db923b4 \</span><br><span class="line">    --control-plane</span><br><span class="line">------------------------------------------------------------------------------------------------------------------------------------------------</span><br><span class="line">[preflight] Running pre-flight checks</span><br><span class="line">[preflight] Reading configuration from the cluster...</span><br><span class="line">[preflight] FYI: You can look at this config file with &apos;kubectl -n kube-system get cm kubeadm-config -oyaml&apos;</span><br><span class="line">[preflight] Running pre-flight checks before initializing the new control plane instance</span><br><span class="line">[preflight] Pulling images required for setting up a Kubernetes cluster</span><br><span class="line">[preflight] This might take a minute or two, depending on the speed of your internet connection</span><br><span class="line">[preflight] You can also perform this action in beforehand using &apos;kubeadm config images pull&apos;</span><br><span class="line">[certs] Using certificateDir folder &quot;/etc/kubernetes/pki&quot;</span><br><span class="line">[certs] Generating &quot;apiserver-kubelet-client&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;apiserver&quot; certificate and key</span><br><span class="line">[certs] apiserver serving cert is signed for DNS names [master03 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.112.130 192.168.112.136]</span><br><span class="line">[certs] Generating &quot;etcd/peer&quot; certificate and key</span><br><span class="line">[certs] etcd/peer serving cert is signed for DNS names [master03 localhost] and IPs [192.168.112.130 127.0.0.1 ::1]</span><br><span class="line">[certs] Generating &quot;apiserver-etcd-client&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;etcd/server&quot; certificate and key</span><br><span class="line">[certs] etcd/server serving cert is signed for DNS names [master03 localhost] and IPs [192.168.112.130 127.0.0.1 ::1]</span><br><span class="line">[certs] Generating &quot;etcd/healthcheck-client&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;front-proxy-client&quot; certificate and key</span><br><span class="line">[certs] Valid certificates and keys now exist in &quot;/etc/kubernetes/pki&quot;</span><br><span class="line">[certs] Using the existing &quot;sa&quot; key</span><br><span class="line">[kubeconfig] Generating kubeconfig files</span><br><span class="line">[kubeconfig] Using kubeconfig folder &quot;/etc/kubernetes&quot;</span><br><span class="line">[endpoint] WARNING: port specified in controlPlaneEndpoint overrides bindPort in the controlplane address</span><br><span class="line">[kubeconfig] Using existing kubeconfig file: &quot;/etc/kubernetes/admin.conf&quot;</span><br><span class="line">[kubeconfig] Writing &quot;controller-manager.conf&quot; kubeconfig file</span><br><span class="line">[kubeconfig] Writing &quot;scheduler.conf&quot; kubeconfig file</span><br><span class="line">[control-plane] Using manifest folder &quot;/etc/kubernetes/manifests&quot;</span><br><span class="line">[control-plane] Creating static Pod manifest for &quot;kube-apiserver&quot;</span><br><span class="line">W0315 11:49:29.220424    2807 manifests.go:214] the default kube-apiserver authorization-mode is &quot;Node,RBAC&quot;; using &quot;Node,RBAC&quot;</span><br><span class="line">[control-plane] Creating static Pod manifest for &quot;kube-controller-manager&quot;</span><br><span class="line">W0315 11:49:29.225217    2807 manifests.go:214] the default kube-apiserver authorization-mode is &quot;Node,RBAC&quot;; using &quot;Node,RBAC&quot;</span><br><span class="line">[control-plane] Creating static Pod manifest for &quot;kube-scheduler&quot;</span><br><span class="line">W0315 11:49:29.226261    2807 manifests.go:214] the default kube-apiserver authorization-mode is &quot;Node,RBAC&quot;; using &quot;Node,RBAC&quot;</span><br><span class="line">[check-etcd] Checking that the etcd cluster is healthy</span><br><span class="line">[kubelet-start] Downloading configuration for the kubelet from the &quot;kubelet-config-1.17&quot; ConfigMap in the kube-system namespace</span><br><span class="line">[kubelet-start] Writing kubelet configuration to file &quot;/var/lib/kubelet/config.yaml&quot;</span><br><span class="line">[kubelet-start] Writing kubelet environment file with flags to file &quot;/var/lib/kubelet/kubeadm-flags.env&quot;</span><br><span class="line">[kubelet-start] Starting the kubelet</span><br><span class="line">[kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap...</span><br><span class="line">[etcd] Announced new etcd member joining to the existing etcd cluster</span><br><span class="line">[etcd] Creating static Pod manifest for &quot;etcd&quot;</span><br><span class="line">[etcd] Waiting for the new etcd member to join the cluster. This can take up to 40s</span><br><span class="line">&#123;&quot;level&quot;:&quot;warn&quot;,&quot;ts&quot;:&quot;2020-03-15T11:49:56.765+0800&quot;,&quot;caller&quot;:&quot;clientv3/retry_interceptor.go:61&quot;,&quot;msg&quot;:&quot;retrying of unary invoker failed&quot;,&quot;target&quot;:&quot;passthrough:///https://192.168.112.130:2379&quot;,&quot;attempt&quot;:0,&quot;error&quot;:&quot;rpc error: code = DeadlineExceeded desc = context deadline exceeded&quot;&#125;</span><br><span class="line">[upload-config] Storing the configuration used in ConfigMap &quot;kubeadm-config&quot; in the &quot;kube-system&quot; Namespace</span><br><span class="line">[mark-control-plane] Marking the node master03 as control-plane by adding the label &quot;node-role.kubernetes.io/master=&apos;&apos;&quot;</span><br><span class="line">[mark-control-plane] Marking the node master03 as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule]</span><br><span class="line"></span><br><span class="line">This node has joined the cluster and a new control plane instance was created:</span><br><span class="line"></span><br><span class="line">* Certificate signing request was sent to apiserver and approval was received.</span><br><span class="line">* The Kubelet was informed of the new secure connection details.</span><br><span class="line">* Control plane (master) label and taint were applied to the new node.</span><br><span class="line">* The Kubernetes control plane instances scaled up.</span><br><span class="line">* A new etcd member was added to the local/stacked etcd cluster.</span><br><span class="line"></span><br><span class="line">To start administering your cluster from this node, you need to run the following as a regular user:</span><br><span class="line"></span><br><span class="line">	mkdir -p $HOME/.kube</span><br><span class="line">	sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">	sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br><span class="line"></span><br><span class="line">Run &apos;kubectl get nodes&apos; to see this node join the cluster.</span><br><span class="line"></span><br><span class="line">------------------------------------------------------------------------------------------------------------------------------------------------</span><br></pre></td></tr></table></figure>
<h2 id="6-Kubernetes-Control-Plane的三个节点上分别配置Kubectl访问权限"><a href="#6-Kubernetes-Control-Plane的三个节点上分别配置Kubectl访问权限" class="headerlink" title="6. Kubernetes Control Plane的三个节点上分别配置Kubectl访问权限"></a>6. Kubernetes Control Plane的三个节点上分别配置Kubectl访问权限</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 在master01、master02和master03上分别执行</span><br><span class="line">rm -rf $HOME/.kube</span><br><span class="line">mkdir -p $HOME/.kube</span><br><span class="line">cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">chown $(id -u):$(id -g) $HOME/.kube/config</span><br></pre></td></tr></table></figure>
<h2 id="7-高可用部署的Stack结构验证"><a href="#7-高可用部署的Stack结构验证" class="headerlink" title="7. 高可用部署的Stack结构验证"></a>7. 高可用部署的Stack结构验证</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"># 在master01、master02和master03中的任意一个master执行都可以</span><br><span class="line">kubectl get pod --all-namespaces -o wide</span><br><span class="line">------------------------------------------------------------------------------------------------------------------------------------------------</span><br><span class="line">NAMESPACE     NAME                                       READY   STATUS    RESTARTS   AGE     IP                NODE       NOMINATED NODE   READINESS GATES</span><br><span class="line">kube-system   calico-kube-controllers-648f4868b8-gszmn   1/1     Running   0          2m36s   10.211.235.1      master03   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   calico-node-dk4s6                          1/1     Running   0          2m36s   192.168.112.128   master01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   calico-node-lhj5p                          1/1     Running   0          2m36s   192.168.112.129   master02   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   calico-node-tscpz                          1/1     Running   0          2m36s   192.168.112.130   master03   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   coredns-7f9c544f75-9w4kn                   1/1     Running   0          12m     10.211.59.193     master02   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   coredns-7f9c544f75-xvsbn                   1/1     Running   0          12m     10.211.59.194     master02   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   etcd-master01                              1/1     Running   0          12m     192.168.112.128   master01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   etcd-master02                              1/1     Running   0          5m58s   192.168.112.129   master02   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   etcd-master03                              1/1     Running   0          3m46s   192.168.112.130   master03   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   kube-apiserver-master01                    1/1     Running   0          12m     192.168.112.128   master01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   kube-apiserver-master02                    1/1     Running   0          5m59s   192.168.112.129   master02   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   kube-apiserver-master03                    1/1     Running   0          3m46s   192.168.112.130   master03   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   kube-controller-manager-master01           1/1     Running   1          12m     192.168.112.128   master01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   kube-controller-manager-master02           1/1     Running   0          5m59s   192.168.112.129   master02   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   kube-controller-manager-master03           1/1     Running   0          3m46s   192.168.112.130   master03   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   kube-haproxy-master01                      1/1     Running   0          12m     192.168.112.128   master01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   kube-keepalived-master01                   1/1     Running   0          12m     192.168.112.128   master01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   kube-proxy-6fw8x                           1/1     Running   0          12m     192.168.112.128   master01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   kube-proxy-7hkv7                           1/1     Running   0          6m      192.168.112.129   master02   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   kube-proxy-9trwk                           1/1     Running   0          3m47s   192.168.112.130   master03   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   kube-scheduler-master01                    1/1     Running   1          12m     192.168.112.128   master01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   kube-scheduler-master02                    1/1     Running   0          5m59s   192.168.112.129   master02   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   kube-scheduler-master03                    1/1     Running   0          3m46s   192.168.112.130   master03   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">------------------------------------------------------------------------------------------------------------------------------------------------</span><br><span class="line"></span><br><span class="line"># 在master01、master02和master03中的任意一个master执行都可以</span><br><span class="line">kubectl get node -o wide</span><br><span class="line">------------------------------------------------------------------------------------------------------------------------------------------------</span><br><span class="line">NAME       STATUS   ROLES    AGE     VERSION   INTERNAL-IP       EXTERNAL-IP   OS-IMAGE                KERNEL-VERSION                CONTAINER-RUNTIME</span><br><span class="line">master01   Ready    master   13m     v1.17.0   192.168.112.128   &lt;none&gt;        CentOS Linux 7 (Core)   3.10.0-1062.12.1.el7.x86_64   docker://18.9.9</span><br><span class="line">master02   Ready    master   6m40s   v1.17.0   192.168.112.129   &lt;none&gt;        CentOS Linux 7 (Core)   3.10.0-1062.12.1.el7.x86_64   docker://18.9.9</span><br><span class="line">master03   Ready    master   4m27s   v1.17.0   192.168.112.130   &lt;none&gt;        CentOS Linux 7 (Core)   3.10.0-1062.12.1.el7.x86_64   docker://18.9.9</span><br><span class="line">------------------------------------------------------------------------------------------------------------------------------------------------</span><br></pre></td></tr></table></figure>
<h2 id="8-确认etcd的健康状况"><a href="#8-确认etcd的健康状况" class="headerlink" title="8. 确认etcd的健康状况"></a>8. 确认etcd的健康状况</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"># master01、master02和master03上分别执行，这里以master01为例</span><br><span class="line">kubectl exec -it etcd-master01 /bin/sh -n kube-system</span><br><span class="line"></span><br><span class="line">etcdctl --endpoints=https://127.0.0.1:2379 --cacert=/etc/kubernetes/pki/etcd/ca.crt --cert=/etc/kubernetes/pki/etcd/server.crt --key=/etc/kubernetes/pki/etcd/server.key member list</span><br><span class="line">------------------------------------------------------------------------------------------------------------------------------------------------</span><br><span class="line">ade36780a0899522, started, master01, https://192.168.112.128:2380, https://192.168.112.128:2379, false</span><br><span class="line">b4a6061544dbd63b, started, master03, https://192.168.112.130:2380, https://192.168.112.130:2379, false</span><br><span class="line">ecaa91fc374ff6f0, started, master02, https://192.168.112.129:2380, https://192.168.112.129:2379, false</span><br><span class="line">------------------------------------------------------------------------------------------------------------------------------------------------</span><br><span class="line"></span><br><span class="line">etcdctl --endpoints=https://127.0.0.1:2379 --cacert=/etc/kubernetes/pki/etcd/ca.crt --cert=/etc/kubernetes/pki/etcd/server.crt --key=/etc/kubernetes/pki/etcd/server.key endpoint health</span><br><span class="line">------------------------------------------------------------------------------------------------------------------------------------------------</span><br><span class="line">https://127.0.0.1:2379 is healthy: successfully committed proposal: took = 9.338525ms</span><br><span class="line">------------------------------------------------------------------------------------------------------------------------------------------------</span><br><span class="line"></span><br><span class="line">etcdctl --endpoints=https://127.0.0.1:2379 --cacert=/etc/kubernetes/pki/etcd/ca.crt --cert=/etc/kubernetes/pki/etcd/server.crt --key=/etc/kubernetes/pki/etcd/server.key endpoint status</span><br><span class="line">------------------------------------------------------------------------------------------------------------------------------------------------</span><br><span class="line">https://127.0.0.1:2379, ade36780a0899522, 3.4.3, 2.6 MB, false, false, 21, 53251, 53251,</span><br><span class="line">------------------------------------------------------------------------------------------------------------------------------------------------</span><br></pre></td></tr></table></figure>
<h2 id="9-为高可用集群添加两个Node"><a href="#9-为高可用集群添加两个Node" class="headerlink" title="9. 为高可用集群添加两个Node"></a>9. 为高可用集群添加两个Node</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"># node01上执行（无论是自动分发根证书的方式还是手动分发证书的方式，在这里都没有区别）</span><br><span class="line">kubeadm join 192.168.112.136:8443 --token abcdef.0123456789abcdef \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:33a6370b4bb4a9385c1d878e9a7a085ad969d521e4b309b01be797c0d7867d69</span><br><span class="line">------------------------------------------------------------------------------------------------------------------------------------------------</span><br><span class="line">W0315 11:12:27.853703    9587 join.go:346] [preflight] WARNING: JoinControlPane.controlPlane settings will be ignored when control-plane flag is not set.</span><br><span class="line">[preflight] Running pre-flight checks</span><br><span class="line">[preflight] Reading configuration from the cluster...</span><br><span class="line">[preflight] FYI: You can look at this config file with &apos;kubectl -n kube-system get cm kubeadm-config -oyaml&apos;</span><br><span class="line">[kubelet-start] Downloading configuration for the kubelet from the &quot;kubelet-config-1.17&quot; ConfigMap in the kube-system namespace</span><br><span class="line">[kubelet-start] Writing kubelet configuration to file &quot;/var/lib/kubelet/config.yaml&quot;</span><br><span class="line">[kubelet-start] Writing kubelet environment file with flags to file &quot;/var/lib/kubelet/kubeadm-flags.env&quot;</span><br><span class="line">[kubelet-start] Starting the kubelet</span><br><span class="line">[kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap...</span><br><span class="line"></span><br><span class="line">This node has joined the cluster:</span><br><span class="line">* Certificate signing request was sent to apiserver and a response was received.</span><br><span class="line">* The Kubelet was informed of the new secure connection details.</span><br><span class="line"></span><br><span class="line">Run &apos;kubectl get nodes&apos; on the control-plane to see this node join the cluster.</span><br><span class="line"></span><br><span class="line">------------------------------------------------------------------------------------------------------------------------------------------------</span><br><span class="line"></span><br><span class="line"># node02上执行（无论是自动分发根证书的方式还是手动分发证书的方式，在这里都没有区别）</span><br><span class="line">kubeadm join 192.168.112.136:8443 --token abcdef.0123456789abcdef \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:33a6370b4bb4a9385c1d878e9a7a085ad969d521e4b309b01be797c0d7867d69</span><br><span class="line">------------------------------------------------------------------------------------------------------------------------------------------------</span><br><span class="line">W0315 11:13:18.680949    9561 join.go:346] [preflight] WARNING: JoinControlPane.controlPlane settings will be ignored when control-plane flag is not set.</span><br><span class="line">[preflight] Running pre-flight checks</span><br><span class="line">[preflight] Reading configuration from the cluster...</span><br><span class="line">[preflight] FYI: You can look at this config file with &apos;kubectl -n kube-system get cm kubeadm-config -oyaml&apos;</span><br><span class="line">[kubelet-start] Downloading configuration for the kubelet from the &quot;kubelet-config-1.17&quot; ConfigMap in the kube-system namespace</span><br><span class="line">[kubelet-start] Writing kubelet configuration to file &quot;/var/lib/kubelet/config.yaml&quot;</span><br><span class="line">[kubelet-start] Writing kubelet environment file with flags to file &quot;/var/lib/kubelet/kubeadm-flags.env&quot;</span><br><span class="line">[kubelet-start] Starting the kubelet</span><br><span class="line">[kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap...</span><br><span class="line"></span><br><span class="line">This node has joined the cluster:</span><br><span class="line">* Certificate signing request was sent to apiserver and a response was received.</span><br><span class="line">* The Kubelet was informed of the new secure connection details.</span><br><span class="line"></span><br><span class="line">Run &apos;kubectl get nodes&apos; on the control-plane to see this node join the cluster.</span><br><span class="line"></span><br><span class="line">------------------------------------------------------------------------------------------------------------------------------------------------</span><br><span class="line"></span><br><span class="line"># 在master01、master02和master03中的任意一个master执行都可以</span><br><span class="line">kubectl get node -o wide</span><br><span class="line">------------------------------------------------------------------------------------------------------------------------------------------------</span><br><span class="line">NAME       STATUS   ROLES    AGE     VERSION   INTERNAL-IP       EXTERNAL-IP   OS-IMAGE                KERNEL-VERSION                CONTAINER-RUNTIME</span><br><span class="line">master01   Ready    master   23m     v1.17.0   192.168.112.128   &lt;none&gt;        CentOS Linux 7 (Core)   3.10.0-1062.12.1.el7.x86_64   docker://18.9.9</span><br><span class="line">master02   Ready    master   17m     v1.17.0   192.168.112.129   &lt;none&gt;        CentOS Linux 7 (Core)   3.10.0-1062.12.1.el7.x86_64   docker://18.9.9</span><br><span class="line">master03   Ready    master   15m     v1.17.0   192.168.112.130   &lt;none&gt;        CentOS Linux 7 (Core)   3.10.0-1062.12.1.el7.x86_64   docker://18.9.9</span><br><span class="line">node01     Ready    &lt;none&gt;   4m59s   v1.17.0   192.168.112.131   &lt;none&gt;        CentOS Linux 7 (Core)   3.10.0-1062.12.1.el7.x86_64   docker://18.9.9</span><br><span class="line">node02     Ready    &lt;none&gt;   4m8s    v1.17.0   192.168.112.132   &lt;none&gt;        CentOS Linux 7 (Core)   3.10.0-1062.12.1.el7.x86_64   docker://18.9.9</span><br><span class="line">------------------------------------------------------------------------------------------------------------------------------------------------</span><br><span class="line"></span><br><span class="line"># 在master01、master02和master03中的任意一个master执行都可以</span><br><span class="line">kubectl get pod --all-namespaces -o wide</span><br><span class="line">------------------------------------------------------------------------------------------------------------------------------------------------</span><br><span class="line">NAMESPACE     NAME                                       READY   STATUS    RESTARTS   AGE     IP                NODE       NOMINATED NODE   READINESS GATES</span><br><span class="line">kube-system   calico-kube-controllers-648f4868b8-gszmn   1/1     Running   0          14m     10.211.235.1      master03   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   calico-node-dk4s6                          1/1     Running   0          14m     192.168.112.128   master01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   calico-node-lhj5p                          1/1     Running   0          14m     192.168.112.129   master02   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   calico-node-lkl66                          1/1     Running   0          4m43s   192.168.112.132   node02     &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   calico-node-ncjc4                          1/1     Running   0          5m34s   192.168.112.131   node01     &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   calico-node-tscpz                          1/1     Running   0          14m     192.168.112.130   master03   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   coredns-7f9c544f75-9w4kn                   1/1     Running   0          24m     10.211.59.193     master02   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   coredns-7f9c544f75-xvsbn                   1/1     Running   0          24m     10.211.59.194     master02   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   etcd-master01                              1/1     Running   0          24m     192.168.112.128   master01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   etcd-master02                              1/1     Running   0          18m     192.168.112.129   master02   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   etcd-master03                              1/1     Running   0          15m     192.168.112.130   master03   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   kube-apiserver-master01                    1/1     Running   0          24m     192.168.112.128   master01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   kube-apiserver-master02                    1/1     Running   0          18m     192.168.112.129   master02   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   kube-apiserver-master03                    1/1     Running   0          15m     192.168.112.130   master03   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   kube-controller-manager-master01           1/1     Running   1          24m     192.168.112.128   master01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   kube-controller-manager-master02           1/1     Running   0          18m     192.168.112.129   master02   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   kube-controller-manager-master03           1/1     Running   0          15m     192.168.112.130   master03   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   kube-haproxy-master01                      1/1     Running   0          24m     192.168.112.128   master01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   kube-keepalived-master01                   1/1     Running   0          24m     192.168.112.128   master01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   kube-proxy-6fw8x                           1/1     Running   0          24m     192.168.112.128   master01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   kube-proxy-7hkv7                           1/1     Running   0          18m     192.168.112.129   master02   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   kube-proxy-96cz5                           1/1     Running   0          5m34s   192.168.112.131   node01     &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   kube-proxy-9trwk                           1/1     Running   0          15m     192.168.112.130   master03   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   kube-proxy-pwslt                           1/1     Running   0          4m43s   192.168.112.132   node02     &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   kube-scheduler-master01                    1/1     Running   1          24m     192.168.112.128   master01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   kube-scheduler-master02                    1/1     Running   0          18m     192.168.112.129   master02   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   kube-scheduler-master03                    1/1     Running   0          15m     192.168.112.130   master03   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">------------------------------------------------------------------------------------------------------------------------------------------------</span><br></pre></td></tr></table></figure>
<h1 id="五、关于所有节点（Master和Node）的重置"><a href="#五、关于所有节点（Master和Node）的重置" class="headerlink" title="五、关于所有节点（Master和Node）的重置"></a>五、关于所有节点（Master和Node）的重置</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubeadm reset</span><br><span class="line">rm -rf /etc/kubernetes/ /var/lib/etcd/ /etc/cni/ $HOME/.kube/</span><br><span class="line">reboot</span><br></pre></td></tr></table></figure>
<h1 id="六、参考资料"><a href="#六、参考资料" class="headerlink" title="六、参考资料"></a>六、参考资料</h1><h2 id="1-官方资料（官方最新版本v1-17）"><a href="#1-官方资料（官方最新版本v1-17）" class="headerlink" title="1. 官方资料（官方最新版本v1.17）"></a>1. 官方资料（官方最新版本v1.17）</h2><p><a href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/ha-topology/" target="_blank" rel="noopener">https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/ha-topology/</a><br><a href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/high-availability/" target="_blank" rel="noopener">https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/high-availability/</a></p>
<h2 id="2-第三方资料（因Kubernetes-从v1-15开始到v1-17，kubeadm的安装方式和二进制安装方式基本相同，故v1-15的资料可以供v1-17参考）"><a href="#2-第三方资料（因Kubernetes-从v1-15开始到v1-17，kubeadm的安装方式和二进制安装方式基本相同，故v1-15的资料可以供v1-17参考）" class="headerlink" title="2. 第三方资料（因Kubernetes 从v1.15开始到v1.17，kubeadm的安装方式和二进制安装方式基本相同，故v1.15的资料可以供v1.17参考）"></a>2. 第三方资料（因Kubernetes 从v1.15开始到v1.17，kubeadm的安装方式和二进制安装方式基本相同，故v1.15的资料可以供v1.17参考）</h2><p><a href="https://www.cnblogs.com/lingfenglian/p/11753590.html" target="_blank" rel="noopener">https://www.cnblogs.com/lingfenglian/p/11753590.html</a><br><a href="https://blog.51cto.com/fengwan/2426528?source=dra" target="_blank" rel="noopener">https://blog.51cto.com/fengwan/2426528?source=dra</a><br><a href="https://my.oschina.net/beyondken/blog/1935402" target="_blank" rel="noopener">https://my.oschina.net/beyondken/blog/1935402</a><br><a href="https://www.cnblogs.com/shenlinken/p/9968274.html" target="_blank" rel="noopener">https://www.cnblogs.com/shenlinken/p/9968274.html</a> </p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Docker/">Docker</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Highly-Available/">Highly Available</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Kubeadm/">Kubeadm</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Kubernetes/">Kubernetes</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Setup/">Setup</a></li></ul>
	</div>

      
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/容器云技术/">容器云技术</a>
	</div>


      
      <div class="clearfix"></div>
    </div>
      
    
  </div>
  
</article>







  
    <article id="post-kubernetes_harbor_000" class="article article-type-post" itemscope="" itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2020/03/04/kubernetes_harbor_000/" class="article-date">
  	<time datetime="2020-03-04T08:53:40.160Z" itemprop="datePublished">2020-03-04</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/03/04/kubernetes_harbor_000/">
        Kubernetes Harbor 的安装、配置和使用
        
      </a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="一、实验环境版本信息"><a href="#一、实验环境版本信息" class="headerlink" title="一、实验环境版本信息"></a>一、实验环境版本信息</h1><h2 id="1-操作系统的版本信息"><a href="#1-操作系统的版本信息" class="headerlink" title="1. 操作系统的版本信息"></a>1. 操作系统的版本信息</h2><p>CentOS Linux release 7.6.1810 (Core)</p>
<h2 id="2-各组件的版本信息"><a href="#2-各组件的版本信息" class="headerlink" title="2. 各组件的版本信息"></a>2. 各组件的版本信息</h2><h3 id="kubernetes-cluster-v1-17-0，推荐使用kubeadm-v1-17-0-进行试验"><a href="#kubernetes-cluster-v1-17-0，推荐使用kubeadm-v1-17-0-进行试验" class="headerlink" title="kubernetes cluster v1.17.0，推荐使用kubeadm v1.17.0 进行试验"></a>kubernetes cluster v1.17.0，推荐使用kubeadm v1.17.0 进行试验</h3><p>etcd v3.4.3<br>kube-apiserver v1.17.0<br>kube-controller-manager v1.17.0<br>kube-scheduler v1.17.0<br>kubectl v1.17.0<br>helm v3.1.0</p>
<p>docker 18.09.9<br>kubelet v1.17.0<br>calico v3.11.1</p>
<h3 id="kubernetes-harbor，使用容器化的方式部署"><a href="#kubernetes-harbor，使用容器化的方式部署" class="headerlink" title="kubernetes harbor，使用容器化的方式部署"></a>kubernetes harbor，使用容器化的方式部署</h3><p>kubernetes harbor v1.10.1</p>
<h1 id="二、在-Node-节点上准备Docker镜像"><a href="#二、在-Node-节点上准备Docker镜像" class="headerlink" title="二、在 Node 节点上准备Docker镜像"></a>二、在 Node 节点上准备Docker镜像</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">docker pull goharbor/clair-adapter-photon:v1.0.1-v1.10.1</span><br><span class="line">docker pull goharbor/clair-photon:v2.1.1-v1.10.1</span><br><span class="line">docker pull goharbor/notary-server-photon:v0.6.1-v1.10.1</span><br><span class="line">docker pull goharbor/harbor-core:v1.10.1</span><br><span class="line">docker pull goharbor/harbor-portal:v1.10.1</span><br><span class="line">docker pull goharbor/chartmuseum-photon:v0.9.0-v1.10.1</span><br><span class="line">docker pull goharbor/redis-photon:v1.10.1</span><br><span class="line">docker pull goharbor/notary-signer-photon:v0.6.1-v1.10.1</span><br><span class="line">docker pull goharbor/harbor-registryctl:v1.10.1</span><br><span class="line">docker pull goharbor/registry-photon:v2.7.1-patch-2819-2553-v1.10.1</span><br><span class="line">docker pull goharbor/harbor-jobservice:v1.10.1</span><br><span class="line">docker pull goharbor/harbor-db:v1.10.1</span><br></pre></td></tr></table></figure>
<h1 id="三、安装和配置-Kubernetes-Harbor"><a href="#三、安装和配置-Kubernetes-Harbor" class="headerlink" title="三、安装和配置 Kubernetes Harbor"></a>三、安装和配置 Kubernetes Harbor</h1><h2 id="1-安装-Helm-3-包管理工具"><a href="#1-安装-Helm-3-包管理工具" class="headerlink" title="1. 安装 Helm 3 包管理工具"></a>1. 安装 Helm 3 包管理工具</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># curl -o helm-v3.1.0-linux-amd64.tar.gz https://get.helm.sh/helm-v3.1.0-linux-amd64.tar.gz</span><br><span class="line"># tar -zxvf helm-v3.1.0-linux-amd64.tar.gz</span><br><span class="line"># cd linux-amd64/</span><br><span class="line"># cp helm /usr/local/bin/</span><br><span class="line"></span><br><span class="line"># helm version</span><br><span class="line">version.BuildInfo&#123;Version:&quot;v3.1.0&quot;, GitCommit:&quot;b29d20baf09943e134c2fa5e1e1cab3bf93315fa&quot;, GitTreeState:&quot;clean&quot;, GoVersion:&quot;go1.13.7&quot;&#125;</span><br></pre></td></tr></table></figure>
<h2 id="2-在-Kubernetes-集群中加入动态存储供应的支持，并配置相关的-StorageClass-对象"><a href="#2-在-Kubernetes-集群中加入动态存储供应的支持，并配置相关的-StorageClass-对象" class="headerlink" title="2. 在 Kubernetes 集群中加入动态存储供应的支持，并配置相关的 StorageClass 对象"></a>2. 在 Kubernetes 集群中加入动态存储供应的支持，并配置相关的 StorageClass 对象</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">## 本文以安装了NFS Client Provisioner为例，下面是我环境中的相关资源对象展示，请依据实际环境进行配置。我环境中的 StorageClass 对象叫 managed-nfs-storage </span><br><span class="line"># kubectl get pod -n storage -o wide</span><br><span class="line">NAME                                      READY   STATUS    RESTARTS   AGE   IP               NODE     NOMINATED NODE   READINESS GATES</span><br><span class="line">nfs-client-provisioner-6c45d64447-hrjhq   1/1     Running   2          21h   10.211.196.155   node01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line"></span><br><span class="line"># kubectl get storageclass managed-nfs-storage -o yaml</span><br><span class="line">apiVersion: storage.k8s.io/v1</span><br><span class="line">kind: StorageClass</span><br><span class="line">metadata:</span><br><span class="line">  creationTimestamp: &quot;2020-03-03T12:10:27Z&quot;</span><br><span class="line">  name: managed-nfs-storage</span><br><span class="line">  resourceVersion: &quot;27152&quot;</span><br><span class="line">  selfLink: /apis/storage.k8s.io/v1/storageclasses/managed-nfs-storage</span><br><span class="line">  uid: 05c23ff9-5f9a-4a6b-89dd-ed99013cc344</span><br><span class="line">mountOptions:</span><br><span class="line">- vers=4</span><br><span class="line">parameters:</span><br><span class="line">  archiveOnDelete: &quot;false&quot;</span><br><span class="line">provisioner: fuseim.pri/ifs</span><br><span class="line">reclaimPolicy: Delete</span><br><span class="line">volumeBindingMode: Immediate</span><br><span class="line"></span><br><span class="line"># kubectl get storageclass -o wide</span><br><span class="line">NAME                  PROVISIONER      RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE</span><br><span class="line">managed-nfs-storage   fuseim.pri/ifs   Delete          Immediate           false                  21h</span><br></pre></td></tr></table></figure>
<h2 id="3-使用-Helm-3-安装-Kubernetes-Harbor"><a href="#3-使用-Helm-3-安装-Kubernetes-Harbor" class="headerlink" title="3. 使用 Helm 3 安装 Kubernetes Harbor"></a>3. 使用 Helm 3 安装 Kubernetes Harbor</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br></pre></td><td class="code"><pre><span class="line"># git clone https://github.com/goharbor/harbor-helm.git</span><br><span class="line"># cd harbor-helm/</span><br><span class="line"># git checkout -b v1.3.1.tag v1.3.1</span><br><span class="line"># git diff values.yaml</span><br><span class="line">diff --git a/values.yaml b/values.yaml</span><br><span class="line">index b201d98..fdc5593 100644</span><br><span class="line">--- a/values.yaml</span><br><span class="line">+++ b/values.yaml</span><br><span class="line">@@ -26,8 +26,8 @@ expose:</span><br><span class="line">     commonName: &quot;&quot;</span><br><span class="line">   ingress:</span><br><span class="line">     hosts:</span><br><span class="line">-      core: core.harbor.domain</span><br><span class="line">-      notary: notary.harbor.domain</span><br><span class="line">+      core: core.harbor.singhwang.com</span><br><span class="line">+      notary: notary.harbor.singhwang.com</span><br><span class="line">     # set to the type of ingress controller if it has specific requirements.</span><br><span class="line">     # leave as `default` for most ingress controllers.</span><br><span class="line">     # set to `gce` if using the GCE ingress controller</span><br><span class="line">@@ -98,7 +98,7 @@ expose:</span><br><span class="line"> # the IP address of k8s node</span><br><span class="line"> #</span><br><span class="line"> # If Harbor is deployed behind the proxy, set it as the URL of proxy</span><br><span class="line">-externalURL: https://core.harbor.domain</span><br><span class="line">+externalURL: https://core.harbor.singhwang.com</span><br><span class="line"></span><br><span class="line"> # The persistence is enabled by default and a default StorageClass</span><br><span class="line"> # is needed in the k8s cluster to provision volumes dynamicly.</span><br><span class="line">@@ -120,19 +120,19 @@ persistence:</span><br><span class="line">       # Specify the &quot;storageClass&quot; used to provision the volume. Or the default</span><br><span class="line">       # StorageClass will be used(the default).</span><br><span class="line">       # Set it to &quot;-&quot; to disable dynamic provisioning</span><br><span class="line">-      storageClass: &quot;&quot;</span><br><span class="line">+      storageClass: &quot;managed-nfs-storage&quot;</span><br><span class="line">       subPath: &quot;&quot;</span><br><span class="line">       accessMode: ReadWriteOnce</span><br><span class="line">       size: 5Gi</span><br><span class="line">     chartmuseum:</span><br><span class="line">       existingClaim: &quot;&quot;</span><br><span class="line">-      storageClass: &quot;&quot;</span><br><span class="line">+      storageClass: &quot;managed-nfs-storage&quot;</span><br><span class="line">       subPath: &quot;&quot;</span><br><span class="line">       accessMode: ReadWriteOnce</span><br><span class="line">       size: 5Gi</span><br><span class="line">     jobservice:</span><br><span class="line">       existingClaim: &quot;&quot;</span><br><span class="line">-      storageClass: &quot;&quot;</span><br><span class="line">+      storageClass: &quot;managed-nfs-storage&quot;</span><br><span class="line">       subPath: &quot;&quot;</span><br><span class="line">       accessMode: ReadWriteOnce</span><br><span class="line">       size: 1Gi</span><br><span class="line">@@ -140,7 +140,7 @@ persistence:</span><br><span class="line">     # be ignored</span><br><span class="line">     database:</span><br><span class="line">       existingClaim: &quot;&quot;</span><br><span class="line">-      storageClass: &quot;&quot;</span><br><span class="line">+      storageClass: &quot;managed-nfs-storage&quot;</span><br><span class="line">       subPath: &quot;&quot;</span><br><span class="line">       accessMode: ReadWriteOnce</span><br><span class="line">       size: 1Gi</span><br><span class="line">@@ -148,7 +148,7 @@ persistence:</span><br><span class="line">     # be ignored</span><br><span class="line">     redis:</span><br><span class="line">       existingClaim: &quot;&quot;</span><br><span class="line">-      storageClass: &quot;&quot;</span><br><span class="line">+      storageClass: &quot;managed-nfs-storage&quot;</span><br><span class="line">       subPath: &quot;&quot;</span><br><span class="line">       accessMode: ReadWriteOnce</span><br><span class="line">       size: 1Gi</span><br><span class="line">@@ -250,7 +250,7 @@ updateStrategy:</span><br><span class="line"> logLevel: info</span><br><span class="line"></span><br><span class="line"> # The initial password of Harbor admin. Change it from portal after launching Harbor</span><br><span class="line">-harborAdminPassword: &quot;Harbor12345&quot;</span><br><span class="line">+harborAdminPassword: &quot;190708&quot;</span><br><span class="line"> # The secret key used for encryption. Must be a string of 16 chars.</span><br><span class="line"> secretKey: &quot;not-a-secure-key&quot;</span><br><span class="line">## 按照上述git对比出来的变化进行修改，storageClass 字段的请依据自己的环境进行配置，比如我环境里的叫 managed-nfs-storage</span><br><span class="line"></span><br><span class="line"># helm install harbor harbor-helm --namespace registry</span><br><span class="line"># helm list -n registry</span><br><span class="line">NAME  	NAMESPACE	REVISION	UPDATED                                	STATUS  	CHART       	APP VERSION</span><br><span class="line">harbor	registry 	1       	2020-03-04 11:05:18.297145404 +0800 CST	deployed	harbor-1.3.1	1.10.1</span><br><span class="line"></span><br><span class="line"># kubectl get pod -n registry -o wide</span><br><span class="line">NAME                                           READY   STATUS    RESTARTS   AGE    IP               NODE     NOMINATED NODE   READINESS GATES</span><br><span class="line">harbor-harbor-chartmuseum-6cc998b954-b65jc     1/1     Running   2          6h7m   10.211.140.95    node02   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">harbor-harbor-clair-654dcfd8bf-tk98w           2/2     Running   10         6h7m   10.211.196.153   node01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">harbor-harbor-core-85b965488d-tp7jv            1/1     Running   4          6h7m   10.211.196.156   node01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">harbor-harbor-database-0                       1/1     Running   2          6h7m   10.211.140.94    node02   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">harbor-harbor-jobservice-5f489d87b9-sl57q      1/1     Running   2          6h7m   10.211.140.89    node02   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">harbor-harbor-notary-server-795ccb7bb6-ngfml   1/1     Running   7          6h7m   10.211.196.152   node01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">harbor-harbor-notary-signer-7595696bf9-kvkk7   1/1     Running   8          6h7m   10.211.140.87    node02   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">harbor-harbor-portal-5cbc6d5897-gm2rc          1/1     Running   2          6h7m   10.211.196.154   node01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">harbor-harbor-redis-0                          1/1     Running   2          6h7m   10.211.140.93    node02   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">harbor-harbor-registry-75c4f4cc9b-8h72h        2/2     Running   4          6h7m   10.211.140.88    node02   &lt;none&gt;           &lt;none&gt;</span><br></pre></td></tr></table></figure>
<h1 id="四、使用说明"><a href="#四、使用说明" class="headerlink" title="四、使用说明"></a>四、使用说明</h1><ol>
<li><p>获取 ingress 资源对象中的 HOSTS 和 ADDRESS 在访问端做好 hosts 映射，条件允许的话，也可以配置为网络中的 DNS 记录</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># kubectl get ingress -n registry -o wide</span><br><span class="line">NAME                    HOSTS                                                   ADDRESS                           PORTS     AGE</span><br><span class="line">harbor-harbor-ingress   core.harbor.singhwang.com,notary.harbor.singhwang.com   192.168.112.129,192.168.112.130   80, 443   7h7m</span><br></pre></td></tr></table></figure>
</li>
<li><p>访问 Kubernetes Harbor 服务并登陆 <a href="https://core.harbor.singhwang.com" target="_blank" rel="noopener">https://core.harbor.singhwang.com</a><br><img src="/2020/03/04/kubernetes_harbor_000/login_01.png" alt="login_01"><br><img src="/2020/03/04/kubernetes_harbor_000/login_02.png" alt="login_02"></p>
</li>
<li><p>在 Kubernetes Harbor 中创建项目<br><img src="/2020/03/04/kubernetes_harbor_000/project_01.png" alt="project_01"><br><img src="/2020/03/04/kubernetes_harbor_000/project_02.png" alt="project_02"></p>
</li>
<li><p>需要使用镜像仓库的Node节点上完成证书的配置</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">## 创建证书目录</span><br><span class="line"># mkdir -p /etc/docker/certs.d/core.harbor.singhwang.com/</span><br><span class="line"></span><br><span class="line">## 获取证书内容</span><br><span class="line"># kubectl get secrets harbor-harbor-ingress -n registry -o jsonpath=&quot;&#123;.data.ca\.crt&#125;&quot; | base64 --decode</span><br><span class="line"></span><br><span class="line">## 根据证书内容生成证书文件</span><br><span class="line">cat &lt;&lt;EOF &gt; /etc/docker/certs.d/core.harbor.singhwang.com/ca.crt</span><br><span class="line">。。。这里替换为证书内容。。。</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>
</li>
<li><p>在命令行窗口中推送镜像到项目下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"># docker login core.harbor.singhwang.com</span><br><span class="line">Username: admin</span><br><span class="line">Password:</span><br><span class="line">WARNING! Your password will be stored unencrypted in /root/.docker/config.json.</span><br><span class="line">Configure a credential helper to remove this warning. See</span><br><span class="line">https://docs.docker.com/engine/reference/commandline/login/#credentials-store</span><br><span class="line"></span><br><span class="line">Login Succeeded</span><br><span class="line"></span><br><span class="line"># docker tag nginx:1.7.9 core.harbor.singhwang.com/demo/nginx:1.7.9</span><br><span class="line"></span><br><span class="line"># docker push core.harbor.singhwang.com/demo/nginx:1.7.9</span><br><span class="line">The push refers to repository [core.harbor.singhwang.com/demo/nginx]</span><br><span class="line">5f70bf18a086: Pushed</span><br><span class="line">4b26ab29a475: Pushed</span><br><span class="line">ccb1d68e3fb7: Pushed</span><br><span class="line">e387107e2065: Pushed</span><br><span class="line">63bf84221cce: Pushed</span><br><span class="line">e02dce553481: Pushed</span><br><span class="line">dea2e4984e29: Pushed</span><br><span class="line">1.7.9: digest: sha256:b1f5935eb2e9e2ae89c0b3e2e148c19068d91ca502e857052f14db230443e4c2 size: 3012</span><br><span class="line"></span><br><span class="line"># docker logout core.harbor.singhwang.com</span><br><span class="line">Removing login credentials for core.harbor.singhwang.com</span><br></pre></td></tr></table></figure>
</li>
<li><p>在 Kubernetes Harbor 中查看推送上去的镜像和推送日志<br><img src="/2020/03/04/kubernetes_harbor_000/image_01.png" alt="image_01"><br><img src="/2020/03/04/kubernetes_harbor_000/log_01.png" alt="log_01"></p>
</li>
</ol>
<h1 id="五、参考资料"><a href="#五、参考资料" class="headerlink" title="五、参考资料"></a>五、参考资料</h1><p><a href="https://github.com/goharbor/harbor-helm/tree/v1.3.1" target="_blank" rel="noopener">https://github.com/goharbor/harbor-helm/tree/v1.3.1</a><br><a href="https://www.cnblogs.com/longgor/p/11203820.html" target="_blank" rel="noopener">https://www.cnblogs.com/longgor/p/11203820.html</a></p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Docker/">Docker</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Harbor/">Harbor</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Kubernetes/">Kubernetes</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Setup/">Setup</a></li></ul>
	</div>

      
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/容器云技术/">容器云技术</a>
	</div>


      
      <div class="clearfix"></div>
    </div>
      
    
  </div>
  
</article>







  
    <article id="post-kubernetes_dashboard_001" class="article article-type-post" itemscope="" itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2020/02/17/kubernetes_dashboard_001/" class="article-date">
  	<time datetime="2020-02-17T07:55:43.013Z" itemprop="datePublished">2020-02-17</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/02/17/kubernetes_dashboard_001/">
        通过 Ingress HTTPS 的方式暴露 Kubernetes Dashboard 服务
        
      </a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="一、实验环境版本信息"><a href="#一、实验环境版本信息" class="headerlink" title="一、实验环境版本信息"></a>一、实验环境版本信息</h1><h2 id="1-操作系统的版本信息"><a href="#1-操作系统的版本信息" class="headerlink" title="1. 操作系统的版本信息"></a>1. 操作系统的版本信息</h2><p>CentOS Linux release 7.6.1810 (Core)</p>
<h2 id="2-各组件的版本信息"><a href="#2-各组件的版本信息" class="headerlink" title="2. 各组件的版本信息"></a>2. 各组件的版本信息</h2><h3 id="kubernetes-cluster-v1-17-0，推荐使用kubeadm-v1-17-0-进行试验"><a href="#kubernetes-cluster-v1-17-0，推荐使用kubeadm-v1-17-0-进行试验" class="headerlink" title="kubernetes cluster v1.17.0，推荐使用kubeadm v1.17.0 进行试验"></a>kubernetes cluster v1.17.0，推荐使用kubeadm v1.17.0 进行试验</h3><p>etcd v3.4.3<br>kube-apiserver v1.17.0<br>kube-controller-manager v1.17.0<br>kube-scheduler v1.17.0<br>kubectl v1.17.0</p>
<p>docker 18.09.9<br>kubelet v1.17.0<br>calico v3.11.1</p>
<h3 id="kubernetes-dashborad，使用容器化的方式部署"><a href="#kubernetes-dashborad，使用容器化的方式部署" class="headerlink" title="kubernetes dashborad，使用容器化的方式部署"></a>kubernetes dashborad，使用容器化的方式部署</h3><p>kubernetes dashboard v2.0.0-rc5 </p>
<h1 id="二、配置以-http-的方式访问-Kubernetes-Dashboard"><a href="#二、配置以-http-的方式访问-Kubernetes-Dashboard" class="headerlink" title="二、配置以 http 的方式访问 Kubernetes Dashboard"></a>二、配置以 http 的方式访问 Kubernetes Dashboard</h1><ol>
<li><p>决定了 Kubernetes Dashboard 以 http 的形式对外提供服务的关键参数</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">## 以 http 对外提供服务时，Kubernetes Dashboard 默认是禁用登录模式的</span><br><span class="line"></span><br><span class="line">## 特别注意：该参数启用后，Kubernetes Dashboard 会监听 8443 端口对外提供 https 服务，并且不会监听 9090 端口提供 http 服务</span><br><span class="line">--auto-generate-certificates</span><br><span class="line"></span><br><span class="line">## 设置 http 监听端口，默认值为 9090。当 --auto-generate-certificates 开启时，经测试该参数无效</span><br><span class="line">--insecure-port</span><br><span class="line"></span><br><span class="line">## 设置 http 监听地址，默认值为 127.0.0.1 </span><br><span class="line">--insecure-bind-address</span><br><span class="line"></span><br><span class="line">## 设置以 http 提供服务时，Kubernetes Dashboard 是否启用登录模式，默认为 false</span><br><span class="line">--enable-insecure-login</span><br></pre></td></tr></table></figure>
</li>
<li><p>决定了 Kubernetes Dashboard 能够启动成功的关键参数</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">## 证书相关的secret对象放在哪个namespace下，通常情况下与 Kubernetes Dashboard 的 pod 所在的 namespace 相同，默认值为 kube-system</span><br><span class="line">--namespace</span><br></pre></td></tr></table></figure>
</li>
<li><p>修改相关的 Kubernetes YAML 部署文件，关闭 https 服务，然后开启 http 服务</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line"># git clone https://github.com/kubernetes/dashboard.git</span><br><span class="line"># cd dashboard/</span><br><span class="line"># git checkout -b v2.0.0-rc5.tag v2.0.0-rc5</span><br><span class="line"># git diff aio/deploy/recommended.yaml</span><br><span class="line">diff --git a/aio/deploy/recommended.yaml b/aio/deploy/recommended.yaml</span><br><span class="line">index 742f616..b8c48bd 100644</span><br><span class="line">--- a/aio/deploy/recommended.yaml</span><br><span class="line">+++ b/aio/deploy/recommended.yaml</span><br><span class="line">@@ -38,8 +38,12 @@ metadata:</span><br><span class="line">   namespace: kubernetes-dashboard</span><br><span class="line"> spec:</span><br><span class="line">   ports:</span><br><span class="line">-    - port: 443</span><br><span class="line">+    - name: https</span><br><span class="line">+      port: 443</span><br><span class="line">       targetPort: 8443</span><br><span class="line">+    - name: http</span><br><span class="line">+      port: 80</span><br><span class="line">+      targetPort: 9090</span><br><span class="line">   selector:</span><br><span class="line">     k8s-app: kubernetes-dashboard</span><br><span class="line"></span><br><span class="line">@@ -188,13 +192,21 @@ spec:</span><br><span class="line">       containers:</span><br><span class="line">         - name: kubernetes-dashboard</span><br><span class="line">           image: kubernetesui/dashboard:v2.0.0-rc5</span><br><span class="line">-          imagePullPolicy: Always</span><br><span class="line">+          imagePullPolicy: IfNotPresent</span><br><span class="line">           ports:</span><br><span class="line">             - containerPort: 8443</span><br><span class="line">               protocol: TCP</span><br><span class="line">+              name: https</span><br><span class="line">+            - containerPort: 9090</span><br><span class="line">+              protocol: TCP</span><br><span class="line">+              name: http</span><br><span class="line">           args:</span><br><span class="line">-            - --auto-generate-certificates</span><br><span class="line">+            # - --auto-generate-certificates</span><br><span class="line">             - --namespace=kubernetes-dashboard</span><br><span class="line">+            # - --insecure-port=9090</span><br><span class="line">+            # - --port=8443</span><br><span class="line">+            # - --insecure-bind-address=0.0.0.0</span><br><span class="line">+            - --enable-insecure-login</span><br><span class="line">             # Uncomment the following line to manually specify Kubernetes API server Host</span><br><span class="line">             # If not specified, Dashboard will attempt to auto discover the API server and connect</span><br><span class="line">             # to it. Uncomment only if the default does not work.</span><br><span class="line">@@ -207,9 +219,12 @@ spec:</span><br><span class="line">               name: tmp-volume</span><br><span class="line">           livenessProbe:</span><br><span class="line">             httpGet:</span><br><span class="line">-              scheme: HTTPS</span><br><span class="line">+              # scheme: HTTPS</span><br><span class="line">+              # path: /</span><br><span class="line">+              # port: 8443</span><br><span class="line">+              scheme: HTTP</span><br><span class="line">               path: /</span><br><span class="line">-              port: 8443</span><br><span class="line">+              port: 9090</span><br><span class="line">             initialDelaySeconds: 30</span><br><span class="line">             timeoutSeconds: 30</span><br><span class="line">           securityContext:</span><br><span class="line">@@ -272,6 +287,7 @@ spec:</span><br><span class="line">       containers:</span><br><span class="line">         - name: dashboard-metrics-scraper</span><br><span class="line">           image: kubernetesui/metrics-scraper:v1.0.3</span><br><span class="line">+          imagePullPolicy: IfNotPresent</span><br><span class="line">           ports:</span><br><span class="line">             - containerPort: 8000</span><br><span class="line">               protocol: TCP</span><br><span class="line">## 按照上述git对比出来的变化进行修改</span><br><span class="line"></span><br><span class="line"># kubectl create -f aio/deploy/recommended.yaml</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h1 id="三、安装-Nginx-Ingress-Controller"><a href="#三、安装-Nginx-Ingress-Controller" class="headerlink" title="三、安装 Nginx Ingress Controller"></a>三、安装 Nginx Ingress Controller</h1><h2 id="1-安装-Helm-3-包管理工具"><a href="#1-安装-Helm-3-包管理工具" class="headerlink" title="1. 安装 Helm 3 包管理工具"></a>1. 安装 Helm 3 包管理工具</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># curl -o helm-v3.1.0-linux-amd64.tar.gz https://get.helm.sh/helm-v3.1.0-linux-amd64.tar.gz</span><br><span class="line"># tar -zxvf helm-v3.1.0-linux-amd64.tar.gz</span><br><span class="line"># cd linux-amd64/</span><br><span class="line"># cp helm /usr/local/bin/</span><br><span class="line"></span><br><span class="line"># helm version</span><br><span class="line">version.BuildInfo&#123;Version:&quot;v3.1.0&quot;, GitCommit:&quot;b29d20baf09943e134c2fa5e1e1cab3bf93315fa&quot;, GitTreeState:&quot;clean&quot;, GoVersion:&quot;go1.13.7&quot;&#125;</span><br></pre></td></tr></table></figure>
<h2 id="2-使用-Helm-3-安装-Nginx-Ingress-Controller"><a href="#2-使用-Helm-3-安装-Nginx-Ingress-Controller" class="headerlink" title="2. 使用 Helm 3 安装 Nginx Ingress Controller"></a>2. 使用 Helm 3 安装 Nginx Ingress Controller</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line">## kubernetes node 上拉取镜像</span><br><span class="line"># docker pull quay.io/kubernetes-ingress-controller/nginx-ingress-controller:0.29.0</span><br><span class="line"># docker pull mirrorgooglecontainers/defaultbackend-amd64:1.5</span><br><span class="line"></span><br><span class="line"># git clone https://github.com/helm/charts.git</span><br><span class="line"># cd charts/</span><br><span class="line"># git checkout -b 43edde894f4b141319e46e4311ddfa576a6973f6.tag 43edde894f4b141319e46e4311ddfa576a6973f6</span><br><span class="line"># git diff stable/nginx-ingress/values.yaml</span><br><span class="line">diff --git a/stable/nginx-ingress/values.yaml b/stable/nginx-ingress/values.yaml</span><br><span class="line">index 270a1d3..107d259 100644</span><br><span class="line">--- a/stable/nginx-ingress/values.yaml</span><br><span class="line">+++ b/stable/nginx-ingress/values.yaml</span><br><span class="line">@@ -28,7 +28,7 @@ controller:</span><br><span class="line">   # Required for use with CNI based kubernetes installations (such as ones set up by kubeadm),</span><br><span class="line">   # since CNI and hostport don&apos;t mix yet. Can be deprecated once https://github.com/kubernetes/kubernetes/issues/23920</span><br><span class="line">   # is merged</span><br><span class="line">-  hostNetwork: false</span><br><span class="line">+  hostNetwork: true</span><br><span class="line"></span><br><span class="line">   # Optionally customize the pod dnsConfig.</span><br><span class="line">   dnsConfig: &#123;&#125;</span><br><span class="line">@@ -119,7 +119,7 @@ controller:</span><br><span class="line"></span><br><span class="line">   ## DaemonSet or Deployment</span><br><span class="line">   ##</span><br><span class="line">-  kind: Deployment</span><br><span class="line">+  kind: DaemonSet</span><br><span class="line"></span><br><span class="line">   ## Annotations to be added to the controller deployment</span><br><span class="line">   ##</span><br><span class="line">@@ -428,7 +428,7 @@ defaultBackend:</span><br><span class="line"></span><br><span class="line">   name: default-backend</span><br><span class="line">   image:</span><br><span class="line">-    repository: k8s.gcr.io/defaultbackend-amd64</span><br><span class="line">+    repository: mirrorgooglecontainers/defaultbackend-amd64</span><br><span class="line">     tag: &quot;1.5&quot;</span><br><span class="line">     pullPolicy: IfNotPresent</span><br><span class="line">     # nobody user -&gt; uid 65534</span><br><span class="line">## 按照上述git对比出来的变化进行修改</span><br><span class="line"></span><br><span class="line"># helm install nginx-ingress stable/nginx-ingress --set rbac.create=true --namespace kube-system</span><br><span class="line"># helm list -n kube-system</span><br><span class="line">NAME         	NAMESPACE  	REVISION	UPDATED                                	STATUS  	CHART               	APP VERSION</span><br><span class="line">nginx-ingress	kube-system	1       	2020-02-16 12:20:48.748124293 +0800 CST	deployed	nginx-ingress-1.30.3	0.28.0</span><br><span class="line"></span><br><span class="line"># kubectl get pod --all-namespaces -o wide</span><br><span class="line">NAMESPACE              NAME                                             READY   STATUS    RESTARTS   AGE   IP                NODE     NOMINATED NODE   READINESS GATES</span><br><span class="line">。。。</span><br><span class="line">kube-system            nginx-ingress-controller-69878bd7c7-wjjmp        1/1     Running   0          20h   192.168.112.129   node01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system            nginx-ingress-default-backend-7cbf68bcd8-6csw4   1/1     Running   0          20h   10.211.140.76     node02   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">。。。</span><br></pre></td></tr></table></figure>
<h1 id="四、配置以-Ingress-https-的方式暴露-Kubernetes-Dashboard-服务"><a href="#四、配置以-Ingress-https-的方式暴露-Kubernetes-Dashboard-服务" class="headerlink" title="四、配置以 Ingress https 的方式暴露 Kubernetes Dashboard 服务"></a>四、配置以 Ingress https 的方式暴露 Kubernetes Dashboard 服务</h1><ol>
<li><p>准备 https 证书，以 secret 的形式提交到 Kubernetes Cluster 上</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">mkdir ingress/</span><br><span class="line">openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout tls.key -out tls.crt -subj &quot;/CN=dashboard.kubernetes.singhwang.com&quot;</span><br><span class="line"></span><br><span class="line">## 方法一：利用 kubectl 的功能，直接把证书创建到 kubernetes-dashboard-secret 这个 secret 对象中</span><br><span class="line">kubectl create secret tls kubernetes-dashboard-secret --key tls.key --cert tls.crt -n kubernetes-dashboard</span><br><span class="line"></span><br><span class="line">## 方法二：证书内容做 base64 加密后，写入到 kubernetes-dashboard-secret 这个 secret 对象 data 部分的 tls.crt 和 tls.key 中</span><br><span class="line">cat &lt;&lt;EOF &gt; ingress/01-secret.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Secret</span><br><span class="line">metadata:</span><br><span class="line">  name: kubernetes-dashboard-secret</span><br><span class="line">  namespace: kubernetes-dashboard</span><br><span class="line">type: kubernetes.io/tls</span><br><span class="line">data:</span><br><span class="line">  tls.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURMVENDQWhXZ0F3SUJBZ0lKQUtSMDREdGNBN2MxTUEwR0NTcUdTSWIzRFFFQkN3VUFNQzB4S3pBcEJnTlYKQkFNTUltUmhjMmhpYjJGeVpDNXJkV0psY201bGRHVnpMbk5wYm1kb2QyRnVaeTVqYjIwd0hoY05NakF3TWpFMgpNVEV3TXpVMFdoY05NakV3TWpFMU1URXdNelUwV2pBdE1Tc3dLUVlEVlFRRERDSmtZWE5vWW05aGNtUXVhM1ZpClpYSnVaWFJsY3k1emFXNW5hSGRoYm1jdVkyOXRNSUlCSWpBTkJna3Foa2lHOXcwQkFRRUZBQU9DQVE4QU1JSUIKQ2dLQ0FRRUFwZDZLanM0MnZhOElhWGxGM1hxeUYyM3gvTlJKMGtmM1B2V05hR3RsYzE2UW10Ry9Rcnl6SFVGOAoxOVJDQm5Td01tUVlMUE1xc0crYS9HOGExY0NoQm5mM3pmU09qSmpab0ErVmdqWnYrSE80YmxMaVZ0R25aYkJ5CldaNFZDdlJld0tDakdzQzhmSk5wZG0rYkxLdWgzNUZBeDNlekNnaXNOWXM5VEROWFpWdjArRk15dUNlczBQWUcKYWU1Zi96emtlTUxJT3RPUkc4NllIL2NyQVhUdUxQZko3RXlwRFpMMUpLY1pBUUw4S3RHQmk5aFZvN20xdHJ2NAo2dktudkZnL2pMREszNmI4MTNIekJaa21sUzUwV09XemFSbkxaaGZ6TGRpRkVIbHYwd05jd0dGbVlkb21VaFdnCjJwSEVSY0NrUG5uODF5YXZ2ZktCUElXNVFBZjd0d0lEQVFBQm8xQXdUakFkQmdOVkhRNEVGZ1FVM2tnTnFUMWgKM3ZpQkt0Z0U0VWRKS1J2Wmh3a3dId1lEVlIwakJCZ3dGb0FVM2tnTnFUMWgzdmlCS3RnRTRVZEpLUnZaaHdrdwpEQVlEVlIwVEJBVXdBd0VCL3pBTkJna3Foa2lHOXcwQkFRc0ZBQU9DQVFFQXBLNXR0S0Q5amhXakxHRzNkZjRoClQ4RDhNeHV6SXhNWkRSMFJYeTBLWEhsNFU3VFZVbjVLTEJqdDVUUUQ4ZU00ZEk0N2RQaEUzOVRaV3ZGVmFRbjcKckpiUldXbFV5UmdlWmM2NFFWMzZiOVNLSnErSHRManFTQUNBQmVrT2lNT3pOdTgrWGFBUDRpaERtOG5kU2thQwpjd3U3QkltbHMxS1hHU2VOenNpWU8rOTJ5U3MzTHlYMnQ4aHB6eXFvUzlOTkF3Vnd6WVlhWUo3TmtEWWtaOUZZCnhPUmpuUGlhMEQyZmVzNFhNQkdYK2FScEV4K0MvWUpKTWJxSzJJN3MzK21jRitOaTE2KzJmd0pJTHZuR0hWRkcKaHVKa3RSMGQzK1ZBMzBlTDJMY3l6NW4rTERQeFk2Z1MrVTJiYzJJdFAyZjZRUlRJTTVCUmFjUEJDNlM3UXFKaAoyUT09Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K</span><br><span class="line">  tls.key: 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</span><br><span class="line"></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>
</li>
<li><p>创建 ingress 资源对象到 Kubernetes Cluster 上</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">cat &lt;&lt;EOF &gt; ingress/02-ingress.yaml</span><br><span class="line">apiVersion: networking.k8s.io/v1beta1</span><br><span class="line">kind: Ingress</span><br><span class="line">metadata:</span><br><span class="line">  name: kubernetes-dashboard</span><br><span class="line">  namespace: kubernetes-dashboard</span><br><span class="line">  annotations:</span><br><span class="line">    nginx.ingress.kubernetes.io/ingress.class: nginx</span><br><span class="line">    nginx.ingress.kubernetes.io/secure-backends: &quot;true&quot;</span><br><span class="line">    nginx.ingress.kubernetes.io/ssl-passthrough: &quot;true&quot;</span><br><span class="line">spec:</span><br><span class="line">  tls:</span><br><span class="line">  - hosts:</span><br><span class="line">    - dashboard.kubernetes.singhwang.com</span><br><span class="line">    secretName: kubernetes-dashboard-secret</span><br><span class="line">  rules:</span><br><span class="line">    - host: dashboard.kubernetes.singhwang.com</span><br><span class="line">      http:</span><br><span class="line">        paths:</span><br><span class="line">        - path: /</span><br><span class="line">          backend:</span><br><span class="line">            serviceName: kubernetes-dashboard</span><br><span class="line">            servicePort: 80</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">kubectl create -f ingress/</span><br></pre></td></tr></table></figure>
</li>
<li><p>获取 ingress 资源对象中的 HOSTS 和 ADDRESS 在访问端做好 hosts 映射，条件允许的话，也可以配置为网络中的 DNS 记录</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># kubectl get ingress -n kubernetes-dashboard -o wide</span><br><span class="line">NAME                   HOSTS                                ADDRESS                           PORTS     AGE</span><br><span class="line">kubernetes-dashboard   dashboard.kubernetes.singhwang.com   192.168.112.129,192.168.112.130   80, 443   27s</span><br><span class="line"></span><br><span class="line">## 访问端或者访问端的DNS中配置域名 dashboard.kubernetes.singhwang.com 解析为地址 192.168.112.129 或者 192.168.112.130</span><br></pre></td></tr></table></figure>
</li>
<li><p>接上一步，访问 Kubernetes Dashboard 服务 <a href="https://dashboard.kubernetes.singhwang.com" target="_blank" rel="noopener">https://dashboard.kubernetes.singhwang.com</a><br><img src="/2020/02/17/kubernetes_dashboard_001/login_01.png" alt="login_01"></p>
</li>
</ol>
<h1 id="五、使用说明"><a href="#五、使用说明" class="headerlink" title="五、使用说明"></a>五、使用说明</h1><ol>
<li><p>创建访问用户并授权</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p access/</span><br><span class="line">cat &lt;&lt;EOF &gt; access/01-serviceaccount.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: admin-user</span><br><span class="line">  namespace: kubernetes-dashboard</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt; access/02-clusterrolebinding.yaml</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: admin-user</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: cluster-admin</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: admin-user</span><br><span class="line">  namespace: kubernetes-dashboard</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">kubectl create -f access/</span><br></pre></td></tr></table></figure>
</li>
<li><p>获取用户的 Token， 并在登录页面上输入， 然后登录 Kubernetes Dashboard</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">## 获取上一步授权的用户 Token，用于登录 Kubernetes Dashboard </span><br><span class="line"># kubectl -n kubernetes-dashboard describe secret $(kubectl -n kubernetes-dashboard get secret | grep admin-user | awk &apos;&#123;print $1&#125;&apos;)</span><br><span class="line">Name:         admin-user-token-5k9vs</span><br><span class="line">Namespace:    kubernetes-dashboard</span><br><span class="line">Labels:       &lt;none&gt;</span><br><span class="line">Annotations:  kubernetes.io/service-account.name: admin-user</span><br><span class="line">              kubernetes.io/service-account.uid: 4a2e4bbf-2bb6-4e65-ab49-94913da8d04c</span><br><span class="line"></span><br><span class="line">Type:  kubernetes.io/service-account-token</span><br><span class="line"></span><br><span class="line">Data</span><br><span class="line">====</span><br><span class="line">ca.crt:     1025 bytes</span><br><span class="line">namespace:  20 bytes</span><br><span class="line">token:      eyJhbGciOiJSUzI1NiIsImtpZCI6IkpWcTFvc0Rza0xYZVVhVnlkRkhUX2VDM1RBR1hUNXpKVkdna3kyRTAyVlEifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlcm5ldGVzLWRhc2hib2FyZCIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJhZG1pbi11c2VyLXRva2VuLTVrOXZzIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6ImFkbWluLXVzZXIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiI0YTJlNGJiZi0yYmI2LTRlNjUtYWI0OS05NDkxM2RhOGQwNGMiLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZXJuZXRlcy1kYXNoYm9hcmQ6YWRtaW4tdXNlciJ9.r1tufqV-G_AF1D-WXhP0i_ggM4rBHuzcNryPIyaIdJOYQEfoQ_G7rPPb2qEux6XrmObFgbNZoXvXUWWn8Q_OulalGNmtAO17xgCvTPjs4A_jvQGv-kiVM_OjBAUL5VGn3leT4KkK60U2q6fGUuHVAu6Fzanq178r8F17uyY_6pAz5xkHx_CZQH4aVpOWOOgcN0u8IyjxSgder_KGP7tZqbrjv29hff6xnEWU_x3qxvxWxWtOOj8egjb_NpJQge5Lh_NQvi78djq8SaBn7otkapg8Ob6FuOP48q9N01ALoJoyT2yPVbml7JLoi1qizd5PAQ40ow18cF_soxTdh7iTRw</span><br><span class="line"></span><br><span class="line">## 登录页面上输入 Token 后，点击对应按钮即可实现登录</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p><img src="/2020/02/17/kubernetes_dashboard_001/login_02.png" alt="login_02"><br><img src="/2020/02/17/kubernetes_dashboard_001/login_03.png" alt="login_03"></p>
<h1 id="六、参考资料"><a href="#六、参考资料" class="headerlink" title="六、参考资料"></a>六、参考资料</h1><h2 id="1-Kubernetes-Dashboard-的官方资料"><a href="#1-Kubernetes-Dashboard-的官方资料" class="headerlink" title="1. Kubernetes Dashboard 的官方资料"></a>1. Kubernetes Dashboard 的官方资料</h2><p><a href="https://github.com/kubernetes/dashboard/blob/v2.0.0-rc5/src/app/backend/dashboard.go" target="_blank" rel="noopener">https://github.com/kubernetes/dashboard/blob/v2.0.0-rc5/src/app/backend/dashboard.go</a><br><a href="https://github.com/kubernetes/dashboard/blob/v2.0.0-rc5/docs/user/accessing-dashboard/1.7.x-and-above.md" target="_blank" rel="noopener">https://github.com/kubernetes/dashboard/blob/v2.0.0-rc5/docs/user/accessing-dashboard/1.7.x-and-above.md</a><br><a href="https://github.com/kubernetes/dashboard/blob/v2.0.0-rc5/docs/user/access-control/creating-sample-user.md" target="_blank" rel="noopener">https://github.com/kubernetes/dashboard/blob/v2.0.0-rc5/docs/user/access-control/creating-sample-user.md</a><br><a href="https://github.com/kubernetes/dashboard/blob/v2.0.0-rc5/docs/user/integrations.md" target="_blank" rel="noopener">https://github.com/kubernetes/dashboard/blob/v2.0.0-rc5/docs/user/integrations.md</a><br><a href="https://github.com/kubernetes/dashboard/blob/v2.0.0-rc5/docs/user/certificate-management.md" target="_blank" rel="noopener">https://github.com/kubernetes/dashboard/blob/v2.0.0-rc5/docs/user/certificate-management.md</a></p>
<h2 id="2-Nginx-Ingress-Controller"><a href="#2-Nginx-Ingress-Controller" class="headerlink" title="2. Nginx Ingress Controller"></a>2. Nginx Ingress Controller</h2><p><a href="https://kubernetes.github.io/ingress-nginx/deploy/#using-helm" target="_blank" rel="noopener">https://kubernetes.github.io/ingress-nginx/deploy/#using-helm</a><br><a href="https://www.jianshu.com/p/2da985a32db8" target="_blank" rel="noopener">https://www.jianshu.com/p/2da985a32db8</a></p>
<h2 id="3-Kubernetes-Metric-Server"><a href="#3-Kubernetes-Metric-Server" class="headerlink" title="3. Kubernetes Metric Server"></a>3. Kubernetes Metric Server</h2><p><a href="https://www.cnblogs.com/ding2016/p/10786252.html" target="_blank" rel="noopener">https://www.cnblogs.com/ding2016/p/10786252.html</a><br><a href="https://github.com/singhwang/k8s-prom-hpa" target="_blank" rel="noopener">https://github.com/singhwang/k8s-prom-hpa</a></p>
<h2 id="4-关于-Chrome-无法访问-Kubernetes-Dashboard-的问题解决"><a href="#4-关于-Chrome-无法访问-Kubernetes-Dashboard-的问题解决" class="headerlink" title="4. 关于 Chrome 无法访问 Kubernetes Dashboard 的问题解决"></a>4. 关于 Chrome 无法访问 Kubernetes Dashboard 的问题解决</h2><p><a href="http://team.jiunile.com/blog/2018/12/k8s-dashboard-chrome-err.html" target="_blank" rel="noopener">http://team.jiunile.com/blog/2018/12/k8s-dashboard-chrome-err.html</a><br><a href="https://superuser.com/questions/27268/how-do-i-disable-the-warning-chrome-gives-if-a-security-certificate-is-not-trust" target="_blank" rel="noopener">https://superuser.com/questions/27268/how-do-i-disable-the-warning-chrome-gives-if-a-security-certificate-is-not-trust</a><br><a href="https://www.jianshu.com/p/a8cc2c04ee7c" target="_blank" rel="noopener">https://www.jianshu.com/p/a8cc2c04ee7c</a><br><a href="https://blog.gxxsite.com/wei-mac-osxde-cheng-xu-tian-jia-yong-jiu-qi-dong-can-shu/" target="_blank" rel="noopener">https://blog.gxxsite.com/wei-mac-osxde-cheng-xu-tian-jia-yong-jiu-qi-dong-can-shu/</a></p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Dashboard/">Dashboard</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Docker/">Docker</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Kubernetes/">Kubernetes</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Setup/">Setup</a></li></ul>
	</div>

      
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/容器云技术/">容器云技术</a>
	</div>


      
      <div class="clearfix"></div>
    </div>
      
    
  </div>
  
</article>







  
    <article id="post-kubernetes_dashboard_000" class="article article-type-post" itemscope="" itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2020/02/17/kubernetes_dashboard_000/" class="article-date">
  	<time datetime="2020-02-17T07:42:02.999Z" itemprop="datePublished">2020-02-17</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/02/17/kubernetes_dashboard_000/">
        Kubernetes Dashboard 的安装、配置和使用
        
      </a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="一、实验环境版本信息"><a href="#一、实验环境版本信息" class="headerlink" title="一、实验环境版本信息"></a>一、实验环境版本信息</h1><h2 id="1-操作系统的版本信息"><a href="#1-操作系统的版本信息" class="headerlink" title="1. 操作系统的版本信息"></a>1. 操作系统的版本信息</h2><p>CentOS Linux release 7.6.1810 (Core)</p>
<h2 id="2-各组件的版本信息"><a href="#2-各组件的版本信息" class="headerlink" title="2. 各组件的版本信息"></a>2. 各组件的版本信息</h2><h3 id="kubernetes-cluster-v1-17-0，推荐使用kubeadm-v1-17-0-进行试验"><a href="#kubernetes-cluster-v1-17-0，推荐使用kubeadm-v1-17-0-进行试验" class="headerlink" title="kubernetes cluster v1.17.0，推荐使用kubeadm v1.17.0 进行试验"></a>kubernetes cluster v1.17.0，推荐使用kubeadm v1.17.0 进行试验</h3><p>etcd v3.4.3<br>kube-apiserver v1.17.0<br>kube-controller-manager v1.17.0<br>kube-scheduler v1.17.0<br>kubectl v1.17.0</p>
<p>docker 18.09.9<br>kubelet v1.17.0<br>calico v3.11.1</p>
<h3 id="kubernetes-dashborad，使用容器化的方式部署"><a href="#kubernetes-dashborad，使用容器化的方式部署" class="headerlink" title="kubernetes dashborad，使用容器化的方式部署"></a>kubernetes dashborad，使用容器化的方式部署</h3><p>kubernetes dashboard v2.0.0-rc5 </p>
<h1 id="二、准备Docker镜像与Kubernetes-YAML部署文件"><a href="#二、准备Docker镜像与Kubernetes-YAML部署文件" class="headerlink" title="二、准备Docker镜像与Kubernetes YAML部署文件"></a>二、准备Docker镜像与Kubernetes YAML部署文件</h1><h2 id="1-准备相关的-Docker-镜像"><a href="#1-准备相关的-Docker-镜像" class="headerlink" title="1. 准备相关的 Docker 镜像"></a>1. 准备相关的 Docker 镜像</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker pull kubernetesui/dashboard:v2.0.0-rc5</span><br><span class="line">docker pull kubernetesui/metrics-scraper:v1.0.3</span><br><span class="line">docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/metrics-server-amd64:v0.3.6</span><br></pre></td></tr></table></figure>
<h2 id="2-准备相关的-Kubernetes-YAML-部署文件"><a href="#2-准备相关的-Kubernetes-YAML-部署文件" class="headerlink" title="2. 准备相关的 Kubernetes YAML 部署文件"></a>2. 准备相关的 Kubernetes YAML 部署文件</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># git clone https://github.com/kubernetes/dashboard.git</span><br><span class="line"># cd dashboard/</span><br><span class="line"># git checkout -b v2.0.0-rc5.tag v2.0.0-rc5</span><br></pre></td></tr></table></figure>
<h1 id="三、在-Kubernetes-Cluster-上安装-Kubernetes-Dashboard"><a href="#三、在-Kubernetes-Cluster-上安装-Kubernetes-Dashboard" class="headerlink" title="三、在 Kubernetes Cluster 上安装 Kubernetes Dashboard"></a>三、在 Kubernetes Cluster 上安装 Kubernetes Dashboard</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">## 接上一步，在 dashboard/ 目录下操作，直接使用 kubectl 创建资源即可</span><br><span class="line"># kubectl create -f aio/deploy/recommended.yaml</span><br></pre></td></tr></table></figure>
<h1 id="四、安装-Kubernetes-监控组件-Metric-Server"><a href="#四、安装-Kubernetes-监控组件-Metric-Server" class="headerlink" title="四、安装 Kubernetes 监控组件 Metric Server"></a>四、安装 Kubernetes 监控组件 Metric Server</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br></pre></td><td class="code"><pre><span class="line"># git clone https://github.com/kubernetes-sigs/metrics-server.git</span><br><span class="line"># cd metrics-server/</span><br><span class="line"># git checkout -b v0.3.6.tag v0.3.6</span><br><span class="line"># git branch</span><br><span class="line">  master</span><br><span class="line">* v0.3.6.tag</span><br><span class="line"></span><br><span class="line"># git diff deploy/1.8+/metrics-server-deployment.yaml</span><br><span class="line">diff --git a/deploy/1.8+/metrics-server-deployment.yaml b/deploy/1.8+/metrics-server-deployment.yaml</span><br><span class="line">index 2393e75..86f4219 100644</span><br><span class="line">--- a/deploy/1.8+/metrics-server-deployment.yaml</span><br><span class="line">+++ b/deploy/1.8+/metrics-server-deployment.yaml</span><br><span class="line">@@ -29,8 +29,12 @@ spec:</span><br><span class="line">         emptyDir: &#123;&#125;</span><br><span class="line">       containers:</span><br><span class="line">       - name: metrics-server</span><br><span class="line">-        image: k8s.gcr.io/metrics-server-amd64:v0.3.6</span><br><span class="line">-        imagePullPolicy: Always</span><br><span class="line">+        image: registry.cn-hangzhou.aliyuncs.com/google_containers/metrics-server-amd64:v0.3.6</span><br><span class="line">+        imagePullPolicy: IfNotPresent</span><br><span class="line">+        command:</span><br><span class="line">+        - /metrics-server</span><br><span class="line">+        - --kubelet-preferred-address-types=InternalIP</span><br><span class="line">+        - --kubelet-insecure-tls</span><br><span class="line">         volumeMounts:</span><br><span class="line">         - name: tmp-dir</span><br><span class="line">           mountPath: /tmp</span><br><span class="line">## 按照上述git对比出来的变化进行修改</span><br><span class="line"></span><br><span class="line"># kubectl create -f deploy/1.8+/</span><br><span class="line"></span><br><span class="line"># kubectl get pod -n kube-system -o wide</span><br><span class="line">NAME                             READY   STATUS    RESTARTS   AGE   IP               NODE     NOMINATED NODE   READINESS GATES</span><br><span class="line">。。。</span><br><span class="line">metrics-server-c6774ddf4-nnktl   1/1     Running   0          30h   10.211.196.130   node01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">。。。</span><br><span class="line"></span><br><span class="line">## 验证metric server的可用性</span><br><span class="line"># kubectl get --raw &quot;/apis/metrics.k8s.io/v1beta1/nodes&quot; | jq .</span><br><span class="line">&#123;</span><br><span class="line">  &quot;kind&quot;: &quot;NodeMetricsList&quot;,</span><br><span class="line">  &quot;apiVersion&quot;: &quot;metrics.k8s.io/v1beta1&quot;,</span><br><span class="line">  &quot;metadata&quot;: &#123;</span><br><span class="line">    &quot;selfLink&quot;: &quot;/apis/metrics.k8s.io/v1beta1/nodes&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;items&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;metadata&quot;: &#123;</span><br><span class="line">        &quot;name&quot;: &quot;node02&quot;,</span><br><span class="line">        &quot;selfLink&quot;: &quot;/apis/metrics.k8s.io/v1beta1/nodes/node02&quot;,</span><br><span class="line">        &quot;creationTimestamp&quot;: &quot;2020-02-22T05:32:50Z&quot;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;timestamp&quot;: &quot;2020-02-22T05:32:13Z&quot;,</span><br><span class="line">      &quot;window&quot;: &quot;30s&quot;,</span><br><span class="line">      &quot;usage&quot;: &#123;</span><br><span class="line">        &quot;cpu&quot;: &quot;88057337n&quot;,</span><br><span class="line">        &quot;memory&quot;: &quot;822040Ki&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;metadata&quot;: &#123;</span><br><span class="line">        &quot;name&quot;: &quot;master&quot;,</span><br><span class="line">        &quot;selfLink&quot;: &quot;/apis/metrics.k8s.io/v1beta1/nodes/master&quot;,</span><br><span class="line">        &quot;creationTimestamp&quot;: &quot;2020-02-22T05:32:50Z&quot;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;timestamp&quot;: &quot;2020-02-22T05:32:21Z&quot;,</span><br><span class="line">      &quot;window&quot;: &quot;30s&quot;,</span><br><span class="line">      &quot;usage&quot;: &#123;</span><br><span class="line">        &quot;cpu&quot;: &quot;184970966n&quot;,</span><br><span class="line">        &quot;memory&quot;: &quot;1045388Ki&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;metadata&quot;: &#123;</span><br><span class="line">        &quot;name&quot;: &quot;node01&quot;,</span><br><span class="line">        &quot;selfLink&quot;: &quot;/apis/metrics.k8s.io/v1beta1/nodes/node01&quot;,</span><br><span class="line">        &quot;creationTimestamp&quot;: &quot;2020-02-22T05:32:50Z&quot;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;timestamp&quot;: &quot;2020-02-22T05:32:18Z&quot;,</span><br><span class="line">      &quot;window&quot;: &quot;30s&quot;,</span><br><span class="line">      &quot;usage&quot;: &#123;</span><br><span class="line">        &quot;cpu&quot;: &quot;92128619n&quot;,</span><br><span class="line">        &quot;memory&quot;: &quot;833480Ki&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># kubectl get --raw &quot;/apis/metrics.k8s.io/v1beta1/pods&quot; | jq .</span><br><span class="line">&#123;</span><br><span class="line">  &quot;kind&quot;: &quot;PodMetricsList&quot;,</span><br><span class="line">  &quot;apiVersion&quot;: &quot;metrics.k8s.io/v1beta1&quot;,</span><br><span class="line">  &quot;metadata&quot;: &#123;</span><br><span class="line">    &quot;selfLink&quot;: &quot;/apis/metrics.k8s.io/v1beta1/pods&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;items&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;metadata&quot;: &#123;</span><br><span class="line">        &quot;name&quot;: &quot;calico-node-vp2mk&quot;,</span><br><span class="line">        &quot;namespace&quot;: &quot;kube-system&quot;,</span><br><span class="line">        &quot;selfLink&quot;: &quot;/apis/metrics.k8s.io/v1beta1/namespaces/kube-system/pods/calico-node-vp2mk&quot;,</span><br><span class="line">        &quot;creationTimestamp&quot;: &quot;2020-02-22T05:33:20Z&quot;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;timestamp&quot;: &quot;2020-02-22T05:32:13Z&quot;,</span><br><span class="line">      &quot;window&quot;: &quot;30s&quot;,</span><br><span class="line">      &quot;containers&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;name&quot;: &quot;calico-node&quot;,</span><br><span class="line">          &quot;usage&quot;: &#123;</span><br><span class="line">            &quot;cpu&quot;: &quot;23828482n&quot;,</span><br><span class="line">            &quot;memory&quot;: &quot;29852Ki&quot;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;metadata&quot;: &#123;</span><br><span class="line">        &quot;name&quot;: &quot;coredns-7f9c544f75-nbtt9&quot;,</span><br><span class="line">        &quot;namespace&quot;: &quot;kube-system&quot;,</span><br><span class="line">        &quot;selfLink&quot;: &quot;/apis/metrics.k8s.io/v1beta1/namespaces/kube-system/pods/coredns-7f9c544f75-nbtt9&quot;,</span><br><span class="line">        &quot;creationTimestamp&quot;: &quot;2020-02-22T05:33:20Z&quot;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;timestamp&quot;: &quot;2020-02-22T05:32:12Z&quot;,</span><br><span class="line">      &quot;window&quot;: &quot;30s&quot;,</span><br><span class="line">      &quot;containers&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;name&quot;: &quot;coredns&quot;,</span><br><span class="line">          &quot;usage&quot;: &#123;</span><br><span class="line">            &quot;cpu&quot;: &quot;2739715n&quot;,</span><br><span class="line">            &quot;memory&quot;: &quot;8372Ki&quot;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;metadata&quot;: &#123;</span><br><span class="line">        &quot;name&quot;: &quot;kube-controller-manager-master&quot;,</span><br><span class="line">        &quot;namespace&quot;: &quot;kube-system&quot;,</span><br><span class="line">        &quot;selfLink&quot;: &quot;/apis/metrics.k8s.io/v1beta1/namespaces/kube-system/pods/kube-controller-manager-master&quot;,</span><br><span class="line">        &quot;creationTimestamp&quot;: &quot;2020-02-22T05:33:20Z&quot;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;timestamp&quot;: &quot;2020-02-22T05:32:22Z&quot;,</span><br><span class="line">      &quot;window&quot;: &quot;30s&quot;,</span><br><span class="line">      &quot;containers&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;name&quot;: &quot;kube-controller-manager&quot;,</span><br><span class="line">          &quot;usage&quot;: &#123;</span><br><span class="line">            &quot;cpu&quot;: &quot;11899093n&quot;,</span><br><span class="line">            &quot;memory&quot;: &quot;61688Ki&quot;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;metadata&quot;: &#123;</span><br><span class="line">        &quot;name&quot;: &quot;etcd-master&quot;,</span><br><span class="line">        &quot;namespace&quot;: &quot;kube-system&quot;,</span><br><span class="line">        &quot;selfLink&quot;: &quot;/apis/metrics.k8s.io/v1beta1/namespaces/kube-system/pods/etcd-master&quot;,</span><br><span class="line">        &quot;creationTimestamp&quot;: &quot;2020-02-22T05:33:20Z&quot;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;timestamp&quot;: &quot;2020-02-22T05:32:15Z&quot;,</span><br><span class="line">      &quot;window&quot;: &quot;30s&quot;,</span><br><span class="line">      &quot;containers&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;name&quot;: &quot;etcd&quot;,</span><br><span class="line">          &quot;usage&quot;: &#123;</span><br><span class="line">            &quot;cpu&quot;: &quot;15906661n&quot;,</span><br><span class="line">            &quot;memory&quot;: &quot;46120Ki&quot;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;metadata&quot;: &#123;</span><br><span class="line">        &quot;name&quot;: &quot;coredns-7f9c544f75-bk25k&quot;,</span><br><span class="line">        &quot;namespace&quot;: &quot;kube-system&quot;,</span><br><span class="line">        &quot;selfLink&quot;: &quot;/apis/metrics.k8s.io/v1beta1/namespaces/kube-system/pods/coredns-7f9c544f75-bk25k&quot;,</span><br><span class="line">        &quot;creationTimestamp&quot;: &quot;2020-02-22T05:33:20Z&quot;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;timestamp&quot;: &quot;2020-02-22T05:32:07Z&quot;,</span><br><span class="line">      &quot;window&quot;: &quot;30s&quot;,</span><br><span class="line">      &quot;containers&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;name&quot;: &quot;coredns&quot;,</span><br><span class="line">          &quot;usage&quot;: &#123;</span><br><span class="line">            &quot;cpu&quot;: &quot;2311367n&quot;,</span><br><span class="line">            &quot;memory&quot;: &quot;11300Ki&quot;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;metadata&quot;: &#123;</span><br><span class="line">        &quot;name&quot;: &quot;dashboard-metrics-scraper-7b8b58dc8b-nnktl&quot;,</span><br><span class="line">        &quot;namespace&quot;: &quot;kubernetes-dashboard&quot;,</span><br><span class="line">        &quot;selfLink&quot;: &quot;/apis/metrics.k8s.io/v1beta1/namespaces/kubernetes-dashboard/pods/dashboard-metrics-scraper-7b8b58dc8b-nnktl&quot;,</span><br><span class="line">        &quot;creationTimestamp&quot;: &quot;2020-02-22T05:33:20Z&quot;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;timestamp&quot;: &quot;2020-02-22T05:32:12Z&quot;,</span><br><span class="line">      &quot;window&quot;: &quot;30s&quot;,</span><br><span class="line">      &quot;containers&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;name&quot;: &quot;dashboard-metrics-scraper&quot;,</span><br><span class="line">          &quot;usage&quot;: &#123;</span><br><span class="line">            &quot;cpu&quot;: &quot;487926n&quot;,</span><br><span class="line">            &quot;memory&quot;: &quot;3932Ki&quot;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;metadata&quot;: &#123;</span><br><span class="line">        &quot;name&quot;: &quot;kube-proxy-v6vtg&quot;,</span><br><span class="line">        &quot;namespace&quot;: &quot;kube-system&quot;,</span><br><span class="line">        &quot;selfLink&quot;: &quot;/apis/metrics.k8s.io/v1beta1/namespaces/kube-system/pods/kube-proxy-v6vtg&quot;,</span><br><span class="line">        &quot;creationTimestamp&quot;: &quot;2020-02-22T05:33:20Z&quot;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;timestamp&quot;: &quot;2020-02-22T05:32:11Z&quot;,</span><br><span class="line">      &quot;window&quot;: &quot;30s&quot;,</span><br><span class="line">      &quot;containers&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;name&quot;: &quot;kube-proxy&quot;,</span><br><span class="line">          &quot;usage&quot;: &#123;</span><br><span class="line">            &quot;cpu&quot;: &quot;414352n&quot;,</span><br><span class="line">            &quot;memory&quot;: &quot;23932Ki&quot;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;metadata&quot;: &#123;</span><br><span class="line">        &quot;name&quot;: &quot;network-pz6st&quot;,</span><br><span class="line">        &quot;namespace&quot;: &quot;default&quot;,</span><br><span class="line">        &quot;selfLink&quot;: &quot;/apis/metrics.k8s.io/v1beta1/namespaces/default/pods/network-pz6st&quot;,</span><br><span class="line">        &quot;creationTimestamp&quot;: &quot;2020-02-22T05:33:20Z&quot;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;timestamp&quot;: &quot;2020-02-22T05:32:18Z&quot;,</span><br><span class="line">      &quot;window&quot;: &quot;30s&quot;,</span><br><span class="line">      &quot;containers&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;name&quot;: &quot;network&quot;,</span><br><span class="line">          &quot;usage&quot;: &#123;</span><br><span class="line">            &quot;cpu&quot;: &quot;0&quot;,</span><br><span class="line">            &quot;memory&quot;: &quot;44Ki&quot;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;metadata&quot;: &#123;</span><br><span class="line">        &quot;name&quot;: &quot;kube-apiserver-master&quot;,</span><br><span class="line">        &quot;namespace&quot;: &quot;kube-system&quot;,</span><br><span class="line">        &quot;selfLink&quot;: &quot;/apis/metrics.k8s.io/v1beta1/namespaces/kube-system/pods/kube-apiserver-master&quot;,</span><br><span class="line">        &quot;creationTimestamp&quot;: &quot;2020-02-22T05:33:20Z&quot;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;timestamp&quot;: &quot;2020-02-22T05:32:17Z&quot;,</span><br><span class="line">      &quot;window&quot;: &quot;30s&quot;,</span><br><span class="line">      &quot;containers&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;name&quot;: &quot;kube-apiserver&quot;,</span><br><span class="line">          &quot;usage&quot;: &#123;</span><br><span class="line">            &quot;cpu&quot;: &quot;35264598n&quot;,</span><br><span class="line">            &quot;memory&quot;: &quot;300208Ki&quot;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;metadata&quot;: &#123;</span><br><span class="line">        &quot;name&quot;: &quot;calico-kube-controllers-648f4868b8-844cd&quot;,</span><br><span class="line">        &quot;namespace&quot;: &quot;kube-system&quot;,</span><br><span class="line">        &quot;selfLink&quot;: &quot;/apis/metrics.k8s.io/v1beta1/namespaces/kube-system/pods/calico-kube-controllers-648f4868b8-844cd&quot;,</span><br><span class="line">        &quot;creationTimestamp&quot;: &quot;2020-02-22T05:33:20Z&quot;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;timestamp&quot;: &quot;2020-02-22T05:32:19Z&quot;,</span><br><span class="line">      &quot;window&quot;: &quot;30s&quot;,</span><br><span class="line">      &quot;containers&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;name&quot;: &quot;calico-kube-controllers&quot;,</span><br><span class="line">          &quot;usage&quot;: &#123;</span><br><span class="line">            &quot;cpu&quot;: &quot;1185857n&quot;,</span><br><span class="line">            &quot;memory&quot;: &quot;8716Ki&quot;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;metadata&quot;: &#123;</span><br><span class="line">        &quot;name&quot;: &quot;metrics-server-c6774ddf4-f6lg2&quot;,</span><br><span class="line">        &quot;namespace&quot;: &quot;kube-system&quot;,</span><br><span class="line">        &quot;selfLink&quot;: &quot;/apis/metrics.k8s.io/v1beta1/namespaces/kube-system/pods/metrics-server-c6774ddf4-f6lg2&quot;,</span><br><span class="line">        &quot;creationTimestamp&quot;: &quot;2020-02-22T05:33:20Z&quot;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;timestamp&quot;: &quot;2020-02-22T05:32:17Z&quot;,</span><br><span class="line">      &quot;window&quot;: &quot;30s&quot;,</span><br><span class="line">      &quot;containers&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;name&quot;: &quot;metrics-server&quot;,</span><br><span class="line">          &quot;usage&quot;: &#123;</span><br><span class="line">            &quot;cpu&quot;: &quot;1059092n&quot;,</span><br><span class="line">            &quot;memory&quot;: &quot;11748Ki&quot;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;metadata&quot;: &#123;</span><br><span class="line">        &quot;name&quot;: &quot;kube-scheduler-master&quot;,</span><br><span class="line">        &quot;namespace&quot;: &quot;kube-system&quot;,</span><br><span class="line">        &quot;selfLink&quot;: &quot;/apis/metrics.k8s.io/v1beta1/namespaces/kube-system/pods/kube-scheduler-master&quot;,</span><br><span class="line">        &quot;creationTimestamp&quot;: &quot;2020-02-22T05:33:20Z&quot;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;timestamp&quot;: &quot;2020-02-22T05:32:20Z&quot;,</span><br><span class="line">      &quot;window&quot;: &quot;30s&quot;,</span><br><span class="line">      &quot;containers&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;name&quot;: &quot;kube-scheduler&quot;,</span><br><span class="line">          &quot;usage&quot;: &#123;</span><br><span class="line">            &quot;cpu&quot;: &quot;2369907n&quot;,</span><br><span class="line">            &quot;memory&quot;: &quot;24184Ki&quot;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;metadata&quot;: &#123;</span><br><span class="line">        &quot;name&quot;: &quot;calico-node-2qjtg&quot;,</span><br><span class="line">        &quot;namespace&quot;: &quot;kube-system&quot;,</span><br><span class="line">        &quot;selfLink&quot;: &quot;/apis/metrics.k8s.io/v1beta1/namespaces/kube-system/pods/calico-node-2qjtg&quot;,</span><br><span class="line">        &quot;creationTimestamp&quot;: &quot;2020-02-22T05:33:20Z&quot;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;timestamp&quot;: &quot;2020-02-22T05:32:21Z&quot;,</span><br><span class="line">      &quot;window&quot;: &quot;30s&quot;,</span><br><span class="line">      &quot;containers&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;name&quot;: &quot;calico-node&quot;,</span><br><span class="line">          &quot;usage&quot;: &#123;</span><br><span class="line">            &quot;cpu&quot;: &quot;25966443n&quot;,</span><br><span class="line">            &quot;memory&quot;: &quot;25984Ki&quot;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;metadata&quot;: &#123;</span><br><span class="line">        &quot;name&quot;: &quot;kube-proxy-pwh6h&quot;,</span><br><span class="line">        &quot;namespace&quot;: &quot;kube-system&quot;,</span><br><span class="line">        &quot;selfLink&quot;: &quot;/apis/metrics.k8s.io/v1beta1/namespaces/kube-system/pods/kube-proxy-pwh6h&quot;,</span><br><span class="line">        &quot;creationTimestamp&quot;: &quot;2020-02-22T05:33:20Z&quot;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;timestamp&quot;: &quot;2020-02-22T05:32:15Z&quot;,</span><br><span class="line">      &quot;window&quot;: &quot;30s&quot;,</span><br><span class="line">      &quot;containers&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;name&quot;: &quot;kube-proxy&quot;,</span><br><span class="line">          &quot;usage&quot;: &#123;</span><br><span class="line">            &quot;cpu&quot;: &quot;216986n&quot;,</span><br><span class="line">            &quot;memory&quot;: &quot;25156Ki&quot;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;metadata&quot;: &#123;</span><br><span class="line">        &quot;name&quot;: &quot;calico-node-gq9r9&quot;,</span><br><span class="line">        &quot;namespace&quot;: &quot;kube-system&quot;,</span><br><span class="line">        &quot;selfLink&quot;: &quot;/apis/metrics.k8s.io/v1beta1/namespaces/kube-system/pods/calico-node-gq9r9&quot;,</span><br><span class="line">        &quot;creationTimestamp&quot;: &quot;2020-02-22T05:33:20Z&quot;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;timestamp&quot;: &quot;2020-02-22T05:32:04Z&quot;,</span><br><span class="line">      &quot;window&quot;: &quot;30s&quot;,</span><br><span class="line">      &quot;containers&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;name&quot;: &quot;calico-node&quot;,</span><br><span class="line">          &quot;usage&quot;: &#123;</span><br><span class="line">            &quot;cpu&quot;: &quot;25302709n&quot;,</span><br><span class="line">            &quot;memory&quot;: &quot;26760Ki&quot;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;metadata&quot;: &#123;</span><br><span class="line">        &quot;name&quot;: &quot;network-s5tjd&quot;,</span><br><span class="line">        &quot;namespace&quot;: &quot;default&quot;,</span><br><span class="line">        &quot;selfLink&quot;: &quot;/apis/metrics.k8s.io/v1beta1/namespaces/default/pods/network-s5tjd&quot;,</span><br><span class="line">        &quot;creationTimestamp&quot;: &quot;2020-02-22T05:33:20Z&quot;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;timestamp&quot;: &quot;2020-02-22T05:32:10Z&quot;,</span><br><span class="line">      &quot;window&quot;: &quot;30s&quot;,</span><br><span class="line">      &quot;containers&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;name&quot;: &quot;network&quot;,</span><br><span class="line">          &quot;usage&quot;: &#123;</span><br><span class="line">            &quot;cpu&quot;: &quot;0&quot;,</span><br><span class="line">            &quot;memory&quot;: &quot;48Ki&quot;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;metadata&quot;: &#123;</span><br><span class="line">        &quot;name&quot;: &quot;kubernetes-dashboard-866f987876-5npr9&quot;,</span><br><span class="line">        &quot;namespace&quot;: &quot;kubernetes-dashboard&quot;,</span><br><span class="line">        &quot;selfLink&quot;: &quot;/apis/metrics.k8s.io/v1beta1/namespaces/kubernetes-dashboard/pods/kubernetes-dashboard-866f987876-5npr9&quot;,</span><br><span class="line">        &quot;creationTimestamp&quot;: &quot;2020-02-22T05:33:20Z&quot;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;timestamp&quot;: &quot;2020-02-22T05:32:18Z&quot;,</span><br><span class="line">      &quot;window&quot;: &quot;30s&quot;,</span><br><span class="line">      &quot;containers&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;name&quot;: &quot;kubernetes-dashboard&quot;,</span><br><span class="line">          &quot;usage&quot;: &#123;</span><br><span class="line">            &quot;cpu&quot;: &quot;281233n&quot;,</span><br><span class="line">            &quot;memory&quot;: &quot;9512Ki&quot;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;metadata&quot;: &#123;</span><br><span class="line">        &quot;name&quot;: &quot;kube-proxy-knt4j&quot;,</span><br><span class="line">        &quot;namespace&quot;: &quot;kube-system&quot;,</span><br><span class="line">        &quot;selfLink&quot;: &quot;/apis/metrics.k8s.io/v1beta1/namespaces/kube-system/pods/kube-proxy-knt4j&quot;,</span><br><span class="line">        &quot;creationTimestamp&quot;: &quot;2020-02-22T05:33:20Z&quot;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;timestamp&quot;: &quot;2020-02-22T05:32:05Z&quot;,</span><br><span class="line">      &quot;window&quot;: &quot;30s&quot;,</span><br><span class="line">      &quot;containers&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;name&quot;: &quot;kube-proxy&quot;,</span><br><span class="line">          &quot;usage&quot;: &#123;</span><br><span class="line">            &quot;cpu&quot;: &quot;485574n&quot;,</span><br><span class="line">            &quot;memory&quot;: &quot;15496Ki&quot;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="五、配置以https的方式访问-Kubernetes-Dashboard"><a href="#五、配置以https的方式访问-Kubernetes-Dashboard" class="headerlink" title="五、配置以https的方式访问 Kubernetes Dashboard"></a>五、配置以https的方式访问 Kubernetes Dashboard</h1><ol>
<li><p>决定了 Kubernetes Dashboard 以 https 的形式对外提供服务的关键参数</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">## 以 https 对外提供服务时，Kubernetes Dashboard 默认是启用登录模式的</span><br><span class="line">## 特别注意：该参数启用后，Kubernetes Dashboard 会监听 8443 端口对外提供 https 服务，并且不会监听 9090 端口提供 http 服务</span><br><span class="line">--auto-generate-certificates </span><br><span class="line"></span><br><span class="line">## 设置 https 监听端口，默认值为 8443</span><br><span class="line">--port</span><br><span class="line"></span><br><span class="line">## 设置 https 监听地址，默认值为 0.0.0.0</span><br><span class="line">--bind-address</span><br></pre></td></tr></table></figure>
</li>
<li><p>决定了 Kubernetes Dashboard 能够启动成功的关键参数</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">## 证书相关的secret对象放在哪个namespace下，通常情况下与 Kubernetes Dashboard 的 pod 所在的 namespace 相同，默认值为 kube-system</span><br><span class="line">--namespace</span><br></pre></td></tr></table></figure>
</li>
<li><p>如何访问 Kubernetes Dashboard 的登录页</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">## 修改 service 类型为 NodePort 类型</span><br><span class="line"># kubectl edit service kubernetes-dashboard -n kubernetes-dashboard</span><br><span class="line">。。。。。。</span><br><span class="line">spec:</span><br><span class="line">  clusterIP: 10.96.56.103</span><br><span class="line">  externalTrafficPolicy: Cluster</span><br><span class="line">  ports:</span><br><span class="line">  - nodePort: 32027</span><br><span class="line">    port: 443</span><br><span class="line">    protocol: TCP</span><br><span class="line">    targetPort: 8443</span><br><span class="line">  selector:</span><br><span class="line">    k8s-app: kubernetes-dashboard</span><br><span class="line">  sessionAffinity: None</span><br><span class="line">  type: NodePort</span><br><span class="line">。。。。。。</span><br><span class="line"></span><br><span class="line">## 通过 https://&lt;node-ip&gt;:&lt;node-port&gt; 的形式访问 Kubernetes Dashboard 的登录页，例如 https://192.168.112.129:32027/</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p><img src="/2020/02/17/kubernetes_dashboard_000/login_01.png" alt="login_01"></p>
<h1 id="六、使用说明"><a href="#六、使用说明" class="headerlink" title="六、使用说明"></a>六、使用说明</h1><ol>
<li><p>创建访问用户并授权</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p access/</span><br><span class="line">cat &lt;&lt;EOF &gt; access/01-serviceaccount.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: admin-user</span><br><span class="line">  namespace: kubernetes-dashboard</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt; access/02-clusterrolebinding.yaml</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: admin-user</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: cluster-admin</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: admin-user</span><br><span class="line">  namespace: kubernetes-dashboard</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">kubectl create -f access/</span><br></pre></td></tr></table></figure>
</li>
<li><p>获取用户的 Token， 并在登录页面上输入， 然后登录 Kubernetes Dashboard</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">## 获取上一步授权的用户 Token，用于登录 Kubernetes Dashboard </span><br><span class="line"># kubectl -n kubernetes-dashboard describe secret $(kubectl -n kubernetes-dashboard get secret | grep admin-user | awk &apos;&#123;print $1&#125;&apos;)</span><br><span class="line">Name:         admin-user-token-bhp84</span><br><span class="line">Namespace:    kubernetes-dashboard</span><br><span class="line">Labels:       &lt;none&gt;</span><br><span class="line">Annotations:  kubernetes.io/service-account.name: admin-user</span><br><span class="line">              kubernetes.io/service-account.uid: 4c67c8da-0694-4de9-b978-eff7a1075bea</span><br><span class="line"></span><br><span class="line">Type:  kubernetes.io/service-account-token</span><br><span class="line"></span><br><span class="line">Data</span><br><span class="line">====</span><br><span class="line">ca.crt:     1025 bytes</span><br><span class="line">namespace:  20 bytes</span><br><span class="line">token:      eyJhbGciOiJSUzI1NiIsImtpZCI6IkpWcTFvc0Rza0xYZVVhVnlkRkhUX2VDM1RBR1hUNXpKVkdna3kyRTAyVlEifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlcm5ldGVzLWRhc2hib2FyZCIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJhZG1pbi11c2VyLXRva2VuLWJocDg0Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6ImFkbWluLXVzZXIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiI0YzY3YzhkYS0wNjk0LTRkZTktYjk3OC1lZmY3YTEwNzViZWEiLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZXJuZXRlcy1kYXNoYm9hcmQ6YWRtaW4tdXNlciJ9.aF2iWV--nNTdcrOTSQiQLEWi9QQnonjqk4EZNQSxcgqjZjUIaK1ezXBDrm9_bT5M9ddsMXKuE7E4PuTqk2IMTC_8m9DlinRrHHERAneI5OVO8aoAGqRo-pMyatEF7n9YfNoZMR0pLCWgrwrm1ttADHWtsTYsjrj4uT42Gt_h7J4i47VxF5g9qtqv8Jt_yoQNemje_XhWoGK4p9F_jPt3H8OrQ7CKYx1SwTGfw8t7P_mt9XY9AsWuUO4r4AixnZhWOLBtxa0QibM-mK7X4iREN3Ib8nmezVGkdiVt1epd_zmWAAWMHxEgh1D48wSro2Gb0e2p5AQQV2FAHJrfra4qUA</span><br><span class="line"></span><br><span class="line">## 登录页面上输入 Token 后，点击对应按钮即可实现登录</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p><img src="/2020/02/17/kubernetes_dashboard_000/login_02.png" alt="login_02"><br><img src="/2020/02/17/kubernetes_dashboard_000/login_03.png" alt="login_03"></p>
<h1 id="七、参考资料"><a href="#七、参考资料" class="headerlink" title="七、参考资料"></a>七、参考资料</h1><h2 id="1-Kubernetes-Dashboard-的官方资料"><a href="#1-Kubernetes-Dashboard-的官方资料" class="headerlink" title="1. Kubernetes Dashboard 的官方资料"></a>1. Kubernetes Dashboard 的官方资料</h2><p><a href="https://github.com/kubernetes/dashboard/blob/v2.0.0-rc5/src/app/backend/dashboard.go" target="_blank" rel="noopener">https://github.com/kubernetes/dashboard/blob/v2.0.0-rc5/src/app/backend/dashboard.go</a><br><a href="https://github.com/kubernetes/dashboard/blob/v2.0.0-rc5/docs/user/accessing-dashboard/1.7.x-and-above.md" target="_blank" rel="noopener">https://github.com/kubernetes/dashboard/blob/v2.0.0-rc5/docs/user/accessing-dashboard/1.7.x-and-above.md</a><br><a href="https://github.com/kubernetes/dashboard/blob/v2.0.0-rc5/docs/user/access-control/creating-sample-user.md" target="_blank" rel="noopener">https://github.com/kubernetes/dashboard/blob/v2.0.0-rc5/docs/user/access-control/creating-sample-user.md</a><br><a href="https://github.com/kubernetes/dashboard/blob/v2.0.0-rc5/docs/user/integrations.md" target="_blank" rel="noopener">https://github.com/kubernetes/dashboard/blob/v2.0.0-rc5/docs/user/integrations.md</a><br><a href="https://github.com/kubernetes/dashboard/blob/v2.0.0-rc5/docs/user/certificate-management.md" target="_blank" rel="noopener">https://github.com/kubernetes/dashboard/blob/v2.0.0-rc5/docs/user/certificate-management.md</a></p>
<h2 id="2-Kubernetes-Metric-Server"><a href="#2-Kubernetes-Metric-Server" class="headerlink" title="2. Kubernetes Metric Server"></a>2. Kubernetes Metric Server</h2><p><a href="https://www.cnblogs.com/ding2016/p/10786252.html" target="_blank" rel="noopener">https://www.cnblogs.com/ding2016/p/10786252.html</a><br><a href="https://github.com/singhwang/k8s-prom-hpa" target="_blank" rel="noopener">https://github.com/singhwang/k8s-prom-hpa</a></p>
<h2 id="3-关于-Chrome-无法访问-Kubernetes-Dashboard-的问题解决"><a href="#3-关于-Chrome-无法访问-Kubernetes-Dashboard-的问题解决" class="headerlink" title="3. 关于 Chrome 无法访问 Kubernetes Dashboard 的问题解决"></a>3. 关于 Chrome 无法访问 Kubernetes Dashboard 的问题解决</h2><p><a href="http://team.jiunile.com/blog/2018/12/k8s-dashboard-chrome-err.html" target="_blank" rel="noopener">http://team.jiunile.com/blog/2018/12/k8s-dashboard-chrome-err.html</a><br><a href="https://superuser.com/questions/27268/how-do-i-disable-the-warning-chrome-gives-if-a-security-certificate-is-not-trust" target="_blank" rel="noopener">https://superuser.com/questions/27268/how-do-i-disable-the-warning-chrome-gives-if-a-security-certificate-is-not-trust</a><br><a href="https://www.jianshu.com/p/a8cc2c04ee7c" target="_blank" rel="noopener">https://www.jianshu.com/p/a8cc2c04ee7c</a><br><a href="https://blog.gxxsite.com/wei-mac-osxde-cheng-xu-tian-jia-yong-jiu-qi-dong-can-shu/" target="_blank" rel="noopener">https://blog.gxxsite.com/wei-mac-osxde-cheng-xu-tian-jia-yong-jiu-qi-dong-can-shu/</a></p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Dashboard/">Dashboard</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Docker/">Docker</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Kubernetes/">Kubernetes</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Setup/">Setup</a></li></ul>
	</div>

      
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/容器云技术/">容器云技术</a>
	</div>


      
      <div class="clearfix"></div>
    </div>
      
    
  </div>
  
</article>







  
    <article id="post-kubernetes_tls_bootstrapping_000" class="article article-type-post" itemscope="" itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2020/01/07/kubernetes_tls_bootstrapping_000/" class="article-date">
  	<time datetime="2020-01-07T13:56:32.335Z" itemprop="datePublished">2020-01-07</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/01/07/kubernetes_tls_bootstrapping_000/">
        关于TLS bootstrapping的相关资料
        
      </a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="详细解释资料"><a href="#详细解释资料" class="headerlink" title="详细解释资料"></a>详细解释资料</h1><p><a href="https://mritd.me/2018/01/07/kubernetes-tls-bootstrapping-note/" target="_blank" rel="noopener">https://mritd.me/2018/01/07/kubernetes-tls-bootstrapping-note/</a><br><a href="https://mritd.me/2018/08/28/kubernetes-tls-bootstrapping-with-bootstrap-token/" target="_blank" rel="noopener">https://mritd.me/2018/08/28/kubernetes-tls-bootstrapping-with-bootstrap-token/</a></p>
<h1 id="官方资料"><a href="#官方资料" class="headerlink" title="官方资料"></a>官方资料</h1><p><a href="https://kubernetes.io/docs/reference/command-line-tools-reference/kubelet-tls-bootstrapping/" target="_blank" rel="noopener">https://kubernetes.io/docs/reference/command-line-tools-reference/kubelet-tls-bootstrapping/</a></p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Docker/">Docker</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Kubernetes/">Kubernetes</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Setup/">Setup</a></li></ul>
	</div>

      
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/容器云技术/">容器云技术</a>
	</div>


      
      <div class="clearfix"></div>
    </div>
      
    
  </div>
  
</article>







  
    <article id="post-binary_kubernetes_cluster_001" class="article article-type-post" itemscope="" itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2020/01/03/binary_kubernetes_cluster_001/" class="article-date">
  	<time datetime="2020-01-03T02:48:44.715Z" itemprop="datePublished">2020-01-03</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2020/01/03/binary_kubernetes_cluster_001/">
        使用二进制文件的方式安装 Kubernetes v1.17.0 集群（二）
        
      </a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="一、实现方式介绍"><a href="#一、实现方式介绍" class="headerlink" title="一、实现方式介绍"></a>一、实现方式介绍</h1><h2 id="1-控制平面的所有组件都采用二进制方式部署，交由systemd统一管理；"><a href="#1-控制平面的所有组件都采用二进制方式部署，交由systemd统一管理；" class="headerlink" title="1. 控制平面的所有组件都采用二进制方式部署，交由systemd统一管理；"></a>1. 控制平面的所有组件都采用二进制方式部署，交由systemd统一管理；</h2><p>控制平面包括：etcd、kube-apiserver、kube-controller-manager和kube-scheduler。</p>
<h2 id="2-工作节点上的所有组件都采用二进制方式部署，交由systemd统一管理；"><a href="#2-工作节点上的所有组件都采用二进制方式部署，交由systemd统一管理；" class="headerlink" title="2. 工作节点上的所有组件都采用二进制方式部署，交由systemd统一管理；"></a>2. 工作节点上的所有组件都采用二进制方式部署，交由systemd统一管理；</h2><p>工作节点上的组件包括：docker、kubelet和kube-proxy。</p>
<h2 id="3-网络插件依然采用Addon方式部署，交由kubernetes统一管理。"><a href="#3-网络插件依然采用Addon方式部署，交由kubernetes统一管理。" class="headerlink" title="3. 网络插件依然采用Addon方式部署，交由kubernetes统一管理。"></a>3. 网络插件依然采用Addon方式部署，交由kubernetes统一管理。</h2><p>网络插件包括：calico-node及其相关的组件和coredns。</p>
<h1 id="二、实验环境版本信息"><a href="#二、实验环境版本信息" class="headerlink" title="二、实验环境版本信息"></a>二、实验环境版本信息</h1><h2 id="1-操作系统的版本信息"><a href="#1-操作系统的版本信息" class="headerlink" title="1. 操作系统的版本信息"></a>1. 操作系统的版本信息</h2><p>CentOS Linux release 7.6.1810 (Core)</p>
<h2 id="2-各组件的版本信息"><a href="#2-各组件的版本信息" class="headerlink" title="2. 各组件的版本信息"></a>2. 各组件的版本信息</h2><p>etcd v3.4.3<br>kube-apiserver v1.17.0<br>kube-controller-manager v1.17.0<br>kube-scheduler v1.17.0<br>kubectl v1.17.0</p>
<p>docker 18.09.9<br>kubelet v1.17.0<br>calico v3.11.1</p>
<h1 id="三、部署架构"><a href="#三、部署架构" class="headerlink" title="三、部署架构"></a>三、部署架构</h1><h2 id="1-Kubernetes-Master（Control-Plane）"><a href="#1-Kubernetes-Master（Control-Plane）" class="headerlink" title="1. Kubernetes Master（Control Plane）"></a>1. Kubernetes Master（Control Plane）</h2><p>192.168.112.128 master -&gt; etcd kube-apiserver kube-controller-manager kube-scheduler</p>
<h2 id="2-Kubernetes-Node"><a href="#2-Kubernetes-Node" class="headerlink" title="2. Kubernetes Node"></a>2. Kubernetes Node</h2><p>192.168.112.129 node01 -&gt; docker kubelet kube-proxy calico-node<br>192.168.112.130 node02 -&gt; docker kubelet kube-proxy calico-node</p>
<h1 id="四、准备二进制文件与Docker镜像"><a href="#四、准备二进制文件与Docker镜像" class="headerlink" title="四、准备二进制文件与Docker镜像"></a>四、准备二进制文件与Docker镜像</h1><h2 id="1-下载相关的二进制文件压缩包"><a href="#1-下载相关的二进制文件压缩包" class="headerlink" title="1. 下载相关的二进制文件压缩包"></a>1. 下载相关的二进制文件压缩包</h2><p><a href="https://github.com/etcd-io/etcd/releases/download/v3.4.3/etcd-v3.4.3-linux-amd64.tar.gz" target="_blank" rel="noopener">https://github.com/etcd-io/etcd/releases/download/v3.4.3/etcd-v3.4.3-linux-amd64.tar.gz</a><br><a href="https://dl.k8s.io/v1.17.0/kubernetes-server-linux-amd64.tar.gz" target="_blank" rel="noopener">https://dl.k8s.io/v1.17.0/kubernetes-server-linux-amd64.tar.gz</a></p>
<h2 id="2-拉取相关的Docker镜像"><a href="#2-拉取相关的Docker镜像" class="headerlink" title="2. 拉取相关的Docker镜像"></a>2. 拉取相关的Docker镜像</h2><p>calico网络组件的镜像：<br>calico/node:v3.11.1<br>calico/pod2daemon-flexvol:v3.11.1<br>calico/cni:v3.11.1<br>calico/kube-controllers:v3.11.1</p>
<p>kube-dns的镜像：<br>registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:1.6.5</p>
<p>infra容器的镜像：<br>registry.cn-hangzhou.aliyuncs.com/google_containers/pause-amd64:3.1</p>
<h1 id="五、部署过程记录"><a href="#五、部署过程记录" class="headerlink" title="五、部署过程记录"></a>五、部署过程记录</h1><h2 id="1-准备基础环境（Master和Node上都执行）"><a href="#1-准备基础环境（Master和Node上都执行）" class="headerlink" title="1. 准备基础环境（Master和Node上都执行）"></a>1. 准备基础环境（Master和Node上都执行）</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"># 更新系统</span><br><span class="line">yum update -y</span><br><span class="line"></span><br><span class="line"># 设置正确的时区和时间</span><br><span class="line">yum install -y ntpdate</span><br><span class="line">timedatectl set-timezone Asia/Shanghai</span><br><span class="line">ntpdate cn.ntp.org.cn</span><br><span class="line"></span><br><span class="line"># 关闭防火墙</span><br><span class="line">systemctl disable firewalld.service</span><br><span class="line">systemctl stop firewalld.service</span><br><span class="line"></span><br><span class="line"># 关闭swap分区</span><br><span class="line">swapoff -a</span><br><span class="line">sed -i &apos;s#/dev/mapper/cl-swap#\# /dev/mapper/cl-swap#&apos; /etc/fstab</span><br><span class="line"></span><br><span class="line"># 关闭selinux</span><br><span class="line">setenforce 0</span><br><span class="line">sed -i &apos;s/SELINUX=enforcing/SELINUX=disabled/&apos; /etc/selinux/config</span><br><span class="line"></span><br><span class="line"># 设置各个节点的主机名</span><br><span class="line">## 192.168.112.128</span><br><span class="line">hostnamectl set-hostname master</span><br><span class="line"></span><br><span class="line">## 192.168.112.129</span><br><span class="line">hostnamectl set-hostname node01</span><br><span class="line"></span><br><span class="line">## 192.168.112.130</span><br><span class="line">hostnamectl set-hostname node02</span><br><span class="line"></span><br><span class="line"># 配置主机名和IP的映射</span><br><span class="line">cat &lt;&lt;EOF &gt;&gt; /etc/hosts</span><br><span class="line"></span><br><span class="line"># For Kubernetes Cluster</span><br><span class="line">192.168.112.128 master</span><br><span class="line">192.168.112.129 node01</span><br><span class="line">192.168.112.130 node02</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"># 修改内核参数</span><br><span class="line">cat &lt;&lt;EOF &gt; /etc/sysctl.d/kubernetes.conf</span><br><span class="line">net.bridge.bridge-nf-call-iptables = 1</span><br><span class="line"></span><br><span class="line">net.ipv4.ip_forward = 1</span><br><span class="line"></span><br><span class="line">net.ipv4.tcp_timestamps = 1</span><br><span class="line">net.ipv4.tcp_tw_recycle = 1 </span><br><span class="line"></span><br><span class="line">net.ipv4.tcp_fin_timeout = 30</span><br><span class="line">net.ipv4.tcp_tw_resue = 1</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">sysctl --system</span><br><span class="line"></span><br><span class="line"># 修改ulimit限制</span><br><span class="line">cat &lt;&lt;EOF &gt;  /etc/security/limits.d/kubernetes.conf</span><br><span class="line">* hard nofile 65535</span><br><span class="line">* soft nofile 65535</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>
<h2 id="2-安装Docker环境（在所有Node上都执行）"><a href="#2-安装Docker环境（在所有Node上都执行）" class="headerlink" title="2. 安装Docker环境（在所有Node上都执行）"></a>2. 安装Docker环境（在所有Node上都执行）</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"># 配置yum源，然后安装Docker</span><br><span class="line">yum install -y yum-utils device-mapper-persistent-data lvm2</span><br><span class="line">yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</span><br><span class="line">yum makecache fast</span><br><span class="line">yum install -y docker-ce-18.09.9-3.el7 docker-ce-cli-18.09.9-3.el7</span><br><span class="line"></span><br><span class="line"># 启动Docker，并将其设置为开机启动</span><br><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable docker.service</span><br><span class="line">systemctl start docker.service</span><br><span class="line"></span><br><span class="line"># 确认Docker启动是否正常</span><br><span class="line">systemctl status docker.service</span><br><span class="line">docker info</span><br><span class="line">docker version</span><br><span class="line"></span><br><span class="line"># 方法一：检查iptables的forward链的默认策略</span><br><span class="line">iptables -nL</span><br><span class="line">。。。</span><br><span class="line">Chain FORWARD (policy ACCEPT)</span><br><span class="line">。。。</span><br><span class="line"></span><br><span class="line"># 方法二：检查iptables的forward链的默认策略</span><br><span class="line">iptables-save -t filter</span><br><span class="line">。。。</span><br><span class="line"># Generated by iptables-save v1.4.21 on Thu Oct  3 12:28:24 2019</span><br><span class="line">*filter</span><br><span class="line">:INPUT ACCEPT [2117:366255]</span><br><span class="line">:FORWARD ACCEPT [0:0]</span><br><span class="line">:OUTPUT ACCEPT [2188:436727]</span><br><span class="line">。。。</span><br><span class="line"></span><br><span class="line"># 设置docker daemon的cgroup driver为systemd</span><br><span class="line">cat &lt;&lt;EOF &gt; /etc/docker/daemon.json</span><br><span class="line">&#123;</span><br><span class="line">  &quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;],</span><br><span class="line">  &quot;log-driver&quot;:&quot;json-file&quot;,</span><br><span class="line">  &quot;log-opts&quot;: &#123;</span><br><span class="line">     &quot;max-size&quot;: &quot;10m&quot;,</span><br><span class="line">     &quot;max-file&quot;: &quot;3&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl restart docker.service</span><br><span class="line">systemctl status docker.service</span><br><span class="line"></span><br><span class="line"># 验证docker daemon的cgroup driver是否为systemd</span><br><span class="line">docker info</span><br><span class="line">。。。</span><br><span class="line">Cgroup Driver: systemd</span><br><span class="line">。。。</span><br></pre></td></tr></table></figure>
<h2 id="3-复制所有二进制文件到操作系统-usr-bin-目录下"><a href="#3-复制所有二进制文件到操作系统-usr-bin-目录下" class="headerlink" title="3. 复制所有二进制文件到操作系统/usr/bin/目录下"></a>3. 复制所有二进制文件到操作系统/usr/bin/目录下</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># 192.168.112.128 （Master上执行）</span><br><span class="line">tar -zxvf etcd-v3.4.3-linux-amd64.tar.gz</span><br><span class="line">tar -zxvf kubernetes-server-linux-amd64.tar.gz</span><br><span class="line"></span><br><span class="line">cp etcd-v3.4.3-linux-amd64/etcd /usr/bin/</span><br><span class="line">cp etcd-v3.4.3-linux-amd64/etcdctl /usr/bin/</span><br><span class="line">cp kubernetes/server/bin/kube-apiserver /usr/bin/</span><br><span class="line">cp kubernetes/server/bin/kube-controller-manager /usr/bin/</span><br><span class="line">cp kubernetes/server/bin/kube-scheduler /usr/bin/</span><br><span class="line">cp kubernetes/server/bin/kubectl /usr/bin/</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 192.168.112.129 和 192.168.112.130 （Node上执行）</span><br><span class="line">tar -zxvf kubernetes-server-linux-amd64.tar.gz</span><br><span class="line"></span><br><span class="line">cp kubernetes/server/bin/kubelet /usr/bin/</span><br><span class="line">cp kubernetes/server/bin/kube-proxy /usr/bin/</span><br></pre></td></tr></table></figure>
<h1 id="4-在Master上生成所有组件的相关证书和配置文件"><a href="#4-在Master上生成所有组件的相关证书和配置文件" class="headerlink" title="4. 在Master上生成所有组件的相关证书和配置文件"></a>4. 在Master上生成所有组件的相关证书和配置文件</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br></pre></td><td class="code"><pre><span class="line"># 创建证书和配置文件的存放目录</span><br><span class="line">mkdir -p /etc/kubernetes/pki/etcd/</span><br><span class="line"></span><br><span class="line"># 生成etcd的相关证书</span><br><span class="line">cd /etc/kubernetes/pki/etcd/</span><br><span class="line">openssl genrsa -out ca.key 2048</span><br><span class="line">openssl req -x509 -new -nodes -key ca.key -subj &quot;/CN=etcd-ca&quot; -days 5000 -out ca.crt</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt; server_ssl.cnf</span><br><span class="line">[req]</span><br><span class="line">req_extensions = v3_req</span><br><span class="line">distinguished_name = req_distinguished_name</span><br><span class="line"></span><br><span class="line">[req_distinguished_name]</span><br><span class="line">[v3_req]</span><br><span class="line">basicConstraints = CA:FALSE</span><br><span class="line">keyUsage = nonRepudiation,digitalSignature,keyEncipherment</span><br><span class="line">subjectAltName = @alt_names</span><br><span class="line">[alt_names]</span><br><span class="line">DNS.1 = master</span><br><span class="line">DNS.2 = localhost</span><br><span class="line">IP.1 = 192.168.112.128</span><br><span class="line">IP.2 = 127.0.0.1</span><br><span class="line">EOF</span><br><span class="line">openssl genrsa -out server.key 2048</span><br><span class="line">openssl req -new -key server.key -subj &quot;/CN=master&quot; -config server_ssl.cnf -out server.csr</span><br><span class="line">openssl x509 -req -in server.csr -CA ca.crt -CAkey ca.key -CAcreateserial -days 5000 -extensions v3_req -extfile server_ssl.cnf -out server.crt</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt; peer_ssl.cnf</span><br><span class="line">[req]</span><br><span class="line">req_extensions = v3_req</span><br><span class="line">distinguished_name = req_distinguished_name</span><br><span class="line"></span><br><span class="line">[req_distinguished_name]</span><br><span class="line">[v3_req]</span><br><span class="line">basicConstraints = CA:FALSE</span><br><span class="line">keyUsage = nonRepudiation,digitalSignature,keyEncipherment</span><br><span class="line">subjectAltName = @alt_names</span><br><span class="line">[alt_names]</span><br><span class="line">DNS.1 = master</span><br><span class="line">DNS.2 = localhost</span><br><span class="line">IP.1 = 192.168.112.128</span><br><span class="line">IP.2 = 127.0.0.1</span><br><span class="line">EOF</span><br><span class="line">openssl genrsa -out peer.key 2048</span><br><span class="line">openssl req -new -key peer.key -subj &quot;/CN=master&quot; -config peer_ssl.cnf -out peer.csr</span><br><span class="line">openssl x509 -req -in peer.csr -CA ca.crt -CAkey ca.key -CAcreateserial -days 5000 -extensions v3_req -extfile peer_ssl.cnf -out peer.crt</span><br><span class="line"></span><br><span class="line">openssl genrsa -out healthcheck-client.key 2048</span><br><span class="line">openssl req -new -key healthcheck-client.key -subj &quot;/O=system:masters/CN=kube-etcd-healthcheck-client&quot; -out healthcheck-client.csr</span><br><span class="line">openssl x509 -req -in healthcheck-client.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out healthcheck-client.crt -days 5000</span><br><span class="line"></span><br><span class="line">cd /etc/kubernetes/pki/</span><br><span class="line">openssl genrsa -out apiserver-etcd-client.key 2048</span><br><span class="line">openssl req -new -key apiserver-etcd-client.key -subj &quot;/O=system:masters/CN=kube-apiserver-etcd-client&quot; -out apiserver-etcd-client.csr</span><br><span class="line">openssl x509 -req -in apiserver-etcd-client.csr -CA /etc/kubernetes/pki/etcd/ca.crt -CAkey /etc/kubernetes/pki/etcd/ca.key -CAcreateserial -out apiserver-etcd-client.crt -days 5000</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 生成kubernetes组件的相关证书</span><br><span class="line"># 生成rsa的公钥和私钥</span><br><span class="line">openssl genrsa -out sa.key 2048</span><br><span class="line">openssl rsa -in sa.key -pubout -out sa.pub</span><br><span class="line"></span><br><span class="line"># 生成根证书</span><br><span class="line">openssl genrsa -out ca.key 2048</span><br><span class="line">openssl req -x509 -new -nodes -key ca.key -subj &quot;/CN=kubernetes&quot; -days 5000 -out ca.crt</span><br><span class="line"></span><br><span class="line">openssl genrsa -out front-proxy-ca.key 2048</span><br><span class="line">openssl req -x509 -new -nodes -key front-proxy-ca.key -subj &quot;/CN=front-proxy-ca&quot; -days 5000 -out front-proxy-ca.crt</span><br><span class="line"></span><br><span class="line"># 为kube-apiserver生成相关的证书和配置文件</span><br><span class="line">cat &lt;&lt;EOF &gt; master_ssl.cnf</span><br><span class="line">[req]</span><br><span class="line">req_extensions = v3_req</span><br><span class="line">distinguished_name = req_distinguished_name</span><br><span class="line"></span><br><span class="line">[req_distinguished_name]</span><br><span class="line">[v3_req]</span><br><span class="line">basicConstraints = CA:FALSE</span><br><span class="line">keyUsage = nonRepudiation,digitalSignature,keyEncipherment</span><br><span class="line">subjectAltName = @alt_names</span><br><span class="line">[alt_names]</span><br><span class="line">DNS.1 = master</span><br><span class="line">DNS.2 = kubernetes</span><br><span class="line">DNS.3 = kubernetes.default</span><br><span class="line">DNS.4 = kubernetes.default.svc</span><br><span class="line">DNS.5 = kubernetes.default.svc.cluster.local</span><br><span class="line">IP.1 = 10.96.0.1</span><br><span class="line">IP.2 = 192.168.112.128</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">openssl genrsa -out apiserver.key 2048</span><br><span class="line">openssl req -new -key apiserver.key -subj &quot;/CN=kube-apiserver&quot; -config master_ssl.cnf -out apiserver.csr</span><br><span class="line">openssl x509 -req -in apiserver.csr -CA ca.crt -CAkey ca.key -CAcreateserial -days 5000 -extensions v3_req -extfile master_ssl.cnf -out apiserver.crt</span><br><span class="line"></span><br><span class="line">openssl genrsa -out front-proxy-client.key 2048</span><br><span class="line">openssl req -new -key front-proxy-client.key -subj &quot;/CN=front-proxy-client&quot; -out front-proxy-client.csr</span><br><span class="line">openssl x509 -req -in front-proxy-client.csr -CA front-proxy-ca.crt -CAkey front-proxy-ca.key -CAcreateserial -out front-proxy-client.crt -days 5000</span><br><span class="line"></span><br><span class="line">openssl genrsa -out apiserver-kubelet-client.key 2048</span><br><span class="line">openssl req -new -key apiserver-kubelet-client.key -subj &quot;/O=system:masters/CN=kube-apiserver-kubelet-client&quot; -out apiserver-kubelet-client.csr</span><br><span class="line">openssl x509 -req -in apiserver-kubelet-client.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out apiserver-kubelet-client.crt -days 5000</span><br><span class="line"></span><br><span class="line"># 为kube-controller-manager生成相关的证书和配置文件</span><br><span class="line">openssl genrsa -out controller-manager.key 2048</span><br><span class="line">openssl req -new -key controller-manager.key -subj &quot;/CN=system:kube-controller-manager&quot; -out controller-manager.csr</span><br><span class="line">openssl x509 -req -in controller-manager.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out controller-manager.crt -days 5000</span><br><span class="line"></span><br><span class="line">export KUBECONFIG=/etc/kubernetes/controller-manager.conf</span><br><span class="line">kubectl config set-cluster kubernetes --server=https://192.168.112.128:6443 --certificate-authority=/etc/kubernetes/pki/ca.crt --embed-certs=true</span><br><span class="line">kubectl config set-credentials system:kube-controller-manager --client-certificate=/etc/kubernetes/pki/controller-manager.crt --client-key=/etc/kubernetes/pki/controller-manager.key --embed-certs=true</span><br><span class="line">kubectl config set-context system:kube-controller-manager@kubernetes --cluster=kubernetes --user=system:kube-controller-manager</span><br><span class="line">kubectl config use-context system:kube-controller-manager@kubernetes</span><br><span class="line">unset KUBECONFIG</span><br><span class="line"></span><br><span class="line"># 为kube-scheduler生成相关的证书和配置文件</span><br><span class="line">openssl genrsa -out scheduler.key 2048</span><br><span class="line">openssl req -new -key scheduler.key -subj &quot;/CN=system:kube-scheduler&quot; -out scheduler.csr</span><br><span class="line">openssl x509 -req -in scheduler.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out scheduler.crt -days 5000</span><br><span class="line"></span><br><span class="line">export KUBECONFIG=/etc/kubernetes/scheduler.conf</span><br><span class="line">kubectl config set-cluster kubernetes --server=https://192.168.112.128:6443 --certificate-authority=/etc/kubernetes/pki/ca.crt --embed-certs=true</span><br><span class="line">kubectl config set-credentials system:kube-scheduler --client-certificate=/etc/kubernetes/pki/scheduler.crt --client-key=/etc/kubernetes/pki/scheduler.key --embed-certs=true</span><br><span class="line">kubectl config set-context system:kube-scheduler@kubernetes --cluster=kubernetes --user=system:kube-scheduler</span><br><span class="line">kubectl config use-context system:kube-scheduler@kubernetes</span><br><span class="line">unset KUBECONFIG</span><br><span class="line"></span><br><span class="line"># 为kubectl生成相关的证书和配置文件</span><br><span class="line">openssl genrsa -out kubectl.key 2048</span><br><span class="line">openssl req -new -key kubectl.key -subj &quot;/O=system:masters/CN=kubernetes-admin&quot; -out kubectl.csr</span><br><span class="line">openssl x509 -req -in kubectl.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out kubectl.crt -days 5000</span><br><span class="line"></span><br><span class="line">export KUBECONFIG=/etc/kubernetes/admin.conf</span><br><span class="line">kubectl config set-cluster kubernetes --server=https://192.168.112.128:6443 --certificate-authority=/etc/kubernetes/pki/ca.crt --embed-certs=true</span><br><span class="line">kubectl config set-credentials kubernetes-admin --client-certificate=/etc/kubernetes/pki/kubectl.crt --client-key=/etc/kubernetes/pki/kubectl.key --embed-certs=true</span><br><span class="line">kubectl config set-context kubernetes-admin@kubernetes --cluster=kubernetes --user=kubernetes-admin</span><br><span class="line">kubectl config use-context kubernetes-admin@kubernetes</span><br><span class="line">unset KUBECONFIG</span><br><span class="line"></span><br><span class="line"># 注意：因为kubelet使用了tls bootstrap的方式，所以下面这部分内容没有必要了，需把其注释掉</span><br><span class="line"># 为kubelet生成相关的证书和配置文件</span><br><span class="line"># openssl genrsa -out kubelet.key 2048</span><br><span class="line"># openssl req -new -key kubelet.key -subj &quot;/O=system:nodes/CN=system:node:node01&quot; -out kubelet.csr</span><br><span class="line"># openssl x509 -req -in kubelet.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out kubelet.crt -days 5000</span><br><span class="line"># </span><br><span class="line"># export KUBECONFIG=/etc/kubernetes/kubelet.conf</span><br><span class="line"># kubectl config set-cluster kubernetes --server=https://192.168.112.128:6443 --certificate-authority=/etc/kubernetes/pki/ca.crt # --embed-certs=true</span><br><span class="line"># kubectl config set-credentials system:node:node01 --client-certificate=/etc/kubernetes/pki/kubelet.crt --client-key=/etc/kubernetes/pki/# kubelet.key --embed-certs=true</span><br><span class="line"># kubectl config set-context system:node:node01@kubernetes --cluster=kubernetes --user=system:node:node01</span><br><span class="line"># kubectl config use-context system:node:node01@kubernetes</span><br><span class="line"># unset KUBECONFIG</span><br><span class="line"></span><br><span class="line"># 为kube-proxy生成相关的证书和配置文件</span><br><span class="line"># kubernetes内置的为kube-proxy而生的clusterrole，可以使用kubectl get clusterrole system:node-proxier -o yaml进行查看</span><br><span class="line"># kubernetes内置的为kube-proxy而生的clusterrolebinding，绑定到了用户system:kube-proxy，可以使用kubectl get clusterrolebinding system:node-proxier -o yaml进行查看</span><br><span class="line">openssl genrsa -out proxy.key 2048</span><br><span class="line">openssl req -new -key proxy.key -subj &quot;/CN=system:kube-proxy&quot; -out proxy.csr</span><br><span class="line">openssl x509 -req -in proxy.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out proxy.crt -days 5000</span><br><span class="line"></span><br><span class="line">export KUBECONFIG=/etc/kubernetes/proxy.conf</span><br><span class="line">kubectl config set-cluster kubernetes --server=https://192.168.112.128:6443 --certificate-authority=/etc/kubernetes/pki/ca.crt --embed-certs=true</span><br><span class="line">kubectl config set-credentials system:kube-proxy --client-certificate=/etc/kubernetes/pki/proxy.crt --client-key=/etc/kubernetes/pki/proxy.key --embed-certs=true</span><br><span class="line">kubectl config set-context system:kube-proxy@kubernetes --cluster=kubernetes --user=system:kube-proxy</span><br><span class="line">kubectl config use-context system:kube-proxy@kubernetes</span><br><span class="line">unset KUBECONFIG</span><br></pre></td></tr></table></figure>
<h2 id="5-配置和启动Master上的所有组件"><a href="#5-配置和启动Master上的所有组件" class="headerlink" title="5. 配置和启动Master上的所有组件"></a>5. 配置和启动Master上的所有组件</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br></pre></td><td class="code"><pre><span class="line"># 配置和启动etcd服务</span><br><span class="line">mkdir -p /etc/etcd/</span><br><span class="line">mkdir -p /var/lib/etcd/</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt; /usr/lib/systemd/system/etcd.service</span><br><span class="line">[Unit]</span><br><span class="line">Description=Etcd Server </span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=simple</span><br><span class="line">WorkingDirectory=/var/lib/etcd/</span><br><span class="line">EnvironmentFile=-/etc/etcd/etcd.env</span><br><span class="line">ExecStart=/usr/bin/etcd \$ETCD_ARGS</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt; /etc/etcd/etcd.env</span><br><span class="line">ETCD_ARGS=&quot;--advertise-client-urls=https://192.168.112.128:2379 --cert-file=/etc/kubernetes/pki/etcd/server.crt --client-cert-auth=true --data-dir=/var/lib/etcd --initial-advertise-peer-urls=https://192.168.112.128:2380 --initial-cluster=master=https://192.168.112.128:2380 --key-file=/etc/kubernetes/pki/etcd/server.key --listen-client-urls=https://127.0.0.1:2379,https://192.168.112.128:2379 --listen-metrics-urls=http://127.0.0.1:2381 --listen-peer-urls=https://192.168.112.128:2380 --name=master --peer-cert-file=/etc/kubernetes/pki/etcd/peer.crt --peer-client-cert-auth=true --peer-key-file=/etc/kubernetes/pki/etcd/peer.key --peer-trusted-ca-file=/etc/kubernetes/pki/etcd/ca.crt --snapshot-count=10000 --trusted-ca-file=/etc/kubernetes/pki/etcd/ca.crt&quot;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable etcd.service</span><br><span class="line">systemctl start etcd.service</span><br><span class="line">systemctl status etcd.service</span><br><span class="line"></span><br><span class="line"># 配置和启动kube-apiserver服务</span><br><span class="line">cat &lt;&lt;EOF &gt; /usr/lib/systemd/system/kube-apiserver.service</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes API Server</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=etcd.service</span><br><span class="line">Wants=etcd.service</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">EnvironmentFile=-/etc/kubernetes/kube-apiserver.env</span><br><span class="line">ExecStart=/usr/bin/kube-apiserver \$KUBE_API_ARGS</span><br><span class="line">Restart=on-failure</span><br><span class="line">Type=notify</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt; /etc/kubernetes/kube-apiserver.env</span><br><span class="line">KUBE_API_ARGS=&quot; --advertise-address=192.168.112.128 --allow-privileged=true --authorization-mode=Node,RBAC --client-ca-file=/etc/kubernetes/pki/ca.crt --enable-admission-plugins=NodeRestriction --enable-bootstrap-token-auth=true --etcd-cafile=/etc/kubernetes/pki/etcd/ca.crt --etcd-certfile=/etc/kubernetes/pki/apiserver-etcd-client.crt --etcd-keyfile=/etc/kubernetes/pki/apiserver-etcd-client.key --etcd-servers=https://127.0.0.1:2379 --insecure-port=0 --kubelet-client-certificate=/etc/kubernetes/pki/apiserver-kubelet-client.crt --kubelet-client-key=/etc/kubernetes/pki/apiserver-kubelet-client.key --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.crt --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client.key --requestheader-allowed-names=front-proxy-client --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt --requestheader-extra-headers-prefix=X-Remote-Extra- --requestheader-group-headers=X-Remote-Group --requestheader-username-headers=X-Remote-User --secure-port=6443 --service-account-key-file=/etc/kubernetes/pki/sa.pub --service-cluster-ip-range=10.96.0.0/16 --tls-cert-file=/etc/kubernetes/pki/apiserver.crt --tls-private-key-file=/etc/kubernetes/pki/apiserver.key&quot;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable kube-apiserver.service</span><br><span class="line">systemctl start kube-apiserver.service</span><br><span class="line">systemctl status kube-apiserver.service</span><br><span class="line"></span><br><span class="line">export KUBECONFIG=/etc/kubernetes/admin.conf</span><br><span class="line"></span><br><span class="line"># 为各个系统组件涉及的用户绑定cluster-admin角色</span><br><span class="line"># export KUBECONFIG=/etc/kubernetes/admin.conf</span><br><span class="line"># kubectl create clusterrolebinding kube-apiserver --clusterrole=cluster-admin --user=kube-apiserver</span><br><span class="line"># kubectl create clusterrolebinding front-proxy-client --clusterrole=cluster-admin --user=front-proxy-client</span><br><span class="line"># kubectl create clusterrolebinding system:kube-controller-manager --clusterrole=cluster-admin --user=system:kube-controller-manager </span><br><span class="line"># kubectl create clusterrolebinding system:kube-scheduler --clusterrole=cluster-admin --user=system:kube-scheduler </span><br><span class="line"># kubectl create clusterrolebinding system:kubelet --clusterrole=cluster-admin --user=system:kubelet </span><br><span class="line"># kubectl create clusterrolebinding system:kube-proxy --clusterrole=cluster-admin --user=system:kube-proxy</span><br><span class="line"></span><br><span class="line"># 创建Bootstrap Token的相关配置 注意：expiration必须要在当前日期以后，否则会出现token创建后，kubernetes就会自动删除</span><br><span class="line">cat &lt;&lt;EOF &gt; /etc/kubernetes/bootstrap-token-abcdef.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Secret</span><br><span class="line">metadata:</span><br><span class="line">  name: bootstrap-token-abcdef</span><br><span class="line">  namespace: kube-system</span><br><span class="line">type: bootstrap.kubernetes.io/token</span><br><span class="line">stringData:</span><br><span class="line">  auth-extra-groups: system:bootstrappers:default-node-token</span><br><span class="line">  expiration: 2020-01-31T00:00:00+08:00</span><br><span class="line">  token-id: abcdef</span><br><span class="line">  token-secret: 0123456789abcdef</span><br><span class="line">  usage-bootstrap-authentication: &quot;true&quot;</span><br><span class="line">  usage-bootstrap-signing: &quot;true&quot;</span><br><span class="line">EOF</span><br><span class="line">kubectl create -f /etc/kubernetes/bootstrap-token-abcdef.yaml</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt; /etc/kubernetes/create-csrs-for-bootstrapping.yaml</span><br><span class="line"># enable bootstrapping nodes to create CSR</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: create-csrs-for-bootstrapping</span><br><span class="line">subjects:</span><br><span class="line">- kind: Group</span><br><span class="line">  name: system:bootstrappers</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">roleRef:</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: system:node-bootstrapper</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">EOF</span><br><span class="line">kubectl create -f /etc/kubernetes/create-csrs-for-bootstrapping.yaml</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt; /etc/kubernetes/auto-approve-csrs-for-group.yaml</span><br><span class="line"># Approve all CSRs for the group &quot;system:bootstrappers&quot;</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: auto-approve-csrs-for-group</span><br><span class="line">subjects:</span><br><span class="line">- kind: Group</span><br><span class="line">  name: system:bootstrappers</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">roleRef:</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: system:certificates.k8s.io:certificatesigningrequests:nodeclient</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">EOF</span><br><span class="line">kubectl create -f /etc/kubernetes/auto-approve-csrs-for-group.yaml</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt; /etc/kubernetes/auto-approve-renewals-for-nodes.yaml</span><br><span class="line"># Approve renewal CSRs for the group &quot;system:nodes&quot;</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: auto-approve-renewals-for-nodes</span><br><span class="line">subjects:</span><br><span class="line">- kind: Group</span><br><span class="line">  name: system:nodes</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">roleRef:</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: system:certificates.k8s.io:certificatesigningrequests:selfnodeclient</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">EOF</span><br><span class="line">kubectl create -f /etc/kubernetes/auto-approve-renewals-for-nodes.yaml</span><br><span class="line"></span><br><span class="line">export KUBECONFIG=/etc/kubernetes/bootstrap-kubelet.conf</span><br><span class="line">kubectl config set-cluster kubernetes --server=https://192.168.112.128:6443 --certificate-authority=/etc/kubernetes/pki/ca.crt --embed-certs=true</span><br><span class="line">kubectl config set-credentials system:bootstrap:abcdef --token=abcdef.0123456789abcdef</span><br><span class="line">kubectl config set-context system:bootstrap:abcdef@kubernetes --cluster=kubernetes --user=system:bootstrap:abcdef</span><br><span class="line">kubectl config use-context system:bootstrap:abcdef@kubernetes</span><br><span class="line">unset KUBECONFIG</span><br><span class="line"></span><br><span class="line"># 配置和启动kube-controller-manager服务</span><br><span class="line">cat &lt;&lt;EOF &gt; /usr/lib/systemd/system/kube-controller-manager.service</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Controller Manager</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=kube-apiserver.service</span><br><span class="line">Requires=kube-apiserver.service</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">EnvironmentFile=-/etc/kubernetes/kube-controller-manager.env</span><br><span class="line">ExecStart=/usr/bin/kube-controller-manager \$KUBE_CONTROLLER_MANAGER_ARGS</span><br><span class="line">Restart=on-failure</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt; /etc/kubernetes/kube-controller-manager.env</span><br><span class="line">KUBE_CONTROLLER_MANAGER_ARGS=&quot;--allocate-node-cidrs=true --authentication-kubeconfig=/etc/kubernetes/controller-manager.conf --authorization-kubeconfig=/etc/kubernetes/controller-manager.conf --bind-address=127.0.0.1 --client-ca-file=/etc/kubernetes/pki/ca.crt --cluster-cidr=10.211.0.0/16 --cluster-signing-cert-file=/etc/kubernetes/pki/ca.crt --cluster-signing-key-file=/etc/kubernetes/pki/ca.key --controllers=*,bootstrapsigner,tokencleaner --kubeconfig=/etc/kubernetes/controller-manager.conf --leader-elect=true --node-cidr-mask-size=24 --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt --root-ca-file=/etc/kubernetes/pki/ca.crt --service-account-private-key-file=/etc/kubernetes/pki/sa.key --service-cluster-ip-range=10.96.0.0/16 --use-service-account-credentials=true&quot;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable kube-controller-manager.service</span><br><span class="line">systemctl start kube-controller-manager.service</span><br><span class="line">systemctl status kube-controller-manager.service</span><br><span class="line"></span><br><span class="line"># 配置和启动kube-scheduler服务</span><br><span class="line">cat &lt;&lt;EOF &gt; /usr/lib/systemd/system/kube-scheduler.service</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Scheduler</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=kube-apiserver.service</span><br><span class="line">Requires=kube-apiserver.service</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">EnvironmentFile=-/etc/kubernetes/kube-scheduler.env</span><br><span class="line">ExecStart=/usr/bin/kube-scheduler \$KUBE_SCHEDULER_ARGS</span><br><span class="line">Restart=on-failure</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt; /etc/kubernetes/kube-scheduler.env</span><br><span class="line">KUBE_SCHEDULER_ARGS=&quot; --authentication-kubeconfig=/etc/kubernetes/scheduler.conf --authorization-kubeconfig=/etc/kubernetes/scheduler.conf --bind-address=127.0.0.1 --kubeconfig=/etc/kubernetes/scheduler.conf --leader-elect=true&quot;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable kube-scheduler.service</span><br><span class="line">systemctl start kube-scheduler.service</span><br><span class="line">systemctl status kube-scheduler.service</span><br><span class="line"></span><br><span class="line"># 如果master节点需要具备node节点的功能，那么请参考5中的步骤，先在master上完成kubelet和kube-proxy的安装后，再给master节点打上下面的标签和污点</span><br><span class="line">kubectl label node master node-role.kubernetes.io/master=</span><br><span class="line">kubectl taint node master node-role.kubernetes.io/master=:NoSchedule</span><br></pre></td></tr></table></figure>
<h2 id="5-配置和启动Node上的所有组件"><a href="#5-配置和启动Node上的所有组件" class="headerlink" title="5. 配置和启动Node上的所有组件"></a>5. 配置和启动Node上的所有组件</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br></pre></td><td class="code"><pre><span class="line"># 创建配置目录和工作目录</span><br><span class="line">mkdir -p /etc/kubernetes/manifests</span><br><span class="line">mkdir -p /etc/kubernetes/pki/</span><br><span class="line">mkdir -p /var/lib/kubelet/</span><br><span class="line">mkdir -p /var/lib/kube-proxy/</span><br><span class="line"></span><br><span class="line"># 传输相关配置文件到当前节点上</span><br><span class="line">scp root@192.168.112.128:/etc/kubernetes/bootstrap-kubelet.conf /etc/kubernetes/</span><br><span class="line">scp root@192.168.112.128:/etc/kubernetes/pki/ca.crt /etc/kubernetes/pki/</span><br><span class="line"># scp root@192.168.112.128:/etc/kubernetes/kubelet.conf /etc/kubernetes/ # 使用了tls bootstrap的方式，故这步没有必要，需要注释掉</span><br><span class="line">scp root@192.168.112.128:/etc/kubernetes/proxy.conf /etc/kubernetes/</span><br><span class="line"></span><br><span class="line"># 创建kubelet的配置文件</span><br><span class="line">cat &lt;&lt;EOF &gt; /var/lib/kubelet/config.yaml</span><br><span class="line">apiVersion: kubelet.config.k8s.io/v1beta1</span><br><span class="line">authentication:</span><br><span class="line">  anonymous:</span><br><span class="line">    enabled: true</span><br><span class="line">  webhook:</span><br><span class="line">    cacheTTL: 0s</span><br><span class="line">    enabled: true</span><br><span class="line">  x509:</span><br><span class="line">    clientCAFile: /etc/kubernetes/pki/ca.crt</span><br><span class="line">authorization:</span><br><span class="line">  mode: Webhook</span><br><span class="line">  webhook:</span><br><span class="line">    cacheAuthorizedTTL: 0s</span><br><span class="line">    cacheUnauthorizedTTL: 0s</span><br><span class="line">clusterDNS:</span><br><span class="line">- 10.96.0.10</span><br><span class="line">clusterDomain: cluster.local</span><br><span class="line">cpuManagerReconcilePeriod: 0s</span><br><span class="line">evictionPressureTransitionPeriod: 0s</span><br><span class="line">fileCheckFrequency: 0s</span><br><span class="line">healthzBindAddress: 127.0.0.1</span><br><span class="line">healthzPort: 10248</span><br><span class="line">httpCheckFrequency: 0s</span><br><span class="line">imageMinimumGCAge: 0s</span><br><span class="line">kind: KubeletConfiguration</span><br><span class="line">nodeStatusReportFrequency: 0s</span><br><span class="line">nodeStatusUpdateFrequency: 0s</span><br><span class="line">rotateCertificates: true</span><br><span class="line">runtimeRequestTimeout: 0s</span><br><span class="line">staticPodPath: /etc/kubernetes/manifests</span><br><span class="line">streamingConnectionIdleTimeout: 0s</span><br><span class="line">syncFrequency: 0s</span><br><span class="line">volumeStatsAggPeriod: 0s</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"># 配置和启动kubelet服务</span><br><span class="line">cat &lt;&lt;EOF &gt; /usr/lib/systemd/system/kubelet.service</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Kubelet Server</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=docker.service</span><br><span class="line">Requires=docker.service</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">WorkingDirectory=/var/lib/kubelet</span><br><span class="line">EnvironmentFile=-/etc/kubernetes/kubelet.env</span><br><span class="line">ExecStart=/usr/bin/kubelet \$KUBELET_ARGS</span><br><span class="line">Restart=on-failure</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt; /etc/kubernetes/kubelet.env</span><br><span class="line">KUBELET_ARGS=&quot;--bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubernetes/kubelet.conf --config=/var/lib/kubelet/config.yaml --cgroup-driver=systemd --network-plugin=cni --pod-infra-container-image=registry.cn-hangzhou.aliyuncs.com/google_containers/pause-amd64:3.1&quot;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable kubelet.service</span><br><span class="line">systemctl start kubelet.service</span><br><span class="line">systemctl status kubelet.service</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 创建kube-proxy的配置文件</span><br><span class="line">cat &lt;&lt;EOF &gt; /var/lib/kube-proxy/config.conf</span><br><span class="line">apiVersion: kubeproxy.config.k8s.io/v1alpha1</span><br><span class="line">bindAddress: 0.0.0.0</span><br><span class="line">clientConnection:</span><br><span class="line">  acceptContentTypes: &quot;&quot;</span><br><span class="line">  burst: 0</span><br><span class="line">  contentType: &quot;&quot;</span><br><span class="line">  kubeconfig: /etc/kubernetes/proxy.conf</span><br><span class="line">  qps: 0</span><br><span class="line">clusterCIDR: 10.211.0.0/16</span><br><span class="line">configSyncPeriod: 0s</span><br><span class="line">conntrack:</span><br><span class="line">  maxPerCore: null</span><br><span class="line">  min: null</span><br><span class="line">  tcpCloseWaitTimeout: null</span><br><span class="line">  tcpEstablishedTimeout: null</span><br><span class="line">enableProfiling: false</span><br><span class="line">healthzBindAddress: &quot;&quot;</span><br><span class="line">hostnameOverride: &quot;&quot;</span><br><span class="line">iptables:</span><br><span class="line">  masqueradeAll: false</span><br><span class="line">  masqueradeBit: null</span><br><span class="line">  minSyncPeriod: 0s</span><br><span class="line">  syncPeriod: 0s</span><br><span class="line">ipvs:</span><br><span class="line">  excludeCIDRs: null</span><br><span class="line">  minSyncPeriod: 0s</span><br><span class="line">  scheduler: &quot;&quot;</span><br><span class="line">  strictARP: false</span><br><span class="line">  syncPeriod: 0s</span><br><span class="line">kind: KubeProxyConfiguration</span><br><span class="line">metricsBindAddress: &quot;&quot;</span><br><span class="line">mode: &quot;&quot;</span><br><span class="line">nodePortAddresses: null</span><br><span class="line">oomScoreAdj: null</span><br><span class="line">portRange: &quot;&quot;</span><br><span class="line">udpIdleTimeout: 0s</span><br><span class="line">winkernel:</span><br><span class="line">  enableDSR: false</span><br><span class="line">  networkName: &quot;&quot;</span><br><span class="line">  sourceVip: &quot;&quot;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"># 配置和启动kube-proxy服务</span><br><span class="line">cat &lt;&lt;EOF &gt; /usr/lib/systemd/system/kube-proxy.service</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Proxy Server</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=network.target</span><br><span class="line">Requires=network.service</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">EnvironmentFile=-/etc/kubernetes/kube-proxy.env</span><br><span class="line">ExecStart=/usr/bin/kube-proxy \$KUBE_PROXY_ARGS</span><br><span class="line">Restart=on-failure</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt; /etc/kubernetes/kube-proxy.env</span><br><span class="line">KUBE_PROXY_ARGS=&quot;--config=/var/lib/kube-proxy/config.conf --hostname-override=node01&quot;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">yum install -y conntrack</span><br><span class="line"></span><br><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable kube-proxy.service</span><br><span class="line">systemctl start kube-proxy.service</span><br><span class="line">systemctl status kube-proxy.service</span><br></pre></td></tr></table></figure>
<h2 id="6-配置和安装网络插件"><a href="#6-配置和安装网络插件" class="headerlink" title="6. 配置和安装网络插件"></a>6. 配置和安装网络插件</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br><span class="line">448</span><br><span class="line">449</span><br><span class="line">450</span><br><span class="line">451</span><br><span class="line">452</span><br><span class="line">453</span><br><span class="line">454</span><br><span class="line">455</span><br><span class="line">456</span><br><span class="line">457</span><br><span class="line">458</span><br><span class="line">459</span><br><span class="line">460</span><br><span class="line">461</span><br><span class="line">462</span><br><span class="line">463</span><br><span class="line">464</span><br><span class="line">465</span><br><span class="line">466</span><br><span class="line">467</span><br><span class="line">468</span><br><span class="line">469</span><br><span class="line">470</span><br><span class="line">471</span><br><span class="line">472</span><br><span class="line">473</span><br><span class="line">474</span><br><span class="line">475</span><br><span class="line">476</span><br><span class="line">477</span><br><span class="line">478</span><br><span class="line">479</span><br><span class="line">480</span><br><span class="line">481</span><br><span class="line">482</span><br><span class="line">483</span><br><span class="line">484</span><br><span class="line">485</span><br><span class="line">486</span><br><span class="line">487</span><br><span class="line">488</span><br><span class="line">489</span><br><span class="line">490</span><br><span class="line">491</span><br><span class="line">492</span><br><span class="line">493</span><br><span class="line">494</span><br><span class="line">495</span><br><span class="line">496</span><br><span class="line">497</span><br><span class="line">498</span><br><span class="line">499</span><br><span class="line">500</span><br><span class="line">501</span><br><span class="line">502</span><br><span class="line">503</span><br><span class="line">504</span><br><span class="line">505</span><br><span class="line">506</span><br><span class="line">507</span><br><span class="line">508</span><br><span class="line">509</span><br><span class="line">510</span><br><span class="line">511</span><br><span class="line">512</span><br><span class="line">513</span><br><span class="line">514</span><br><span class="line">515</span><br><span class="line">516</span><br><span class="line">517</span><br><span class="line">518</span><br><span class="line">519</span><br><span class="line">520</span><br><span class="line">521</span><br><span class="line">522</span><br><span class="line">523</span><br><span class="line">524</span><br><span class="line">525</span><br><span class="line">526</span><br><span class="line">527</span><br><span class="line">528</span><br><span class="line">529</span><br><span class="line">530</span><br><span class="line">531</span><br><span class="line">532</span><br><span class="line">533</span><br><span class="line">534</span><br><span class="line">535</span><br><span class="line">536</span><br><span class="line">537</span><br><span class="line">538</span><br><span class="line">539</span><br><span class="line">540</span><br><span class="line">541</span><br><span class="line">542</span><br><span class="line">543</span><br><span class="line">544</span><br><span class="line">545</span><br><span class="line">546</span><br><span class="line">547</span><br><span class="line">548</span><br><span class="line">549</span><br><span class="line">550</span><br><span class="line">551</span><br><span class="line">552</span><br><span class="line">553</span><br><span class="line">554</span><br><span class="line">555</span><br><span class="line">556</span><br><span class="line">557</span><br><span class="line">558</span><br><span class="line">559</span><br><span class="line">560</span><br><span class="line">561</span><br><span class="line">562</span><br><span class="line">563</span><br><span class="line">564</span><br><span class="line">565</span><br><span class="line">566</span><br><span class="line">567</span><br><span class="line">568</span><br><span class="line">569</span><br><span class="line">570</span><br><span class="line">571</span><br><span class="line">572</span><br><span class="line">573</span><br><span class="line">574</span><br><span class="line">575</span><br><span class="line">576</span><br><span class="line">577</span><br><span class="line">578</span><br><span class="line">579</span><br><span class="line">580</span><br><span class="line">581</span><br><span class="line">582</span><br><span class="line">583</span><br><span class="line">584</span><br><span class="line">585</span><br><span class="line">586</span><br><span class="line">587</span><br><span class="line">588</span><br><span class="line">589</span><br><span class="line">590</span><br><span class="line">591</span><br><span class="line">592</span><br><span class="line">593</span><br><span class="line">594</span><br><span class="line">595</span><br><span class="line">596</span><br><span class="line">597</span><br><span class="line">598</span><br><span class="line">599</span><br><span class="line">600</span><br><span class="line">601</span><br><span class="line">602</span><br><span class="line">603</span><br><span class="line">604</span><br><span class="line">605</span><br><span class="line">606</span><br><span class="line">607</span><br><span class="line">608</span><br><span class="line">609</span><br><span class="line">610</span><br><span class="line">611</span><br><span class="line">612</span><br><span class="line">613</span><br><span class="line">614</span><br><span class="line">615</span><br><span class="line">616</span><br><span class="line">617</span><br><span class="line">618</span><br><span class="line">619</span><br><span class="line">620</span><br><span class="line">621</span><br><span class="line">622</span><br><span class="line">623</span><br><span class="line">624</span><br><span class="line">625</span><br><span class="line">626</span><br><span class="line">627</span><br><span class="line">628</span><br><span class="line">629</span><br><span class="line">630</span><br><span class="line">631</span><br><span class="line">632</span><br><span class="line">633</span><br><span class="line">634</span><br><span class="line">635</span><br><span class="line">636</span><br><span class="line">637</span><br><span class="line">638</span><br><span class="line">639</span><br><span class="line">640</span><br><span class="line">641</span><br><span class="line">642</span><br><span class="line">643</span><br><span class="line">644</span><br><span class="line">645</span><br><span class="line">646</span><br><span class="line">647</span><br><span class="line">648</span><br><span class="line">649</span><br><span class="line">650</span><br><span class="line">651</span><br><span class="line">652</span><br><span class="line">653</span><br><span class="line">654</span><br><span class="line">655</span><br><span class="line">656</span><br><span class="line">657</span><br><span class="line">658</span><br><span class="line">659</span><br><span class="line">660</span><br><span class="line">661</span><br><span class="line">662</span><br><span class="line">663</span><br><span class="line">664</span><br><span class="line">665</span><br><span class="line">666</span><br><span class="line">667</span><br><span class="line">668</span><br><span class="line">669</span><br><span class="line">670</span><br><span class="line">671</span><br><span class="line">672</span><br><span class="line">673</span><br><span class="line">674</span><br><span class="line">675</span><br><span class="line">676</span><br><span class="line">677</span><br><span class="line">678</span><br><span class="line">679</span><br><span class="line">680</span><br><span class="line">681</span><br><span class="line">682</span><br><span class="line">683</span><br><span class="line">684</span><br><span class="line">685</span><br><span class="line">686</span><br><span class="line">687</span><br><span class="line">688</span><br><span class="line">689</span><br><span class="line">690</span><br><span class="line">691</span><br><span class="line">692</span><br><span class="line">693</span><br><span class="line">694</span><br><span class="line">695</span><br><span class="line">696</span><br><span class="line">697</span><br><span class="line">698</span><br><span class="line">699</span><br><span class="line">700</span><br><span class="line">701</span><br><span class="line">702</span><br><span class="line">703</span><br><span class="line">704</span><br><span class="line">705</span><br><span class="line">706</span><br><span class="line">707</span><br><span class="line">708</span><br><span class="line">709</span><br><span class="line">710</span><br><span class="line">711</span><br><span class="line">712</span><br><span class="line">713</span><br><span class="line">714</span><br><span class="line">715</span><br><span class="line">716</span><br><span class="line">717</span><br><span class="line">718</span><br><span class="line">719</span><br><span class="line">720</span><br><span class="line">721</span><br><span class="line">722</span><br><span class="line">723</span><br><span class="line">724</span><br><span class="line">725</span><br><span class="line">726</span><br><span class="line">727</span><br><span class="line">728</span><br><span class="line">729</span><br><span class="line">730</span><br><span class="line">731</span><br><span class="line">732</span><br><span class="line">733</span><br><span class="line">734</span><br><span class="line">735</span><br><span class="line">736</span><br><span class="line">737</span><br><span class="line">738</span><br><span class="line">739</span><br><span class="line">740</span><br><span class="line">741</span><br><span class="line">742</span><br><span class="line">743</span><br><span class="line">744</span><br><span class="line">745</span><br><span class="line">746</span><br><span class="line">747</span><br><span class="line">748</span><br><span class="line">749</span><br><span class="line">750</span><br><span class="line">751</span><br><span class="line">752</span><br><span class="line">753</span><br><span class="line">754</span><br><span class="line">755</span><br><span class="line">756</span><br><span class="line">757</span><br><span class="line">758</span><br><span class="line">759</span><br><span class="line">760</span><br><span class="line">761</span><br><span class="line">762</span><br><span class="line">763</span><br><span class="line">764</span><br><span class="line">765</span><br><span class="line">766</span><br><span class="line">767</span><br><span class="line">768</span><br><span class="line">769</span><br><span class="line">770</span><br><span class="line">771</span><br><span class="line">772</span><br><span class="line">773</span><br><span class="line">774</span><br><span class="line">775</span><br><span class="line">776</span><br><span class="line">777</span><br><span class="line">778</span><br><span class="line">779</span><br><span class="line">780</span><br><span class="line">781</span><br><span class="line">782</span><br><span class="line">783</span><br><span class="line">784</span><br><span class="line">785</span><br><span class="line">786</span><br><span class="line">787</span><br><span class="line">788</span><br><span class="line">789</span><br><span class="line">790</span><br><span class="line">791</span><br><span class="line">792</span><br><span class="line">793</span><br><span class="line">794</span><br><span class="line">795</span><br><span class="line">796</span><br><span class="line">797</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p calico/</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt; calico/calico.yaml</span><br><span class="line">---</span><br><span class="line"># Source: calico/templates/calico-config.yaml</span><br><span class="line"># This ConfigMap is used to configure a self-hosted Calico installation.</span><br><span class="line">kind: ConfigMap</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  name: calico-config</span><br><span class="line">  namespace: kube-system</span><br><span class="line">data:</span><br><span class="line">  # Typha is disabled.</span><br><span class="line">  typha_service_name: &quot;none&quot;</span><br><span class="line">  # Configure the backend to use.</span><br><span class="line">  calico_backend: &quot;bird&quot;</span><br><span class="line"></span><br><span class="line">  # Configure the MTU to use</span><br><span class="line">  veth_mtu: &quot;1440&quot;</span><br><span class="line"></span><br><span class="line">  # The CNI network configuration to install on each node.  The special</span><br><span class="line">  # values in this config will be automatically populated.</span><br><span class="line">  cni_network_config: |-</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;name&quot;: &quot;k8s-pod-network&quot;,</span><br><span class="line">      &quot;cniVersion&quot;: &quot;0.3.1&quot;,</span><br><span class="line">      &quot;plugins&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;type&quot;: &quot;calico&quot;,</span><br><span class="line">          &quot;log_level&quot;: &quot;info&quot;,</span><br><span class="line">          &quot;datastore_type&quot;: &quot;kubernetes&quot;,</span><br><span class="line">          &quot;nodename&quot;: &quot;__KUBERNETES_NODE_NAME__&quot;,</span><br><span class="line">          &quot;mtu&quot;: __CNI_MTU__,</span><br><span class="line">          &quot;ipam&quot;: &#123;</span><br><span class="line">              &quot;type&quot;: &quot;calico-ipam&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;policy&quot;: &#123;</span><br><span class="line">              &quot;type&quot;: &quot;k8s&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;kubernetes&quot;: &#123;</span><br><span class="line">              &quot;kubeconfig&quot;: &quot;__KUBECONFIG_FILEPATH__&quot;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;type&quot;: &quot;portmap&quot;,</span><br><span class="line">          &quot;snat&quot;: true,</span><br><span class="line">          &quot;capabilities&quot;: &#123;&quot;portMappings&quot;: true&#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"># Source: calico/templates/kdd-crds.yaml</span><br><span class="line">apiVersion: apiextensions.k8s.io/v1beta1</span><br><span class="line">kind: CustomResourceDefinition</span><br><span class="line">metadata:</span><br><span class="line">  name: felixconfigurations.crd.projectcalico.org</span><br><span class="line">spec:</span><br><span class="line">  scope: Cluster</span><br><span class="line">  group: crd.projectcalico.org</span><br><span class="line">  version: v1</span><br><span class="line">  names:</span><br><span class="line">    kind: FelixConfiguration</span><br><span class="line">    plural: felixconfigurations</span><br><span class="line">    singular: felixconfiguration</span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">apiVersion: apiextensions.k8s.io/v1beta1</span><br><span class="line">kind: CustomResourceDefinition</span><br><span class="line">metadata:</span><br><span class="line">  name: ipamblocks.crd.projectcalico.org</span><br><span class="line">spec:</span><br><span class="line">  scope: Cluster</span><br><span class="line">  group: crd.projectcalico.org</span><br><span class="line">  version: v1</span><br><span class="line">  names:</span><br><span class="line">    kind: IPAMBlock</span><br><span class="line">    plural: ipamblocks</span><br><span class="line">    singular: ipamblock</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">apiVersion: apiextensions.k8s.io/v1beta1</span><br><span class="line">kind: CustomResourceDefinition</span><br><span class="line">metadata:</span><br><span class="line">  name: blockaffinities.crd.projectcalico.org</span><br><span class="line">spec:</span><br><span class="line">  scope: Cluster</span><br><span class="line">  group: crd.projectcalico.org</span><br><span class="line">  version: v1</span><br><span class="line">  names:</span><br><span class="line">    kind: BlockAffinity</span><br><span class="line">    plural: blockaffinities</span><br><span class="line">    singular: blockaffinity</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">apiVersion: apiextensions.k8s.io/v1beta1</span><br><span class="line">kind: CustomResourceDefinition</span><br><span class="line">metadata:</span><br><span class="line">  name: ipamhandles.crd.projectcalico.org</span><br><span class="line">spec:</span><br><span class="line">  scope: Cluster</span><br><span class="line">  group: crd.projectcalico.org</span><br><span class="line">  version: v1</span><br><span class="line">  names:</span><br><span class="line">    kind: IPAMHandle</span><br><span class="line">    plural: ipamhandles</span><br><span class="line">    singular: ipamhandle</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">apiVersion: apiextensions.k8s.io/v1beta1</span><br><span class="line">kind: CustomResourceDefinition</span><br><span class="line">metadata:</span><br><span class="line">  name: ipamconfigs.crd.projectcalico.org</span><br><span class="line">spec:</span><br><span class="line">  scope: Cluster</span><br><span class="line">  group: crd.projectcalico.org</span><br><span class="line">  version: v1</span><br><span class="line">  names:</span><br><span class="line">    kind: IPAMConfig</span><br><span class="line">    plural: ipamconfigs</span><br><span class="line">    singular: ipamconfig</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">apiVersion: apiextensions.k8s.io/v1beta1</span><br><span class="line">kind: CustomResourceDefinition</span><br><span class="line">metadata:</span><br><span class="line">  name: bgppeers.crd.projectcalico.org</span><br><span class="line">spec:</span><br><span class="line">  scope: Cluster</span><br><span class="line">  group: crd.projectcalico.org</span><br><span class="line">  version: v1</span><br><span class="line">  names:</span><br><span class="line">    kind: BGPPeer</span><br><span class="line">    plural: bgppeers</span><br><span class="line">    singular: bgppeer</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">apiVersion: apiextensions.k8s.io/v1beta1</span><br><span class="line">kind: CustomResourceDefinition</span><br><span class="line">metadata:</span><br><span class="line">  name: bgpconfigurations.crd.projectcalico.org</span><br><span class="line">spec:</span><br><span class="line">  scope: Cluster</span><br><span class="line">  group: crd.projectcalico.org</span><br><span class="line">  version: v1</span><br><span class="line">  names:</span><br><span class="line">    kind: BGPConfiguration</span><br><span class="line">    plural: bgpconfigurations</span><br><span class="line">    singular: bgpconfiguration</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">apiVersion: apiextensions.k8s.io/v1beta1</span><br><span class="line">kind: CustomResourceDefinition</span><br><span class="line">metadata:</span><br><span class="line">  name: ippools.crd.projectcalico.org</span><br><span class="line">spec:</span><br><span class="line">  scope: Cluster</span><br><span class="line">  group: crd.projectcalico.org</span><br><span class="line">  version: v1</span><br><span class="line">  names:</span><br><span class="line">    kind: IPPool</span><br><span class="line">    plural: ippools</span><br><span class="line">    singular: ippool</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">apiVersion: apiextensions.k8s.io/v1beta1</span><br><span class="line">kind: CustomResourceDefinition</span><br><span class="line">metadata:</span><br><span class="line">  name: hostendpoints.crd.projectcalico.org</span><br><span class="line">spec:</span><br><span class="line">  scope: Cluster</span><br><span class="line">  group: crd.projectcalico.org</span><br><span class="line">  version: v1</span><br><span class="line">  names:</span><br><span class="line">    kind: HostEndpoint</span><br><span class="line">    plural: hostendpoints</span><br><span class="line">    singular: hostendpoint</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">apiVersion: apiextensions.k8s.io/v1beta1</span><br><span class="line">kind: CustomResourceDefinition</span><br><span class="line">metadata:</span><br><span class="line">  name: clusterinformations.crd.projectcalico.org</span><br><span class="line">spec:</span><br><span class="line">  scope: Cluster</span><br><span class="line">  group: crd.projectcalico.org</span><br><span class="line">  version: v1</span><br><span class="line">  names:</span><br><span class="line">    kind: ClusterInformation</span><br><span class="line">    plural: clusterinformations</span><br><span class="line">    singular: clusterinformation</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">apiVersion: apiextensions.k8s.io/v1beta1</span><br><span class="line">kind: CustomResourceDefinition</span><br><span class="line">metadata:</span><br><span class="line">  name: globalnetworkpolicies.crd.projectcalico.org</span><br><span class="line">spec:</span><br><span class="line">  scope: Cluster</span><br><span class="line">  group: crd.projectcalico.org</span><br><span class="line">  version: v1</span><br><span class="line">  names:</span><br><span class="line">    kind: GlobalNetworkPolicy</span><br><span class="line">    plural: globalnetworkpolicies</span><br><span class="line">    singular: globalnetworkpolicy</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">apiVersion: apiextensions.k8s.io/v1beta1</span><br><span class="line">kind: CustomResourceDefinition</span><br><span class="line">metadata:</span><br><span class="line">  name: globalnetworksets.crd.projectcalico.org</span><br><span class="line">spec:</span><br><span class="line">  scope: Cluster</span><br><span class="line">  group: crd.projectcalico.org</span><br><span class="line">  version: v1</span><br><span class="line">  names:</span><br><span class="line">    kind: GlobalNetworkSet</span><br><span class="line">    plural: globalnetworksets</span><br><span class="line">    singular: globalnetworkset</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">apiVersion: apiextensions.k8s.io/v1beta1</span><br><span class="line">kind: CustomResourceDefinition</span><br><span class="line">metadata:</span><br><span class="line">  name: networkpolicies.crd.projectcalico.org</span><br><span class="line">spec:</span><br><span class="line">  scope: Namespaced</span><br><span class="line">  group: crd.projectcalico.org</span><br><span class="line">  version: v1</span><br><span class="line">  names:</span><br><span class="line">    kind: NetworkPolicy</span><br><span class="line">    plural: networkpolicies</span><br><span class="line">    singular: networkpolicy</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">apiVersion: apiextensions.k8s.io/v1beta1</span><br><span class="line">kind: CustomResourceDefinition</span><br><span class="line">metadata:</span><br><span class="line">  name: networksets.crd.projectcalico.org</span><br><span class="line">spec:</span><br><span class="line">  scope: Namespaced</span><br><span class="line">  group: crd.projectcalico.org</span><br><span class="line">  version: v1</span><br><span class="line">  names:</span><br><span class="line">    kind: NetworkSet</span><br><span class="line">    plural: networksets</span><br><span class="line">    singular: networkset</span><br><span class="line">---</span><br><span class="line"># Source: calico/templates/rbac.yaml</span><br><span class="line"></span><br><span class="line"># Include a clusterrole for the kube-controllers component,</span><br><span class="line"># and bind it to the calico-kube-controllers serviceaccount.</span><br><span class="line">kind: ClusterRole</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: calico-kube-controllers</span><br><span class="line">rules:</span><br><span class="line">  # Nodes are watched to monitor for deletions.</span><br><span class="line">  - apiGroups: [&quot;&quot;]</span><br><span class="line">    resources:</span><br><span class="line">      - nodes</span><br><span class="line">    verbs:</span><br><span class="line">      - watch</span><br><span class="line">      - list</span><br><span class="line">      - get</span><br><span class="line">  # Pods are queried to check for existence.</span><br><span class="line">  - apiGroups: [&quot;&quot;]</span><br><span class="line">    resources:</span><br><span class="line">      - pods</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">  # IPAM resources are manipulated when nodes are deleted.</span><br><span class="line">  - apiGroups: [&quot;crd.projectcalico.org&quot;]</span><br><span class="line">    resources:</span><br><span class="line">      - ippools</span><br><span class="line">    verbs:</span><br><span class="line">      - list</span><br><span class="line">  - apiGroups: [&quot;crd.projectcalico.org&quot;]</span><br><span class="line">    resources:</span><br><span class="line">      - blockaffinities</span><br><span class="line">      - ipamblocks</span><br><span class="line">      - ipamhandles</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">      - list</span><br><span class="line">      - create</span><br><span class="line">      - update</span><br><span class="line">      - delete</span><br><span class="line">  # Needs access to update clusterinformations.</span><br><span class="line">  - apiGroups: [&quot;crd.projectcalico.org&quot;]</span><br><span class="line">    resources:</span><br><span class="line">      - clusterinformations</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">      - create</span><br><span class="line">      - update</span><br><span class="line">---</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: calico-kube-controllers</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: calico-kube-controllers</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: calico-kube-controllers</span><br><span class="line">  namespace: kube-system</span><br><span class="line">---</span><br><span class="line"># Include a clusterrole for the calico-node DaemonSet,</span><br><span class="line"># and bind it to the calico-node serviceaccount.</span><br><span class="line">kind: ClusterRole</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: calico-node</span><br><span class="line">rules:</span><br><span class="line">  # The CNI plugin needs to get pods, nodes, and namespaces.</span><br><span class="line">  - apiGroups: [&quot;&quot;]</span><br><span class="line">    resources:</span><br><span class="line">      - pods</span><br><span class="line">      - nodes</span><br><span class="line">      - namespaces</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">  - apiGroups: [&quot;&quot;]</span><br><span class="line">    resources:</span><br><span class="line">      - endpoints</span><br><span class="line">      - services</span><br><span class="line">    verbs:</span><br><span class="line">      # Used to discover service IPs for advertisement.</span><br><span class="line">      - watch</span><br><span class="line">      - list</span><br><span class="line">      # Used to discover Typhas.</span><br><span class="line">      - get</span><br><span class="line">  - apiGroups: [&quot;&quot;]</span><br><span class="line">    resources:</span><br><span class="line">      - nodes/status</span><br><span class="line">    verbs:</span><br><span class="line">      # Needed for clearing NodeNetworkUnavailable flag.</span><br><span class="line">      - patch</span><br><span class="line">      # Calico stores some configuration information in node annotations.</span><br><span class="line">      - update</span><br><span class="line">  # Watch for changes to Kubernetes NetworkPolicies.</span><br><span class="line">  - apiGroups: [&quot;networking.k8s.io&quot;]</span><br><span class="line">    resources:</span><br><span class="line">      - networkpolicies</span><br><span class="line">    verbs:</span><br><span class="line">      - watch</span><br><span class="line">      - list</span><br><span class="line">  # Used by Calico for policy information.</span><br><span class="line">  - apiGroups: [&quot;&quot;]</span><br><span class="line">    resources:</span><br><span class="line">      - pods</span><br><span class="line">      - namespaces</span><br><span class="line">      - serviceaccounts</span><br><span class="line">    verbs:</span><br><span class="line">      - list</span><br><span class="line">      - watch</span><br><span class="line">  # The CNI plugin patches pods/status.</span><br><span class="line">  - apiGroups: [&quot;&quot;]</span><br><span class="line">    resources:</span><br><span class="line">      - pods/status</span><br><span class="line">    verbs:</span><br><span class="line">      - patch</span><br><span class="line">  # Calico monitors various CRDs for config.</span><br><span class="line">  - apiGroups: [&quot;crd.projectcalico.org&quot;]</span><br><span class="line">    resources:</span><br><span class="line">      - globalfelixconfigs</span><br><span class="line">      - felixconfigurations</span><br><span class="line">      - bgppeers</span><br><span class="line">      - globalbgpconfigs</span><br><span class="line">      - bgpconfigurations</span><br><span class="line">      - ippools</span><br><span class="line">      - ipamblocks</span><br><span class="line">      - globalnetworkpolicies</span><br><span class="line">      - globalnetworksets</span><br><span class="line">      - networkpolicies</span><br><span class="line">      - networksets</span><br><span class="line">      - clusterinformations</span><br><span class="line">      - hostendpoints</span><br><span class="line">      - blockaffinities</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">      - list</span><br><span class="line">      - watch</span><br><span class="line">  # Calico must create and update some CRDs on startup.</span><br><span class="line">  - apiGroups: [&quot;crd.projectcalico.org&quot;]</span><br><span class="line">    resources:</span><br><span class="line">      - ippools</span><br><span class="line">      - felixconfigurations</span><br><span class="line">      - clusterinformations</span><br><span class="line">    verbs:</span><br><span class="line">      - create</span><br><span class="line">      - update</span><br><span class="line">  # Calico stores some configuration information on the node.</span><br><span class="line">  - apiGroups: [&quot;&quot;]</span><br><span class="line">    resources:</span><br><span class="line">      - nodes</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">      - list</span><br><span class="line">      - watch</span><br><span class="line">  # These permissions are only requried for upgrade from v2.6, and can</span><br><span class="line">  # be removed after upgrade or on fresh installations.</span><br><span class="line">  - apiGroups: [&quot;crd.projectcalico.org&quot;]</span><br><span class="line">    resources:</span><br><span class="line">      - bgpconfigurations</span><br><span class="line">      - bgppeers</span><br><span class="line">    verbs:</span><br><span class="line">      - create</span><br><span class="line">      - update</span><br><span class="line">  # These permissions are required for Calico CNI to perform IPAM allocations.</span><br><span class="line">  - apiGroups: [&quot;crd.projectcalico.org&quot;]</span><br><span class="line">    resources:</span><br><span class="line">      - blockaffinities</span><br><span class="line">      - ipamblocks</span><br><span class="line">      - ipamhandles</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">      - list</span><br><span class="line">      - create</span><br><span class="line">      - update</span><br><span class="line">      - delete</span><br><span class="line">  - apiGroups: [&quot;crd.projectcalico.org&quot;]</span><br><span class="line">    resources:</span><br><span class="line">      - ipamconfigs</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">  # Block affinities must also be watchable by confd for route aggregation.</span><br><span class="line">  - apiGroups: [&quot;crd.projectcalico.org&quot;]</span><br><span class="line">    resources:</span><br><span class="line">      - blockaffinities</span><br><span class="line">    verbs:</span><br><span class="line">      - watch</span><br><span class="line">  # The Calico IPAM migration needs to get daemonsets. These permissions can be</span><br><span class="line">  # removed if not upgrading from an installation using host-local IPAM.</span><br><span class="line">  - apiGroups: [&quot;apps&quot;]</span><br><span class="line">    resources:</span><br><span class="line">      - daemonsets</span><br><span class="line">    verbs:</span><br><span class="line">      - get</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: calico-node</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: calico-node</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: calico-node</span><br><span class="line">  namespace: kube-system</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"># Source: calico/templates/calico-node.yaml</span><br><span class="line"># This manifest installs the calico-node container, as well</span><br><span class="line"># as the CNI plugins and network config on</span><br><span class="line"># each master and worker node in a Kubernetes cluster.</span><br><span class="line">kind: DaemonSet</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: calico-node</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: calico-node</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      k8s-app: calico-node</span><br><span class="line">  updateStrategy:</span><br><span class="line">    type: RollingUpdate</span><br><span class="line">    rollingUpdate:</span><br><span class="line">      maxUnavailable: 1</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        k8s-app: calico-node</span><br><span class="line">      annotations:</span><br><span class="line">        # This, along with the CriticalAddonsOnly toleration below,</span><br><span class="line">        # marks the pod as a critical add-on, ensuring it gets</span><br><span class="line">        # priority scheduling and that its resources are reserved</span><br><span class="line">        # if it ever gets evicted.</span><br><span class="line">        scheduler.alpha.kubernetes.io/critical-pod: &apos;&apos;</span><br><span class="line">    spec:</span><br><span class="line">      nodeSelector:</span><br><span class="line">        beta.kubernetes.io/os: linux</span><br><span class="line">      hostNetwork: true</span><br><span class="line">      tolerations:</span><br><span class="line">        # Make sure calico-node gets scheduled on all nodes.</span><br><span class="line">        - effect: NoSchedule</span><br><span class="line">          operator: Exists</span><br><span class="line">        # Mark the pod as a critical add-on for rescheduling.</span><br><span class="line">        - key: CriticalAddonsOnly</span><br><span class="line">          operator: Exists</span><br><span class="line">        - effect: NoExecute</span><br><span class="line">          operator: Exists</span><br><span class="line">      serviceAccountName: calico-node</span><br><span class="line">      # Minimize downtime during a rolling upgrade or deletion; tell Kubernetes to do a &quot;force</span><br><span class="line">      # deletion&quot;: https://kubernetes.io/docs/concepts/workloads/pods/pod/#termination-of-pods.</span><br><span class="line">      terminationGracePeriodSeconds: 0</span><br><span class="line">      priorityClassName: system-node-critical</span><br><span class="line">      initContainers:</span><br><span class="line">        # This container performs upgrade from host-local IPAM to calico-ipam.</span><br><span class="line">        # It can be deleted if this is a fresh installation, or if you have already</span><br><span class="line">        # upgraded to use calico-ipam.</span><br><span class="line">        - name: upgrade-ipam</span><br><span class="line">          image: calico/cni:v3.11.1</span><br><span class="line">          command: [&quot;/opt/cni/bin/calico-ipam&quot;, &quot;-upgrade&quot;]</span><br><span class="line">          env:</span><br><span class="line">            - name: KUBERNETES_NODE_NAME</span><br><span class="line">              valueFrom:</span><br><span class="line">                fieldRef:</span><br><span class="line">                  fieldPath: spec.nodeName</span><br><span class="line">            - name: CALICO_NETWORKING_BACKEND</span><br><span class="line">              valueFrom:</span><br><span class="line">                configMapKeyRef:</span><br><span class="line">                  name: calico-config</span><br><span class="line">                  key: calico_backend</span><br><span class="line">          volumeMounts:</span><br><span class="line">            - mountPath: /var/lib/cni/networks</span><br><span class="line">              name: host-local-net-dir</span><br><span class="line">            - mountPath: /host/opt/cni/bin</span><br><span class="line">              name: cni-bin-dir</span><br><span class="line">          securityContext:</span><br><span class="line">            privileged: true</span><br><span class="line">        # This container installs the CNI binaries</span><br><span class="line">        # and CNI network config file on each node.</span><br><span class="line">        - name: install-cni</span><br><span class="line">          image: calico/cni:v3.11.1</span><br><span class="line">          command: [&quot;/install-cni.sh&quot;]</span><br><span class="line">          env:</span><br><span class="line">            # Name of the CNI config file to create.</span><br><span class="line">            - name: CNI_CONF_NAME</span><br><span class="line">              value: &quot;10-calico.conflist&quot;</span><br><span class="line">            # The CNI network config to install on each node.</span><br><span class="line">            - name: CNI_NETWORK_CONFIG</span><br><span class="line">              valueFrom:</span><br><span class="line">                configMapKeyRef:</span><br><span class="line">                  name: calico-config</span><br><span class="line">                  key: cni_network_config</span><br><span class="line">            # Set the hostname based on the k8s node name.</span><br><span class="line">            - name: KUBERNETES_NODE_NAME</span><br><span class="line">              valueFrom:</span><br><span class="line">                fieldRef:</span><br><span class="line">                  fieldPath: spec.nodeName</span><br><span class="line">            # CNI MTU Config variable</span><br><span class="line">            - name: CNI_MTU</span><br><span class="line">              valueFrom:</span><br><span class="line">                configMapKeyRef:</span><br><span class="line">                  name: calico-config</span><br><span class="line">                  key: veth_mtu</span><br><span class="line">            # Prevents the container from sleeping forever.</span><br><span class="line">            - name: SLEEP</span><br><span class="line">              value: &quot;false&quot;</span><br><span class="line">          volumeMounts:</span><br><span class="line">            - mountPath: /host/opt/cni/bin</span><br><span class="line">              name: cni-bin-dir</span><br><span class="line">            - mountPath: /host/etc/cni/net.d</span><br><span class="line">              name: cni-net-dir</span><br><span class="line">          securityContext:</span><br><span class="line">            privileged: true</span><br><span class="line">        # Adds a Flex Volume Driver that creates a per-pod Unix Domain Socket to allow Dikastes</span><br><span class="line">        # to communicate with Felix over the Policy Sync API.</span><br><span class="line">        - name: flexvol-driver</span><br><span class="line">          image: calico/pod2daemon-flexvol:v3.11.1</span><br><span class="line">          volumeMounts:</span><br><span class="line">          - name: flexvol-driver-host</span><br><span class="line">            mountPath: /host/driver</span><br><span class="line">          securityContext:</span><br><span class="line">            privileged: true</span><br><span class="line">      containers:</span><br><span class="line">        # Runs calico-node container on each Kubernetes node.  This</span><br><span class="line">        # container programs network policy and routes on each</span><br><span class="line">        # host.</span><br><span class="line">        - name: calico-node</span><br><span class="line">          image: calico/node:v3.11.1</span><br><span class="line">          env:</span><br><span class="line">            # Use Kubernetes API as the backing datastore.</span><br><span class="line">            - name: DATASTORE_TYPE</span><br><span class="line">              value: &quot;kubernetes&quot;</span><br><span class="line">            # Wait for the datastore.</span><br><span class="line">            - name: WAIT_FOR_DATASTORE</span><br><span class="line">              value: &quot;true&quot;</span><br><span class="line">            # Set based on the k8s node name.</span><br><span class="line">            - name: NODENAME</span><br><span class="line">              valueFrom:</span><br><span class="line">                fieldRef:</span><br><span class="line">                  fieldPath: spec.nodeName</span><br><span class="line">            # Choose the backend to use.</span><br><span class="line">            - name: CALICO_NETWORKING_BACKEND</span><br><span class="line">              valueFrom:</span><br><span class="line">                configMapKeyRef:</span><br><span class="line">                  name: calico-config</span><br><span class="line">                  key: calico_backend</span><br><span class="line">            # Cluster type to identify the deployment type</span><br><span class="line">            - name: CLUSTER_TYPE</span><br><span class="line">              value: &quot;k8s,bgp&quot;</span><br><span class="line">            # Auto-detect the BGP IP address.</span><br><span class="line">            - name: IP</span><br><span class="line">              value: &quot;autodetect&quot;</span><br><span class="line">            # Enable IPIP</span><br><span class="line">            - name: CALICO_IPV4POOL_IPIP</span><br><span class="line">              value: &quot;CrossSubnet&quot;</span><br><span class="line">            # Set MTU for tunnel device used if ipip is enabled</span><br><span class="line">            - name: FELIX_IPINIPMTU</span><br><span class="line">              valueFrom:</span><br><span class="line">                configMapKeyRef:</span><br><span class="line">                  name: calico-config</span><br><span class="line">                  key: veth_mtu</span><br><span class="line">            # The default IPv4 pool to create on startup if none exists. Pod IPs will be</span><br><span class="line">            # chosen from this range. Changing this value after installation will have</span><br><span class="line">            # no effect. This should fall within \`--cluster-cidr\`.</span><br><span class="line">            - name: CALICO_IPV4POOL_CIDR</span><br><span class="line">              value: &quot;10.211.0.0/16&quot;</span><br><span class="line">            # Disable file logging so \`kubectl logs\` works.</span><br><span class="line">            - name: CALICO_DISABLE_FILE_LOGGING</span><br><span class="line">              value: &quot;true&quot;</span><br><span class="line">            # Set Felix endpoint to host default action to ACCEPT.</span><br><span class="line">            - name: FELIX_DEFAULTENDPOINTTOHOSTACTION</span><br><span class="line">              value: &quot;ACCEPT&quot;</span><br><span class="line">            # Disable IPv6 on Kubernetes.</span><br><span class="line">            - name: FELIX_IPV6SUPPORT</span><br><span class="line">              value: &quot;false&quot;</span><br><span class="line">            # Set Felix logging to &quot;info&quot;</span><br><span class="line">            - name: FELIX_LOGSEVERITYSCREEN</span><br><span class="line">              value: &quot;info&quot;</span><br><span class="line">            - name: FELIX_HEALTHENABLED</span><br><span class="line">              value: &quot;true&quot;</span><br><span class="line">          securityContext:</span><br><span class="line">            privileged: true</span><br><span class="line">          resources:</span><br><span class="line">            requests:</span><br><span class="line">              cpu: 250m</span><br><span class="line">          livenessProbe:</span><br><span class="line">            exec:</span><br><span class="line">              command:</span><br><span class="line">              - /bin/calico-node</span><br><span class="line">              - -felix-live</span><br><span class="line">              - -bird-live</span><br><span class="line">            periodSeconds: 10</span><br><span class="line">            initialDelaySeconds: 10</span><br><span class="line">            failureThreshold: 6</span><br><span class="line">          readinessProbe:</span><br><span class="line">            exec:</span><br><span class="line">              command:</span><br><span class="line">              - /bin/calico-node</span><br><span class="line">              - -felix-ready</span><br><span class="line">              - -bird-ready</span><br><span class="line">            periodSeconds: 10</span><br><span class="line">          volumeMounts:</span><br><span class="line">            - mountPath: /lib/modules</span><br><span class="line">              name: lib-modules</span><br><span class="line">              readOnly: true</span><br><span class="line">            - mountPath: /run/xtables.lock</span><br><span class="line">              name: xtables-lock</span><br><span class="line">              readOnly: false</span><br><span class="line">            - mountPath: /var/run/calico</span><br><span class="line">              name: var-run-calico</span><br><span class="line">              readOnly: false</span><br><span class="line">            - mountPath: /var/lib/calico</span><br><span class="line">              name: var-lib-calico</span><br><span class="line">              readOnly: false</span><br><span class="line">            - name: policysync</span><br><span class="line">              mountPath: /var/run/nodeagent</span><br><span class="line">      volumes:</span><br><span class="line">        # Used by calico-node.</span><br><span class="line">        - name: lib-modules</span><br><span class="line">          hostPath:</span><br><span class="line">            path: /lib/modules</span><br><span class="line">        - name: var-run-calico</span><br><span class="line">          hostPath:</span><br><span class="line">            path: /var/run/calico</span><br><span class="line">        - name: var-lib-calico</span><br><span class="line">          hostPath:</span><br><span class="line">            path: /var/lib/calico</span><br><span class="line">        - name: xtables-lock</span><br><span class="line">          hostPath:</span><br><span class="line">            path: /run/xtables.lock</span><br><span class="line">            type: FileOrCreate</span><br><span class="line">        # Used to install CNI.</span><br><span class="line">        - name: cni-bin-dir</span><br><span class="line">          hostPath:</span><br><span class="line">            path: /opt/cni/bin</span><br><span class="line">        - name: cni-net-dir</span><br><span class="line">          hostPath:</span><br><span class="line">            path: /etc/cni/net.d</span><br><span class="line">        # Mount in the directory for host-local IPAM allocations. This is</span><br><span class="line">        # used when upgrading from host-local to calico-ipam, and can be removed</span><br><span class="line">        # if not using the upgrade-ipam init container.</span><br><span class="line">        - name: host-local-net-dir</span><br><span class="line">          hostPath:</span><br><span class="line">            path: /var/lib/cni/networks</span><br><span class="line">        # Used to create per-pod Unix Domain Sockets</span><br><span class="line">        - name: policysync</span><br><span class="line">          hostPath:</span><br><span class="line">            type: DirectoryOrCreate</span><br><span class="line">            path: /var/run/nodeagent</span><br><span class="line">        # Used to install Flex Volume Driver</span><br><span class="line">        - name: flexvol-driver-host</span><br><span class="line">          hostPath:</span><br><span class="line">            type: DirectoryOrCreate</span><br><span class="line">            path: /usr/libexec/kubernetes/kubelet-plugins/volume/exec/nodeagent~uds</span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: calico-node</span><br><span class="line">  namespace: kube-system</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"># Source: calico/templates/calico-kube-controllers.yaml</span><br><span class="line"></span><br><span class="line"># See https://github.com/projectcalico/kube-controllers</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: calico-kube-controllers</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: calico-kube-controllers</span><br><span class="line">spec:</span><br><span class="line">  # The controllers can only have a single active instance.</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      k8s-app: calico-kube-controllers</span><br><span class="line">  strategy:</span><br><span class="line">    type: Recreate</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      name: calico-kube-controllers</span><br><span class="line">      namespace: kube-system</span><br><span class="line">      labels:</span><br><span class="line">        k8s-app: calico-kube-controllers</span><br><span class="line">      annotations:</span><br><span class="line">        scheduler.alpha.kubernetes.io/critical-pod: &apos;&apos;</span><br><span class="line">    spec:</span><br><span class="line">      nodeSelector:</span><br><span class="line">        beta.kubernetes.io/os: linux</span><br><span class="line">      tolerations:</span><br><span class="line">        # Mark the pod as a critical add-on for rescheduling.</span><br><span class="line">        - key: CriticalAddonsOnly</span><br><span class="line">          operator: Exists</span><br><span class="line">        - key: node-role.kubernetes.io/master</span><br><span class="line">          effect: NoSchedule</span><br><span class="line">      serviceAccountName: calico-kube-controllers</span><br><span class="line">      priorityClassName: system-cluster-critical</span><br><span class="line">      containers:</span><br><span class="line">        - name: calico-kube-controllers</span><br><span class="line">          image: calico/kube-controllers:v3.11.1</span><br><span class="line">          env:</span><br><span class="line">            # Choose which controllers to run.</span><br><span class="line">            - name: ENABLED_CONTROLLERS</span><br><span class="line">              value: node</span><br><span class="line">            - name: DATASTORE_TYPE</span><br><span class="line">              value: kubernetes</span><br><span class="line">          readinessProbe:</span><br><span class="line">            exec:</span><br><span class="line">              command:</span><br><span class="line">              - /usr/bin/check-status</span><br><span class="line">              - -r</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: calico-kube-controllers</span><br><span class="line">  namespace: kube-system</span><br><span class="line">---</span><br><span class="line"># Source: calico/templates/calico-etcd-secrets.yaml</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"># Source: calico/templates/calico-typha.yaml</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"># Source: calico/templates/configure-canal.yaml</span><br><span class="line"></span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">kubectl create -f calico/</span><br></pre></td></tr></table></figure>
<h2 id="7-配置和安装DNS插件"><a href="#7-配置和安装DNS插件" class="headerlink" title="7. 配置和安装DNS插件"></a>7. 配置和安装DNS插件</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p kube-dns/</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt; kube-dns/configmap.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">data:</span><br><span class="line">  Corefile: |</span><br><span class="line">    .:53 &#123;</span><br><span class="line">        errors</span><br><span class="line">        health &#123;</span><br><span class="line">           lameduck 5s</span><br><span class="line">        &#125;</span><br><span class="line">        ready</span><br><span class="line">        kubernetes cluster.local in-addr.arpa ip6.arpa &#123;</span><br><span class="line">           pods insecure</span><br><span class="line">           fallthrough in-addr.arpa ip6.arpa</span><br><span class="line">           ttl 30</span><br><span class="line">        &#125;</span><br><span class="line">        prometheus :9153</span><br><span class="line">        forward . /etc/resolv.conf</span><br><span class="line">        cache 30</span><br><span class="line">        loop</span><br><span class="line">        reload</span><br><span class="line">        loadbalance</span><br><span class="line">    &#125;</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">  name: coredns</span><br><span class="line">  namespace: kube-system</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt; kube-dns/serviceaccount.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: coredns</span><br><span class="line">  namespace: kube-system</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt; kube-dns/clusterrole.yaml</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRole</span><br><span class="line">metadata:</span><br><span class="line">  name: system:coredns</span><br><span class="line">rules:</span><br><span class="line">- apiGroups:</span><br><span class="line">  - &quot;&quot;</span><br><span class="line">  resources:</span><br><span class="line">  - endpoints</span><br><span class="line">  - services</span><br><span class="line">  - pods</span><br><span class="line">  - namespaces</span><br><span class="line">  verbs:</span><br><span class="line">  - list</span><br><span class="line">  - watch</span><br><span class="line">- apiGroups:</span><br><span class="line">  - &quot;&quot;</span><br><span class="line">  resources:</span><br><span class="line">  - nodes</span><br><span class="line">  verbs:</span><br><span class="line">  - get</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt; kube-dns/clusterrolebinding.yaml</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: system:coredns</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: system:coredns</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: coredns</span><br><span class="line">  namespace: kube-system</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt; kube-dns/deployment.yaml</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    deployment.kubernetes.io/revision: &quot;1&quot;</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kube-dns</span><br><span class="line">  name: coredns</span><br><span class="line">  namespace: kube-system</span><br><span class="line">spec:</span><br><span class="line">  replicas: 2</span><br><span class="line">  revisionHistoryLimit: 10</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      k8s-app: kube-dns</span><br><span class="line">  strategy:</span><br><span class="line">    rollingUpdate:</span><br><span class="line">      maxSurge: 25%</span><br><span class="line">      maxUnavailable: 1</span><br><span class="line">    type: RollingUpdate</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      creationTimestamp: null</span><br><span class="line">      labels:</span><br><span class="line">        k8s-app: kube-dns</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - args:</span><br><span class="line">        - -conf</span><br><span class="line">        - /etc/coredns/Corefile</span><br><span class="line">        image: registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:1.6.5</span><br><span class="line">        imagePullPolicy: IfNotPresent</span><br><span class="line">        livenessProbe:</span><br><span class="line">          failureThreshold: 5</span><br><span class="line">          httpGet:</span><br><span class="line">            path: /health</span><br><span class="line">            port: 8080</span><br><span class="line">            scheme: HTTP</span><br><span class="line">          initialDelaySeconds: 60</span><br><span class="line">          periodSeconds: 10</span><br><span class="line">          successThreshold: 1</span><br><span class="line">          timeoutSeconds: 5</span><br><span class="line">        name: coredns</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 53</span><br><span class="line">          name: dns</span><br><span class="line">          protocol: UDP</span><br><span class="line">        - containerPort: 53</span><br><span class="line">          name: dns-tcp</span><br><span class="line">          protocol: TCP</span><br><span class="line">        - containerPort: 9153</span><br><span class="line">          name: metrics</span><br><span class="line">          protocol: TCP</span><br><span class="line">        readinessProbe:</span><br><span class="line">          failureThreshold: 3</span><br><span class="line">          httpGet:</span><br><span class="line">            path: /ready</span><br><span class="line">            port: 8181</span><br><span class="line">            scheme: HTTP</span><br><span class="line">          periodSeconds: 10</span><br><span class="line">          successThreshold: 1</span><br><span class="line">          timeoutSeconds: 1</span><br><span class="line">        resources:</span><br><span class="line">          limits:</span><br><span class="line">            memory: 170Mi</span><br><span class="line">          requests:</span><br><span class="line">            cpu: 100m</span><br><span class="line">            memory: 70Mi</span><br><span class="line">        securityContext:</span><br><span class="line">          allowPrivilegeEscalation: false</span><br><span class="line">          capabilities:</span><br><span class="line">            add:</span><br><span class="line">            - NET_BIND_SERVICE</span><br><span class="line">            drop:</span><br><span class="line">            - all</span><br><span class="line">          readOnlyRootFilesystem: true</span><br><span class="line">        terminationMessagePath: /dev/termination-log</span><br><span class="line">        terminationMessagePolicy: File</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - mountPath: /etc/coredns</span><br><span class="line">          name: config-volume</span><br><span class="line">          readOnly: true</span><br><span class="line">      dnsPolicy: Default</span><br><span class="line">      nodeSelector:</span><br><span class="line">        beta.kubernetes.io/os: linux</span><br><span class="line">      priorityClassName: system-cluster-critical</span><br><span class="line">      restartPolicy: Always</span><br><span class="line">      schedulerName: default-scheduler</span><br><span class="line">      securityContext: &#123;&#125;</span><br><span class="line">      serviceAccount: coredns</span><br><span class="line">      serviceAccountName: coredns</span><br><span class="line">      terminationGracePeriodSeconds: 30</span><br><span class="line">      tolerations:</span><br><span class="line">      - key: CriticalAddonsOnly</span><br><span class="line">        operator: Exists</span><br><span class="line">      - effect: NoSchedule</span><br><span class="line">        key: node-role.kubernetes.io/master</span><br><span class="line">      volumes:</span><br><span class="line">      - configMap:</span><br><span class="line">          defaultMode: 420</span><br><span class="line">          items:</span><br><span class="line">          - key: Corefile</span><br><span class="line">            path: Corefile</span><br><span class="line">          name: coredns</span><br><span class="line">        name: config-volume</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt; kube-dns/service.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    prometheus.io/port: &quot;9153&quot;</span><br><span class="line">    prometheus.io/scrape: &quot;true&quot;</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kube-dns</span><br><span class="line">    kubernetes.io/cluster-service: &quot;true&quot;</span><br><span class="line">    kubernetes.io/name: KubeDNS</span><br><span class="line">  name: kube-dns</span><br><span class="line">  namespace: kube-system</span><br><span class="line">spec:</span><br><span class="line">  clusterIP: 10.96.0.10</span><br><span class="line">  ports:</span><br><span class="line">  - name: dns</span><br><span class="line">    port: 53</span><br><span class="line">    protocol: UDP</span><br><span class="line">    targetPort: 53</span><br><span class="line">  - name: dns-tcp</span><br><span class="line">    port: 53</span><br><span class="line">    protocol: TCP</span><br><span class="line">    targetPort: 53</span><br><span class="line">  - name: metrics</span><br><span class="line">    port: 9153</span><br><span class="line">    protocol: TCP</span><br><span class="line">    targetPort: 9153</span><br><span class="line">  selector:</span><br><span class="line">    k8s-app: kube-dns</span><br><span class="line">  sessionAffinity: None</span><br><span class="line">  type: ClusterIP</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">kubectl create -f kube-dns/</span><br></pre></td></tr></table></figure>
<h2 id="7-验证Service的访问"><a href="#7-验证Service的访问" class="headerlink" title="7. 验证Service的访问"></a>7. 验证Service的访问</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p nginx/</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt; nginx/01-deployment.yaml</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx</span><br><span class="line">  labels:</span><br><span class="line">    app: nginx</span><br><span class="line">spec:</span><br><span class="line">  replicas: 2</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: nginx</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: nginx</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: nginx</span><br><span class="line">        image: nginx:1.7.9</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 80</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt; nginx/02-service.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    app: nginx</span><br><span class="line">  ports:</span><br><span class="line">    - nodePort: 31073</span><br><span class="line">      protocol: TCP</span><br><span class="line">      port: 80</span><br><span class="line">      targetPort: 80</span><br><span class="line">  type: NodePort</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">kubectl create -f nginx/</span><br><span class="line"></span><br><span class="line"># 有响应视为正常，否则视为不正常</span><br><span class="line">curl -XGET http://192.168.112.129:31073</span><br><span class="line">curl -XGET http://192.168.112.130:31073</span><br></pre></td></tr></table></figure>
<h2 id="8-验证Pod的网络和DNS配置"><a href="#8-验证Pod的网络和DNS配置" class="headerlink" title="8. 验证Pod的网络和DNS配置"></a>8. 验证Pod的网络和DNS配置</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br></pre></td><td class="code"><pre><span class="line"># 在node01节点和node02节点上分别操作</span><br><span class="line">mkdir -p network/</span><br><span class="line">cd network/</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt; Dockerfile</span><br><span class="line">FROM alpine:3.8</span><br><span class="line"></span><br><span class="line">MAINTAINER wangxin_0611@126.com</span><br><span class="line"></span><br><span class="line">RUN apk add --no-cache ca-certificates bind-tools iputils iproute2 net-tools tcpdump</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">docker build -t wangx/alpine:3.8-network .</span><br><span class="line"></span><br><span class="line"># 在master节点上操作</span><br><span class="line">mkdir -p network/</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt; network/network.yaml</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: DaemonSet</span><br><span class="line">metadata:</span><br><span class="line">  name: network</span><br><span class="line">  namespace: default</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: network</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: network</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: network</span><br><span class="line">        image: wangx/alpine:3.8-network</span><br><span class="line">        imagePullPolicy: IfNotPresent</span><br><span class="line">        command:</span><br><span class="line">        - sleep</span><br><span class="line">        - &quot;3600&quot;</span><br><span class="line">      restartPolicy: Always</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">kubectl create -f network/</span><br><span class="line"></span><br><span class="line">[root@master ~]# kubectl get pod -o wide</span><br><span class="line">NAME            READY     STATUS    RESTARTS   AGE       IP           NODE</span><br><span class="line">network-bl7jx   1/1       Running   0          6m        10.211.1.4   node02</span><br><span class="line">network-m2vp6   1/1       Running   0          6m        10.211.0.4   node01</span><br><span class="line"></span><br><span class="line"># 在node01上的pod中验证</span><br><span class="line">[root@master ~]# kubectl exec -it network-m2vp6 /bin/sh</span><br><span class="line">/ # cat /etc/resolv.conf</span><br><span class="line">nameserver 10.96.0.10</span><br><span class="line">search default.svc.cluster.local svc.cluster.local cluster.local</span><br><span class="line">options ndots:5</span><br><span class="line">/ # ip address</span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1/8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 ::1/128 scope host</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">2: tunl0@NONE: &lt;NOARP&gt; mtu 1480 qdisc noop state DOWN group default qlen 1</span><br><span class="line">    link/ipip 0.0.0.0 brd 0.0.0.0</span><br><span class="line">4: eth0@if11: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default</span><br><span class="line">    link/ether 72:01:49:fa:fb:f3 brd ff:ff:ff:ff:ff:ff link-netnsid 0</span><br><span class="line">    inet 10.211.0.4/32 scope global eth0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::7001:49ff:fefa:fbf3/64 scope link</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">/ # ping -c 4 10.211.1.4</span><br><span class="line">PING 10.211.1.4 (10.211.1.4) 56(84) bytes of data.</span><br><span class="line">64 bytes from 10.211.1.4: icmp_seq=1 ttl=62 time=0.314 ms</span><br><span class="line">64 bytes from 10.211.1.4: icmp_seq=2 ttl=62 time=0.490 ms</span><br><span class="line">64 bytes from 10.211.1.4: icmp_seq=3 ttl=62 time=0.415 ms</span><br><span class="line">64 bytes from 10.211.1.4: icmp_seq=4 ttl=62 time=0.491 ms</span><br><span class="line"></span><br><span class="line">--- 10.211.1.4 ping statistics ---</span><br><span class="line">4 packets transmitted, 4 received, 0% packet loss, time 3000ms</span><br><span class="line">rtt min/avg/max/mdev = 0.314/0.427/0.491/0.075 ms</span><br><span class="line">/ # nslookup kubernetes.default</span><br><span class="line">Server:   10.96.0.10</span><br><span class="line">Address:  10.96.0.10#53</span><br><span class="line"></span><br><span class="line">Name: kubernetes.default.svc.cluster.local</span><br><span class="line">Address: 10.96.0.1</span><br><span class="line"></span><br><span class="line">/ # nslookup kubernetes</span><br><span class="line">Server:   10.96.0.10</span><br><span class="line">Address:  10.96.0.10#53</span><br><span class="line"></span><br><span class="line">Name: kubernetes.default.svc.cluster.local</span><br><span class="line">Address: 10.96.0.1</span><br><span class="line"></span><br><span class="line">/ # exit</span><br><span class="line"></span><br><span class="line"># 在node02上的pod中验证</span><br><span class="line">[root@master ~]# kubectl get pod -o wide</span><br><span class="line">NAME            READY     STATUS    RESTARTS   AGE       IP           NODE</span><br><span class="line">network-bl7jx   1/1       Running   0          9m        10.211.1.4   node02</span><br><span class="line">network-m2vp6   1/1       Running   0          9m        10.211.0.4   node01</span><br><span class="line">[root@master ~]# kubectl exec -it network-bl7jx /bin/sh</span><br><span class="line">/ # cat /etc/resolv.conf</span><br><span class="line">nameserver 10.96.0.10</span><br><span class="line">search default.svc.cluster.local svc.cluster.local cluster.local</span><br><span class="line">options ndots:5</span><br><span class="line">/ # ip address</span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1/8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 ::1/128 scope host</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">2: tunl0@NONE: &lt;NOARP&gt; mtu 1480 qdisc noop state DOWN group default qlen 1</span><br><span class="line">    link/ipip 0.0.0.0 brd 0.0.0.0</span><br><span class="line">4: eth0@if9: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default</span><br><span class="line">    link/ether 5a:a6:51:22:9d:2b brd ff:ff:ff:ff:ff:ff link-netnsid 0</span><br><span class="line">    inet 10.211.1.4/32 scope global eth0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::58a6:51ff:fe22:9d2b/64 scope link</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">/ # ping -c 4 10.211.0.4</span><br><span class="line">PING 10.211.0.4 (10.211.0.4) 56(84) bytes of data.</span><br><span class="line">64 bytes from 10.211.0.4: icmp_seq=1 ttl=62 time=0.450 ms</span><br><span class="line">64 bytes from 10.211.0.4: icmp_seq=2 ttl=62 time=0.685 ms</span><br><span class="line">64 bytes from 10.211.0.4: icmp_seq=3 ttl=62 time=0.726 ms</span><br><span class="line">64 bytes from 10.211.0.4: icmp_seq=4 ttl=62 time=0.707 ms</span><br><span class="line"></span><br><span class="line">--- 10.211.0.4 ping statistics ---</span><br><span class="line">4 packets transmitted, 4 received, 0% packet loss, time 3003ms</span><br><span class="line">rtt min/avg/max/mdev = 0.450/0.642/0.726/0.111 ms</span><br><span class="line">/ # nslookup kubernetes.default</span><br><span class="line">Server:   10.96.0.10</span><br><span class="line">Address:  10.96.0.10#53</span><br><span class="line"></span><br><span class="line">Name: kubernetes.default.svc.cluster.local</span><br><span class="line">Address: 10.96.0.1</span><br><span class="line"></span><br><span class="line">/ # nslookup kubernetes</span><br><span class="line">Server:   10.96.0.10</span><br><span class="line">Address:  10.96.0.10#53</span><br><span class="line"></span><br><span class="line">Name: kubernetes.default.svc.cluster.local</span><br><span class="line">Address: 10.96.0.1</span><br><span class="line"></span><br><span class="line">/ # exit</span><br></pre></td></tr></table></figure>
<h1 id="六、参考资料"><a href="#六、参考资料" class="headerlink" title="六、参考资料"></a>六、参考资料</h1><p><a href="https://mritd.me/2018/01/07/kubernetes-tls-bootstrapping-note/" target="_blank" rel="noopener">https://mritd.me/2018/01/07/kubernetes-tls-bootstrapping-note/</a><br><a href="https://mritd.me/2018/08/28/kubernetes-tls-bootstrapping-with-bootstrap-token/" target="_blank" rel="noopener">https://mritd.me/2018/08/28/kubernetes-tls-bootstrapping-with-bootstrap-token/</a><br><a href="https://jimmysong.io/kubernetes-handbook/practice/kubectl-installation.html" target="_blank" rel="noopener">https://jimmysong.io/kubernetes-handbook/practice/kubectl-installation.html</a><br><a href="https://kubernetes.io/docs/reference/access-authn-authz/rbac/#default-roles-and-role-bindings" target="_blank" rel="noopener">https://kubernetes.io/docs/reference/access-authn-authz/rbac/#default-roles-and-role-bindings</a><br><a href="https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/#noderestriction" target="_blank" rel="noopener">https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/#noderestriction</a><br><a href="https://kubernetes.io/docs/reference/access-authn-authz/node/" target="_blank" rel="noopener">https://kubernetes.io/docs/reference/access-authn-authz/node/</a><br><a href="https://kubernetes.io/docs/reference/command-line-tools-reference/kubelet-tls-bootstrapping/" target="_blank" rel="noopener">https://kubernetes.io/docs/reference/command-line-tools-reference/kubelet-tls-bootstrapping/</a><br><a href="https://kubernetes.io/docs/reference/access-authn-authz/bootstrap-tokens/" target="_blank" rel="noopener">https://kubernetes.io/docs/reference/access-authn-authz/bootstrap-tokens/</a><br><a href="https://www.cnblogs.com/shenlinken/p/9968274.html" target="_blank" rel="noopener">https://www.cnblogs.com/shenlinken/p/9968274.html</a></p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Docker/">Docker</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Kubernetes/">Kubernetes</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Setup/">Setup</a></li></ul>
	</div>

      
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/容器云技术/">容器云技术</a>
	</div>


      
      <div class="clearfix"></div>
    </div>
      
    
  </div>
  
</article>







  
    <article id="post-ceph_dock_kubernetes_001" class="article article-type-post" itemscope="" itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2019/10/14/ceph_dock_kubernetes_001/" class="article-date">
  	<time datetime="2019-10-14T03:04:19.009Z" itemprop="datePublished">2019-10-14</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/10/14/ceph_dock_kubernetes_001/">
        Kubernetes集群对接Ceph集群：搭建可对接Ceph实验环境的Kubernetes实验环境
        
      </a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="一、实验环境说明"><a href="#一、实验环境说明" class="headerlink" title="一、实验环境说明"></a>一、实验环境说明</h1><h2 id="1-环境主旨说明"><a href="#1-环境主旨说明" class="headerlink" title="1. 环境主旨说明"></a>1. 环境主旨说明</h2><p>本文旨在帮助读者搭建一个可对接Ceph实验环境的Kubernetes实验环境。关于基本Kubernetes环境的搭建，这里不做讲解，读者请参考网络上的资料，或者本博客的另外一篇文章《使用kubeadm的方式安装Kubernetes集群（一）》，链接地址详见“参考资料”。</p>
<h2 id="2-环境要点说明"><a href="#2-环境要点说明" class="headerlink" title="2. 环境要点说明"></a>2. 环境要点说明</h2><p>升级所有节点的内核为主线版本，包括master节点和所有node节点。<br>所有的节点都安装ceph-common组件和python-cephfs组件，包括master节点和所有node节点。</p>
<h1 id="二、实验环境版本信息"><a href="#二、实验环境版本信息" class="headerlink" title="二、实验环境版本信息"></a>二、实验环境版本信息</h1><h2 id="1-操作系统的版本信息"><a href="#1-操作系统的版本信息" class="headerlink" title="1. 操作系统的版本信息"></a>1. 操作系统的版本信息</h2><p>CentOS Linux release 7.7.1908 (Core)</p>
<h2 id="2-核心组件的版本信息"><a href="#2-核心组件的版本信息" class="headerlink" title="2. 核心组件的版本信息"></a>2. 核心组件的版本信息</h2><p>Ceph Luminous 版本 的 ceph-common 和 python-cephfs<br>Kubernetes v1.16.0</p>
<h1 id="三、实验步骤"><a href="#三、实验步骤" class="headerlink" title="三、实验步骤"></a>三、实验步骤</h1><h2 id="1-升级所有节点（所有的master和node节点）的内核为主线版本（当前主线版本为-5-3-6-1-el7-elrepo-x86-64）"><a href="#1-升级所有节点（所有的master和node节点）的内核为主线版本（当前主线版本为-5-3-6-1-el7-elrepo-x86-64）" class="headerlink" title="1. 升级所有节点（所有的master和node节点）的内核为主线版本（当前主线版本为 5.3.6-1.el7.elrepo.x86_64）"></a>1. 升级所有节点（所有的master和node节点）的内核为主线版本（当前主线版本为 5.3.6-1.el7.elrepo.x86_64）</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">yum install -y yum-plugin-fastestmirror</span><br><span class="line">cat /etc/redhat-release</span><br><span class="line">cat /etc/os-release</span><br><span class="line">uname -snr</span><br><span class="line"></span><br><span class="line">rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org</span><br><span class="line">rpm -Uvh https://www.elrepo.org/elrepo-release-7.0-3.el7.elrepo.noarch.rpm</span><br><span class="line">yum repolist</span><br><span class="line"></span><br><span class="line">yum --enablerepo=elrepo-kernel install -y kernel-ml</span><br><span class="line">yum repolist all</span><br><span class="line"></span><br><span class="line">awk -F\&apos; &apos;$1==&quot;menuentry &quot; &#123;print i++ &quot; : &quot; $2&#125;&apos; /etc/grub2.cfg</span><br><span class="line">grub2-set-default 0</span><br><span class="line">grub2-mkconfig -o /boot/grub2/grub.cfg</span><br><span class="line">reboot</span><br><span class="line"></span><br><span class="line">uname -snr</span><br></pre></td></tr></table></figure>
<h2 id="2-所有节点（所有的master和node节点）安装-ceph-luminous-版本-的-ceph-common-和-python-cephfs"><a href="#2-所有节点（所有的master和node节点）安装-ceph-luminous-版本-的-ceph-common-和-python-cephfs" class="headerlink" title="2. 所有节点（所有的master和node节点）安装 ceph luminous 版本 的 ceph-common 和 python-cephfs"></a>2. 所有节点（所有的master和node节点）安装 ceph luminous 版本 的 ceph-common 和 python-cephfs</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">cat &lt;&lt;EOF &gt;&gt; /etc/yum.repos.d/ceph.repo</span><br><span class="line">[ceph-noarch]</span><br><span class="line">name=Ceph noarch packages</span><br><span class="line">baseurl=http://mirrors.163.com/ceph/rpm-luminous/el7/noarch</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=1</span><br><span class="line">priority=1</span><br><span class="line">type=rpm-md</span><br><span class="line">gpgkey=http://mirrors.163.com/ceph/keys/release.asc</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">yum makecache fast</span><br><span class="line">yum install -y ceph-common python-cephfs</span><br></pre></td></tr></table></figure>
<h2 id="3-为-Kubernetes-集群安装-ceph-rbd-和-ceph-fs-的-对应的-provisioner-服务"><a href="#3-为-Kubernetes-集群安装-ceph-rbd-和-ceph-fs-的-对应的-provisioner-服务" class="headerlink" title="3. 为 Kubernetes 集群安装 ceph rbd 和 ceph fs 的 对应的 provisioner 服务"></a>3. 为 Kubernetes 集群安装 ceph rbd 和 ceph fs 的 对应的 provisioner 服务</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p external-storage/ceph/common/</span><br><span class="line">mkdir -p external-storage/ceph/rbd/</span><br><span class="line">mkdir -p external-storage/ceph/fs/</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt;&gt; external-storage/ceph/common/01-namespaces.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Namespace</span><br><span class="line">metadata:</span><br><span class="line">  name: storage</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"># For ceph rbd</span><br><span class="line">cat &lt;&lt;EOF &gt;&gt; external-storage/ceph/rbd/01-serviceaccount.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: cephrbd-provisioner</span><br><span class="line">  namespace: storage</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt;&gt; external-storage/ceph/rbd/02-clusterrole.yaml</span><br><span class="line">kind: ClusterRole</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: cephrbd-provisioner</span><br><span class="line">rules:</span><br><span class="line">  - apiGroups: [&quot;&quot;]</span><br><span class="line">    resources: [&quot;endpoints&quot;]</span><br><span class="line">    verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;, &quot;create&quot;, &quot;update&quot;, &quot;patch&quot;]</span><br><span class="line">  - apiGroups: [&quot;&quot;]</span><br><span class="line">    resources: [&quot;secrets&quot;]</span><br><span class="line">    verbs: [&quot;get&quot;, &quot;watch&quot;, &quot;list&quot;, &quot;create&quot;, &quot;update&quot;, &quot;delete&quot;]</span><br><span class="line">  - apiGroups: [&quot;&quot;]</span><br><span class="line">    resources: [&quot;persistentvolumes&quot;]</span><br><span class="line">    verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;, &quot;create&quot;, &quot;delete&quot;]</span><br><span class="line">  - apiGroups: [&quot;&quot;]</span><br><span class="line">    resources: [&quot;persistentvolumeclaims&quot;]</span><br><span class="line">    verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;, &quot;update&quot;]</span><br><span class="line">  - apiGroups: [&quot;storage.k8s.io&quot;]</span><br><span class="line">    resources: [&quot;storageclasses&quot;]</span><br><span class="line">    verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;]</span><br><span class="line">  - apiGroups: [&quot;&quot;]</span><br><span class="line">    resources: [&quot;events&quot;]</span><br><span class="line">    verbs: [&quot;create&quot;, &quot;update&quot;, &quot;patch&quot;]</span><br><span class="line">  - apiGroups: [&quot;&quot;]</span><br><span class="line">    resources: [&quot;services&quot;]</span><br><span class="line">    resourceNames: [&quot;kube-dns&quot;,&quot;coredns&quot;]</span><br><span class="line">    verbs: [&quot;list&quot;, &quot;get&quot;]</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt;&gt; external-storage/ceph/rbd/03-clusterrolebinding.yaml</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: cephrbd-provisioner</span><br><span class="line">subjects:</span><br><span class="line">  - kind: ServiceAccount</span><br><span class="line">    name: cephrbd-provisioner</span><br><span class="line">    namespace: storage</span><br><span class="line">roleRef:</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: cephrbd-provisioner</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt;&gt; external-storage/ceph/rbd/04-deployment.yaml</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: cephrbd-provisioner</span><br><span class="line">  namespace: storage</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: cephrbd-provisioner</span><br><span class="line">  strategy:</span><br><span class="line">    type: Recreate</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: cephrbd-provisioner</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">        - name: cephrbd-provisioner</span><br><span class="line">          image: wangx/rbd-provisioner:luminous</span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          env:</span><br><span class="line">            - name: PROVISIONER_NAME</span><br><span class="line">              value: ceph.com/rbd</span><br><span class="line">      serviceAccount: cephrbd-provisioner</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># For ceph fs</span><br><span class="line">cat &lt;&lt;EOF &gt;&gt; external-storage/ceph/fs/01-serviceaccount.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: cephfs-provisioner</span><br><span class="line">  namespace: storage</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt;&gt; external-storage/ceph/fs/02-clusterrole.yaml</span><br><span class="line">kind: ClusterRole</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: cephfs-provisioner</span><br><span class="line">rules:</span><br><span class="line">  - apiGroups: [&quot;&quot;]</span><br><span class="line">    resources: [&quot;endpoints&quot;]</span><br><span class="line">    verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;, &quot;create&quot;, &quot;update&quot;, &quot;patch&quot;]</span><br><span class="line">  - apiGroups: [&quot;&quot;]</span><br><span class="line">    resources: [&quot;secrets&quot;]</span><br><span class="line">    verbs: [&quot;get&quot;, &quot;watch&quot;, &quot;list&quot;, &quot;create&quot;, &quot;update&quot;, &quot;delete&quot;]</span><br><span class="line">  - apiGroups: [&quot;&quot;]</span><br><span class="line">    resources: [&quot;persistentvolumes&quot;]</span><br><span class="line">    verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;, &quot;create&quot;, &quot;delete&quot;]</span><br><span class="line">  - apiGroups: [&quot;&quot;]</span><br><span class="line">    resources: [&quot;persistentvolumeclaims&quot;]</span><br><span class="line">    verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;, &quot;update&quot;]</span><br><span class="line">  - apiGroups: [&quot;storage.k8s.io&quot;]</span><br><span class="line">    resources: [&quot;storageclasses&quot;]</span><br><span class="line">    verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;]</span><br><span class="line">  - apiGroups: [&quot;&quot;]</span><br><span class="line">    resources: [&quot;events&quot;]</span><br><span class="line">    verbs: [&quot;create&quot;, &quot;update&quot;, &quot;patch&quot;]</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt;&gt; external-storage/ceph/fs/03-clusterrolebinding.yaml</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: cephfs-provisioner</span><br><span class="line">subjects:</span><br><span class="line">  - kind: ServiceAccount</span><br><span class="line">    name: cephfs-provisioner</span><br><span class="line">    namespace: storage</span><br><span class="line">roleRef:</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: cephfs-provisioner</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt;&gt; external-storage/ceph/fs/04-deployment.yaml</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: cephfs-provisioner</span><br><span class="line">  namespace: storage</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: cephfs-provisioner</span><br><span class="line">  strategy:</span><br><span class="line">    type: Recreate</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: cephfs-provisioner</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">        - name: cephfs-provisioner</span><br><span class="line">          image: wangx/cephfs-provisioner:luminous</span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          env:</span><br><span class="line">            - name: PROVISIONER_NAME</span><br><span class="line">              value: ceph.com/cephfs</span><br><span class="line">          command:</span><br><span class="line">            - &quot;/usr/local/bin/cephfs-provisioner&quot;</span><br><span class="line">          args:</span><br><span class="line">            - &quot;-id=cephfs-provisioner-1&quot;</span><br><span class="line">      serviceAccount: cephfs-provisioner</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"># crete ceph provisioner&apos;s namespace</span><br><span class="line">kubectl create -f external-storage/ceph/common/</span><br><span class="line"></span><br><span class="line"># create ceph rbd provisioner</span><br><span class="line">kubectl create -f external-storage/ceph/rbd/</span><br><span class="line"></span><br><span class="line"># create ceph fs provisioner</span><br><span class="line">kubectl create -f external-storage/ceph/fs/</span><br></pre></td></tr></table></figure>
<h2 id="4-为-Kubernetes-集群的-ceph-rbd-和-ceph-fs-的-provisioner-服务创建-StroageClass-对象"><a href="#4-为-Kubernetes-集群的-ceph-rbd-和-ceph-fs-的-provisioner-服务创建-StroageClass-对象" class="headerlink" title="4. 为 Kubernetes 集群的 ceph rbd 和 ceph fs 的 provisioner 服务创建 StroageClass 对象"></a>4. 为 Kubernetes 集群的 ceph rbd 和 ceph fs 的 provisioner 服务创建 StroageClass 对象</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br></pre></td><td class="code"><pre><span class="line"># For ceph rbd </span><br><span class="line">## 注意：这里需要更换两个Secret的key的值为你的环境的。</span><br><span class="line">mkdir -p external-storage/ceph/rbd/storageclass/</span><br><span class="line">cat &lt;&lt;EOF &gt;&gt; external-storage/ceph/rbd/storageclass/01-secrets.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Secret</span><br><span class="line">metadata:</span><br><span class="line">  name: cephrbd-admin-secret</span><br><span class="line">  namespace: storage</span><br><span class="line">type: &quot;kubernetes.io/cephrbd&quot;</span><br><span class="line">data:</span><br><span class="line">  # ceph auth get-key client.admin | base64</span><br><span class="line">  key: QVFDTmZxRmRDRmtnT3hBQURwY29VdjltbGJqRmIxMTJ2dzlLdEE9PQ==</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Secret</span><br><span class="line">metadata:</span><br><span class="line">  name: cephrbd-user-secret</span><br><span class="line">  namespace: storage</span><br><span class="line">type: &quot;kubernetes.io/cephrbd&quot;</span><br><span class="line">data:</span><br><span class="line">  # ceph auth add client.kube mon &apos;allow r&apos; osd &apos;allow rwx pool=kube&apos;</span><br><span class="line">  # ceph auth get-key client.kube | base64</span><br><span class="line">  key: QVFBZ3Q2RmRibnBOTXhBQXkwQkJrdmQxQW5adHlWN0syZWIvSEE9PQ==</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt;&gt; external-storage/ceph/rbd/storageclass/02-storageclass.yaml</span><br><span class="line">kind: StorageClass</span><br><span class="line">apiVersion: storage.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: cephrbd</span><br><span class="line">provisioner: ceph.com/rbd</span><br><span class="line">parameters:</span><br><span class="line">  monitors: ceph-mon.storage.svc.cluster.local:6789 # 这里需要使用Kubernetes内部的DNS配置ceph monitor的地址</span><br><span class="line">  pool: kube</span><br><span class="line">  adminId: admin</span><br><span class="line">  adminSecretNamespace: storage</span><br><span class="line">  adminSecretName: cephrbd-admin-secret</span><br><span class="line">  userId: kube</span><br><span class="line">  userSecretNamespace: storage</span><br><span class="line">  userSecretName: cephrbd-user-secret</span><br><span class="line">  imageFormat: &quot;2&quot;</span><br><span class="line">  imageFeatures: layering</span><br><span class="line">---</span><br><span class="line">kind: Service</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  name: ceph-mon</span><br><span class="line">  namespace: storage</span><br><span class="line">spec:</span><br><span class="line">  type: ExternalName</span><br><span class="line">  externalName: 192.168.112.131.xip.io # ceph monitor的地址</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">kubectl create -f external-storage/ceph/rbd/storageclass/</span><br><span class="line"></span><br><span class="line"># For ceph fs</span><br><span class="line">## 注意：这里需要更换Secret的key的值为你的环境的。</span><br><span class="line">mkdir -p external-storage/ceph/fs/storageclass/</span><br><span class="line">cat &lt;&lt;EOF &gt;&gt; external-storage/ceph/fs/storageclass/01-secrets.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Secret</span><br><span class="line">metadata:</span><br><span class="line">  name: cephfs-admin-secret</span><br><span class="line">  namespace: storage</span><br><span class="line">type: &quot;kubernetes.io/cephfs&quot;</span><br><span class="line">data:</span><br><span class="line">  # ceph auth get-key client.admin | base64</span><br><span class="line">  key: QVFDTmZxRmRDRmtnT3hBQURwY29VdjltbGJqRmIxMTJ2dzlLdEE9PQ==</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt;&gt; external-storage/ceph/fs/storageclass/02-storageclass.yaml</span><br><span class="line">kind: StorageClass</span><br><span class="line">apiVersion: storage.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: cephfs</span><br><span class="line">provisioner: ceph.com/cephfs</span><br><span class="line">parameters:</span><br><span class="line">  monitors: 192.168.112.131:6789</span><br><span class="line">  adminId: admin</span><br><span class="line">  adminSecretName: cephfs-admin-secret</span><br><span class="line">  adminSecretNamespace: storage</span><br><span class="line">  claimRoot: /volumes/kubernetes</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">kubectl create -f external-storage/ceph/fs/storageclass/</span><br></pre></td></tr></table></figure>
<h2 id="5-验证-Kubernetes-集群的-ceph-rbd-和-ceph-fs-的-provisioner-服务配合StroageClass-对象实现的动态存储供应功能"><a href="#5-验证-Kubernetes-集群的-ceph-rbd-和-ceph-fs-的-provisioner-服务配合StroageClass-对象实现的动态存储供应功能" class="headerlink" title="5. 验证 Kubernetes 集群的 ceph rbd 和 ceph fs 的 provisioner 服务配合StroageClass 对象实现的动态存储供应功能"></a>5. 验证 Kubernetes 集群的 ceph rbd 和 ceph fs 的 provisioner 服务配合StroageClass 对象实现的动态存储供应功能</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br></pre></td><td class="code"><pre><span class="line"># 创建pvc和pod用于验证ceph rbd</span><br><span class="line">mkdir -p external-storage/ceph/rbd/example/</span><br><span class="line">cat &lt;&lt;EOF &gt;&gt; external-storage/ceph/rbd/example/01-claim.yaml</span><br><span class="line">kind: PersistentVolumeClaim</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  name: claim1</span><br><span class="line">spec:</span><br><span class="line">  accessModes:</span><br><span class="line">    - ReadWriteOnce</span><br><span class="line">  storageClassName: cephrbd</span><br><span class="line">  resources:</span><br><span class="line">    requests:</span><br><span class="line">      storage: 1Gi</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt;&gt; external-storage/ceph/rbd/example/02-pod.yaml</span><br><span class="line">kind: Pod</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  name: test-pod-1</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">    - name: test-pod-1</span><br><span class="line">      image: nginx:1.7.9</span><br><span class="line">      imagePullPolicy: IfNotPresent</span><br><span class="line">      ports:</span><br><span class="line">        - containerPort: 80</span><br><span class="line">      volumeMounts:</span><br><span class="line">        - name: pvc</span><br><span class="line">          mountPath: &quot;/data&quot;</span><br><span class="line">  volumes:</span><br><span class="line">    - name: pvc</span><br><span class="line">      persistentVolumeClaim:</span><br><span class="line">        claimName: claim1</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">kubectl create -f external-storage/ceph/rbd/example/</span><br><span class="line"></span><br><span class="line"># 创建pvc和pod用于验证ceph fs</span><br><span class="line">mkdir -p external-storage/ceph/fs/example/</span><br><span class="line">cat &lt;&lt;EOF &gt;&gt; external-storage/ceph/fs/example/01-claim.yaml</span><br><span class="line">kind: PersistentVolumeClaim</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  name: claim2</span><br><span class="line">spec:</span><br><span class="line">  storageClassName: cephfs</span><br><span class="line">  accessModes:</span><br><span class="line">    - ReadWriteMany</span><br><span class="line">  resources:</span><br><span class="line">    requests:</span><br><span class="line">      storage: 1Gi</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt;&gt; external-storage/ceph/fs/example/02-pod.yaml</span><br><span class="line">kind: Pod</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  name: test-pod-2</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">    - name: test-pod-2</span><br><span class="line">      image: nginx:1.7.9</span><br><span class="line">      imagePullPolicy: IfNotPresent</span><br><span class="line">      ports:</span><br><span class="line">        - containerPort: 80</span><br><span class="line">      volumeMounts:</span><br><span class="line">        - name: pvc</span><br><span class="line">          mountPath: &quot;/data&quot;</span><br><span class="line">  volumes:</span><br><span class="line">    - name: pvc</span><br><span class="line">      persistentVolumeClaim:</span><br><span class="line">        claimName: claim2</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">kubectl create -f external-storage/ceph/fs/example/</span><br><span class="line"></span><br><span class="line"># 验证步骤如下所示：</span><br><span class="line">[root@master ~]# kubectl get pvc</span><br><span class="line">NAME     STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE</span><br><span class="line">claim1   Bound    pvc-8bcd7a8a-9c72-4c24-a5ce-dda3f72b459c   1Gi        RWO            cephrbd        5m22s</span><br><span class="line">claim2   Bound    pvc-6aeaf23b-c1c0-4654-8fa9-50656b5b7247   1Gi        RWX            cephfs         3m43s</span><br><span class="line"></span><br><span class="line">[root@master ~]# kubectl get pv</span><br><span class="line">NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM            STORAGECLASS   REASON   AGE</span><br><span class="line">pvc-6aeaf23b-c1c0-4654-8fa9-50656b5b7247   1Gi        RWX            Delete           Bound    default/claim2   cephfs                  3m55s</span><br><span class="line">pvc-8bcd7a8a-9c72-4c24-a5ce-dda3f72b459c   1Gi        RWO            Delete           Bound    default/claim1   cephrbd                 5m36s</span><br><span class="line"></span><br><span class="line">[root@master ~]# kubectl get pod -o wide</span><br><span class="line">NAME            READY   STATUS    RESTARTS   AGE     IP               NODE     NOMINATED NODE   READINESS GATES</span><br><span class="line">test-pod-1      1/1     Running   0          6m2s    10.211.196.133   node01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">test-pod-2      1/1     Running   0          4m23s   10.211.140.69    node02   &lt;none&gt;           &lt;none&gt;</span><br><span class="line"></span><br><span class="line">## 进入pod下的container中</span><br><span class="line">[root@master ~]# kubectl exec -it test-pod-1 /bin/bash</span><br><span class="line">root@test-pod-1:/# df -h</span><br><span class="line">Filesystem           Size  Used Avail Use% Mounted on</span><br><span class="line">overlay               17G  3.6G   14G  21% /</span><br><span class="line">tmpfs                 64M     0   64M   0% /dev</span><br><span class="line">tmpfs                982M     0  982M   0% /sys/fs/cgroup</span><br><span class="line">/dev/rbd0            976M  2.6M  958M   1% /data</span><br><span class="line">/dev/mapper/cl-root   17G  3.6G   14G  21% /dev/termination-log</span><br><span class="line">/dev/mapper/cl-root   17G  3.6G   14G  21% /etc/resolv.conf</span><br><span class="line">/dev/mapper/cl-root   17G  3.6G   14G  21% /etc/hostname</span><br><span class="line">/dev/mapper/cl-root   17G  3.6G   14G  21% /etc/hosts</span><br><span class="line">shm                   64M     0   64M   0% /dev/shm</span><br><span class="line">/dev/mapper/cl-root   17G  3.6G   14G  21% /var/cache/nginx</span><br><span class="line">tmpfs                982M   12K  982M   1% /run/secrets/kubernetes.io/serviceaccount</span><br><span class="line">tmpfs                982M     0  982M   0% /proc/acpi</span><br><span class="line">tmpfs                 64M     0   64M   0% /proc/kcore</span><br><span class="line">tmpfs                 64M     0   64M   0% /proc/keys</span><br><span class="line">tmpfs                 64M     0   64M   0% /proc/timer_list</span><br><span class="line">tmpfs                 64M     0   64M   0% /proc/sched_debug</span><br><span class="line">tmpfs                982M     0  982M   0% /proc/scsi</span><br><span class="line">tmpfs                982M     0  982M   0% /sys/firmware</span><br><span class="line">root@test-pod-1:/# cd /data/</span><br><span class="line">root@test-pod-1:/data# ls -la</span><br><span class="line">total 20</span><br><span class="line">drwxr-xr-x 3 root root  4096 Oct 14 05:43 .</span><br><span class="line">drwxr-xr-x 1 root root    41 Oct 14 05:39 ..</span><br><span class="line">drwx------ 2 root root 16384 Oct 14 05:39 lost+found</span><br><span class="line">root@test-pod-1:/data# echo &apos;hello ceph rbd.&apos; &gt; readme.md</span><br><span class="line">root@test-pod-1:/data# ls -la</span><br><span class="line">total 24</span><br><span class="line">drwxr-xr-x 3 root root  4096 Oct 14 05:43 .</span><br><span class="line">drwxr-xr-x 1 root root    41 Oct 14 05:39 ..</span><br><span class="line">drwx------ 2 root root 16384 Oct 14 05:39 lost+found</span><br><span class="line">-rw-r--r-- 1 root root    16 Oct 14 05:43 readme.md</span><br><span class="line">root@test-pod-1:/data# cat readme.md</span><br><span class="line">hello ceph rbd.</span><br><span class="line">root@test-pod-1:/data# exit</span><br><span class="line">exit</span><br><span class="line"></span><br><span class="line">[root@master ~]# kubectl exec -it test-pod-2 /bin/bash</span><br><span class="line">root@test-pod-2:/# df -h</span><br><span class="line">Filesystem                                                                                                       Size  Used Avail Use% Mounted on</span><br><span class="line">overlay                                                                                                           17G  3.6G   14G  21% /</span><br><span class="line">tmpfs                                                                                                             64M     0   64M   0% /dev</span><br><span class="line">tmpfs                                                                                                            982M     0  982M   0% /sys/fs/cgroup</span><br><span class="line">192.168.112.131:6789:/volumes/kubernetes/kubernetes/kubernetes-dynamic-pvc-41646ced-ee45-11e9-bfd9-eec9a057c13d   18G     0   18G   0% /data</span><br><span class="line">/dev/mapper/cl-root                                                                                               17G  3.6G   14G  21% /dev/termination-log</span><br><span class="line">/dev/mapper/cl-root                                                                                               17G  3.6G   14G  21% /etc/resolv.conf</span><br><span class="line">/dev/mapper/cl-root                                                                                               17G  3.6G   14G  21% /etc/hostname</span><br><span class="line">/dev/mapper/cl-root                                                                                               17G  3.6G   14G  21% /etc/hosts</span><br><span class="line">shm                                                                                                               64M     0   64M   0% /dev/shm</span><br><span class="line">/dev/mapper/cl-root                                                                                               17G  3.6G   14G  21% /var/cache/nginx</span><br><span class="line">tmpfs                                                                                                            982M   12K  982M   1% /run/secrets/kubernetes.io/serviceaccount</span><br><span class="line">tmpfs                                                                                                            982M     0  982M   0% /proc/acpi</span><br><span class="line">tmpfs                                                                                                             64M     0   64M   0% /proc/kcore</span><br><span class="line">tmpfs                                                                                                             64M     0   64M   0% /proc/keys</span><br><span class="line">tmpfs                                                                                                             64M     0   64M   0% /proc/timer_list</span><br><span class="line">tmpfs                                                                                                             64M     0   64M   0% /proc/sched_debug</span><br><span class="line">tmpfs                                                                                                            982M     0  982M   0% /proc/scsi</span><br><span class="line">tmpfs                                                                                                            982M     0  982M   0% /sys/firmware</span><br><span class="line">root@test-pod-2:/# cd /data/</span><br><span class="line">root@test-pod-2:/data# ls -la</span><br><span class="line">total 0</span><br><span class="line">drwxr-xr-x 2 root root  0 Oct 14 05:41 .</span><br><span class="line">drwxr-xr-x 1 root root 29 Oct 14 05:41 ..</span><br><span class="line">root@test-pod-2:/data# echo &apos;hello ceph fs.&apos; &gt; readme.md</span><br><span class="line">root@test-pod-2:/data# ls -la</span><br><span class="line">total 1</span><br><span class="line">drwxr-xr-x 2 root root  1 Oct 14 05:44 .</span><br><span class="line">drwxr-xr-x 1 root root 29 Oct 14 05:41 ..</span><br><span class="line">-rw-r--r-- 1 root root 15 Oct 14 05:44 readme.md</span><br><span class="line">root@test-pod-2:/data# cat readme.md</span><br><span class="line">hello ceph fs.</span><br><span class="line">root@test-pod-2:/data# exit</span><br><span class="line">exit</span><br><span class="line"></span><br><span class="line"># 在test-pod-1的宿主机上</span><br><span class="line">[root@node01 ~]# df -h</span><br><span class="line">Filesystem           Size  Used Avail Use% Mounted on</span><br><span class="line">devtmpfs             969M     0  969M   0% /dev</span><br><span class="line">tmpfs                982M     0  982M   0% /dev/shm</span><br><span class="line">tmpfs                982M   23M  959M   3% /run</span><br><span class="line">tmpfs                982M     0  982M   0% /sys/fs/cgroup</span><br><span class="line">/dev/mapper/cl-root   17G  3.6G   14G  21% /</span><br><span class="line">/dev/sda1           1014M  242M  773M  24% /boot</span><br><span class="line">tmpfs                982M   12K  982M   1% /var/lib/kubelet/pods/444da5da-6b0b-4eb9-961c-e67620e2790d/volumes/kubernetes.io~secret/calico-node-token-j29td</span><br><span class="line">tmpfs                982M   12K  982M   1% /var/lib/kubelet/pods/5c6b4dc9-9789-431f-abda-69b791e00852/volumes/kubernetes.io~secret/kube-proxy-token-2xvqz</span><br><span class="line">tmpfs                982M   12K  982M   1% /var/lib/kubelet/pods/117bf0a0-1de4-4233-8f86-58e3b7e222d9/volumes/kubernetes.io~secret/default-token-lvg9j</span><br><span class="line">overlay               17G  3.6G   14G  21% /var/lib/docker/overlay2/c0137c8945f708c9a9af29c435006164f1880e62e12d0944558d76fe826cf79e/merged</span><br><span class="line">overlay               17G  3.6G   14G  21% /var/lib/docker/overlay2/a173aac7b6bd051d9309d31dc98bffc8d8b4601738ad8670981c65e9f206f4d7/merged</span><br><span class="line">shm                   64M     0   64M   0% /var/lib/docker/containers/af5a902877155cc3f0d80506e4af572364e1b02b7527ebc272e36cc3537fdaf0/mounts/shm</span><br><span class="line">shm                   64M     0   64M   0% /var/lib/docker/containers/779e0a0a9e8e46ba53b976b9e0e0acb133778159c001d314d9fb4a689ce4dd51/mounts/shm</span><br><span class="line">overlay               17G  3.6G   14G  21% /var/lib/docker/overlay2/e0f0e09989f3e152c17f2ccf7e15df86a0844f59277804d409126e7508e892f2/merged</span><br><span class="line">overlay               17G  3.6G   14G  21% /var/lib/docker/overlay2/6cf53e19aa7a1cabfcc992b492f0c2d7b3a5b7a41a999e3e17c6e85acd432385/merged</span><br><span class="line">tmpfs                197M     0  197M   0% /run/user/0</span><br><span class="line">overlay               17G  3.6G   14G  21% /var/lib/docker/overlay2/ea9758ae1391c0b51be400d2c716398a6e6a75042c2d266b0fd5fffce49f1856/merged</span><br><span class="line">shm                   64M     0   64M   0% /var/lib/docker/containers/78374c2866c9e59956b46e6cf7745743e5366273eae4a28f584167895eff28c3/mounts/shm</span><br><span class="line">overlay               17G  3.6G   14G  21% /var/lib/docker/overlay2/f75360891104dd17f6035b84fc53e2cee9aa49cf4cb99abbc07ea4e53f3e68fa/merged</span><br><span class="line">tmpfs                982M   12K  982M   1% /var/lib/kubelet/pods/bc337b72-b78d-4f22-9074-0ea1e3c0854b/volumes/kubernetes.io~secret/cephfs-provisioner-token-gnvmf</span><br><span class="line">overlay               17G  3.6G   14G  21% /var/lib/docker/overlay2/5f2bb0260a595ebf2685f606c8fa57ae312b36d9ed0d2ac1c0226f108dcb4f8a/merged</span><br><span class="line">shm                   64M     0   64M   0% /var/lib/docker/containers/2be9a9eab8bf6181da1b00bd6745053236b5b72b4a625244f58664d6cef4056d/mounts/shm</span><br><span class="line">overlay               17G  3.6G   14G  21% /var/lib/docker/overlay2/19c0add3e797d302865131a736187e08b5773ff504cf24baa5ca6dc9e1e2f0bd/merged</span><br><span class="line">tmpfs                982M   12K  982M   1% /var/lib/kubelet/pods/94567637-87d1-44bf-b40c-4cf8d7249455/volumes/kubernetes.io~secret/default-token-lvg9j</span><br><span class="line">/dev/rbd0            976M  2.6M  958M   1% /var/lib/kubelet/plugins/kubernetes.io/rbd/mounts/kube-image-kubernetes-dynamic-pvc-06ed8402-ee45-11e9-81e1-626518d2252b</span><br><span class="line">overlay               17G  3.6G   14G  21% /var/lib/docker/overlay2/0f9b3b248dd6fd5db871c9a8340c3b221099ca48e5e44496b0e8ff87d385053e/merged</span><br><span class="line">shm                   64M     0   64M   0% /var/lib/docker/containers/7fa70409cd56a31427c89a61db4d102261610678a06a550eecfd1c44092c0d02/mounts/shm</span><br><span class="line">overlay               17G  3.6G   14G  21% /var/lib/docker/overlay2/723eda3646d4eabdb62faa89566f0c6d84a14f7f882acee46af96630d96480e4/merged</span><br><span class="line"></span><br><span class="line"># 在test-pod-2的宿主机上</span><br><span class="line">[root@node02 ~]# df -h</span><br><span class="line">Filesystem                                                                                                       Size  Used Avail Use% Mounted on</span><br><span class="line">devtmpfs                                                                                                         969M     0  969M   0% /dev</span><br><span class="line">tmpfs                                                                                                            982M     0  982M   0% /dev/shm</span><br><span class="line">tmpfs                                                                                                            982M   22M  960M   3% /run</span><br><span class="line">tmpfs                                                                                                            982M     0  982M   0% /sys/fs/cgroup</span><br><span class="line">/dev/mapper/cl-root                                                                                               17G  3.6G   14G  21% /</span><br><span class="line">/dev/sda1                                                                                                       1014M  242M  773M  24% /boot</span><br><span class="line">tmpfs                                                                                                            982M   12K  982M   1% /var/lib/kubelet/pods/cde8bcd0-da54-40f8-90e1-a8c53daaca8a/volumes/kubernetes.io~secret/default-token-lvg9j</span><br><span class="line">tmpfs                                                                                                            982M   12K  982M   1% /var/lib/kubelet/pods/27785efc-053d-41c1-b081-d61056715dce/volumes/kubernetes.io~secret/kube-proxy-token-2xvqz</span><br><span class="line">tmpfs                                                                                                            982M   12K  982M   1% /var/lib/kubelet/pods/6af3ba89-fd1d-4ca6-9f1f-d1a9d24aab68/volumes/kubernetes.io~secret/calico-node-token-j29td</span><br><span class="line">overlay                                                                                                           17G  3.6G   14G  21% /var/lib/docker/overlay2/fe5b85b1611ec8ce24761d70dec417d8102f71c13dc3ba0005387999d7f90538/merged</span><br><span class="line">overlay                                                                                                           17G  3.6G   14G  21% /var/lib/docker/overlay2/a2e0efa3dd1bc8d4725acd7ea3123cf2331cabfbd3f58185de44f81dc61f17b2/merged</span><br><span class="line">shm                                                                                                               64M     0   64M   0% /var/lib/docker/containers/a9a00476e189f794aaa8d448f3fd492ed95d7f285ebe398f2561c3369f98f6fc/mounts/shm</span><br><span class="line">shm                                                                                                               64M     0   64M   0% /var/lib/docker/containers/97c5b22f15b951a1d8c88deae0a34163d729cedc2fd21aef2108e657d3dbd2ed/mounts/shm</span><br><span class="line">overlay                                                                                                           17G  3.6G   14G  21% /var/lib/docker/overlay2/d69d00d1bb9d51e3b2a622edfe213b16069886f6a3507b7d22f8cf35aadb67fb/merged</span><br><span class="line">overlay                                                                                                           17G  3.6G   14G  21% /var/lib/docker/overlay2/bc97fe5450c049b42c16ed70907ebf759fd16d8aa0f1f1b597828c400a95fec1/merged</span><br><span class="line">tmpfs                                                                                                            197M     0  197M   0% /run/user/0</span><br><span class="line">overlay                                                                                                           17G  3.6G   14G  21% /var/lib/docker/overlay2/be31ca99791b3a61b34750063296b3f61e0e33f6ca13bd89d09305e29282d93f/merged</span><br><span class="line">shm                                                                                                               64M     0   64M   0% /var/lib/docker/containers/75bf7cd29b86a191287b60b505ca9147aee2590026227b75c108e527c8a42050/mounts/shm</span><br><span class="line">overlay                                                                                                           17G  3.6G   14G  21% /var/lib/docker/overlay2/d424bbdc32abf0a7860ea8cc57138a578d3ac379a2a5a62d467ebdd503f85f12/merged</span><br><span class="line">tmpfs                                                                                                            982M   12K  982M   1% /var/lib/kubelet/pods/63e075b8-1b82-4ead-924b-e8233217c597/volumes/kubernetes.io~secret/cephrbd-provisioner-token-xx8qj</span><br><span class="line">overlay                                                                                                           17G  3.6G   14G  21% /var/lib/docker/overlay2/032279366ff9f083d5f54e8653789f77d30962fb74d9c796912462336ba089a8/merged</span><br><span class="line">shm                                                                                                               64M     0   64M   0% /var/lib/docker/containers/8e3f8bcbbb05781e69759fe678fdba68fa6ec0514972b3a399936c90d754ea1d/mounts/shm</span><br><span class="line">overlay                                                                                                           17G  3.6G   14G  21% /var/lib/docker/overlay2/ca226a39a87d3319f974bdbca242ff6621cafe356a24e9080d65b013f26b30ef/merged</span><br><span class="line">tmpfs                                                                                                            982M   12K  982M   1% /var/lib/kubelet/pods/094d7470-5712-4523-8eb8-9994dbfb2cfe/volumes/kubernetes.io~secret/default-token-lvg9j</span><br><span class="line">192.168.112.131:6789:/volumes/kubernetes/kubernetes/kubernetes-dynamic-pvc-41646ced-ee45-11e9-bfd9-eec9a057c13d   18G     0   18G   0% /var/lib/kubelet/pods/094d7470-5712-4523-8eb8-9994dbfb2cfe/volumes/kubernetes.io~cephfs/pvc-6aeaf23b-c1c0-4654-8fa9-50656b5b7247</span><br><span class="line">overlay                                                                                                           17G  3.6G   14G  21% /var/lib/docker/overlay2/7615fa1f189797ca2b111fa6122ea3a1d8c2f2c009d052a3e06c6a9e9d0b9ba3/merged</span><br><span class="line">shm                                                                                                               64M     0   64M   0% /var/lib/docker/containers/0a76bdb1043188470fa7a2aa3df3ce9640b658064cb41c872025b90ed46f6bcd/mounts/shm</span><br><span class="line">overlay                                                                                                           17G  3.6G   14G  21% /var/lib/docker/overlay2/49ef6810dedcd675d541f06df84336744a7cbb84a876daf96ffab7bbcfa304f7/merged</span><br></pre></td></tr></table></figure>
<h1 id="四、参考资料"><a href="#四、参考资料" class="headerlink" title="四、参考资料"></a>四、参考资料</h1><p><a href="https://github.com/kubernetes-incubator/external-storage/tree/v5.2.0/ceph" target="_blank" rel="noopener">https://github.com/kubernetes-incubator/external-storage/tree/v5.2.0/ceph</a><br><a href="https://www.howtoforge.com/tutorial/how-to-upgrade-kernel-in-centos-7-server/" target="_blank" rel="noopener">https://www.howtoforge.com/tutorial/how-to-upgrade-kernel-in-centos-7-server/</a><br><a href="https://singhwang.github.io/2019/10/03/kubeadm_kubernetes_cluster_000/" target="_blank" rel="noopener">https://singhwang.github.io/2019/10/03/kubeadm_kubernetes_cluster_000/</a></p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Ceph/">Ceph</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Docker/">Docker</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Kubernetes/">Kubernetes</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Storage/">Storage</a></li></ul>
	</div>

      
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/容器云技术/">容器云技术</a>
	</div>


      
      <div class="clearfix"></div>
    </div>
      
    
  </div>
  
</article>







  
  
    <nav id="page-nav">
      <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/5/">5</a><a class="extend next" rel="next" href="/page/2/">Next &raquo;</a>
    </nav>
  
</div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
      <div class="footer-left">
        &copy; 2020 Singh Wang
      </div>
        <div class="footer-right">
          <a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="https://github.com/smackgg/hexo-theme-smackdown" target="_blank">Smackdown</a>
        </div>
    </div>
  </div>
</footer>
    </div>
    
  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">


<script>
	var yiliaConfig = {
		fancybox: true,
		mathjax: true,
		animate: true,
		isHome: true,
		isPost: false,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: false
	}
</script>
<script src="/js/main.js"></script>



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js"></script>


  </div>
</body>
</html>