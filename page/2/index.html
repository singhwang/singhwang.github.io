<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  
  <title>Singh Wang</title>

  <!-- keywords -->
  

  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Singh Wang">
<meta property="og:url" content="http://yoursite.com/page/2/index.html">
<meta property="og:site_name" content="Singh Wang">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Singh Wang">
  
    <link rel="alternative" href="/atom.xml" title="Singh Wang" type="application/atom+xml">
  
  
    <link rel="icon" href="http://7xkj1z.com1.z0.glb.clouddn.com/head.jpg">
  
  <link rel="stylesheet" href="/css/style.css">
  
  

  <script src="//cdn.bootcss.com/require.js/2.3.2/require.min.js"></script>
  <script src="//cdn.bootcss.com/jquery/3.1.1/jquery.min.js"></script>

  
</head></html>
<body>
  <div id="container">
    <div id="particles-js"></div>
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			
			<img lazy-src="https://avatars0.githubusercontent.com/u/17465385?s=400&amp;u=cea56ed1710ec6ebab160c1ce1e068317e05b025&amp;v=4" class="js-avatar">
			
		</a>

		<hgroup>
		  <h1 class="header-author"><a href="/">Singh Wang</a></h1>
		</hgroup>

		

		
			<div class="switch-btn">
				<div class="icon">
					<div class="icon-ctn">
						<div class="icon-wrap icon-house" data-idx="0">
							<div class="birdhouse"></div>
							<div class="birdhouse_holes"></div>
						</div>
						<div class="icon-wrap icon-ribbon hide" data-idx="1">
							<div class="ribbon"></div>
						</div>
						
						
					</div>
					
				</div>
				<div class="tips-box hide">
					<div class="tips-arrow"></div>
					<ul class="tips-inner">
						<li>菜单</li>
						<li>标签</li>
						
						
					</ul>
				</div>
			</div>
		

		<div class="switch-area">
			<div class="switch-wrap">
				<section class="switch-part switch-part1">
					<nav class="header-menu">
						<ul>
						
							<li><a href="/archives">所有文章</a></li>
				        
							<li><a href="/categories/容器云技术/">容器云技术</a></li>
				        
						</ul>
					</nav>
					<nav class="header-nav">
						<div class="social">
							
								<a class="github" target="_blank" href="https://github.com/singhwang" title="github">github</a>
					        
						</div>
					</nav>
				</section>
				
				
				<section class="switch-part switch-part2">
					<div class="widget tagcloud" id="js-tagcloud">
						<a href="/tags/Calico/" style="font-size: 10px;">Calico</a> <a href="/tags/Ceph/" style="font-size: 10px;">Ceph</a> <a href="/tags/Common/" style="font-size: 10px;">Common</a> <a href="/tags/Docker/" style="font-size: 20px;">Docker</a> <a href="/tags/Elasticsearch/" style="font-size: 10px;">Elasticsearch</a> <a href="/tags/Fluentd/" style="font-size: 12px;">Fluentd</a> <a href="/tags/Ingress/" style="font-size: 10px;">Ingress</a> <a href="/tags/Kubernetes/" style="font-size: 18px;">Kubernetes</a> <a href="/tags/Label/" style="font-size: 10px;">Label</a> <a href="/tags/Logging/" style="font-size: 14px;">Logging</a> <a href="/tags/Monitoring/" style="font-size: 10px;">Monitoring</a> <a href="/tags/Network/" style="font-size: 14px;">Network</a> <a href="/tags/Prometheus/" style="font-size: 10px;">Prometheus</a> <a href="/tags/Setup/" style="font-size: 10px;">Setup</a> <a href="/tags/Storage/" style="font-size: 10px;">Storage</a> <a href="/tags/TimeZone/" style="font-size: 10px;">TimeZone</a> <a href="/tags/Trouble-Shooting/" style="font-size: 16px;">Trouble Shooting</a>
					</div>
				</section>
				
				
				

				
			</div>
		</div>
	</header>				
</div>
    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
  	<div class="overlay">
  		<div class="slider-trigger"></div>
  		<h1 class="header-author js-mobile-header hide">Singh Wang</h1>
  	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
				<img lazy-src="https://avatars0.githubusercontent.com/u/17465385?s=400&amp;u=cea56ed1710ec6ebab160c1ce1e068317e05b025&amp;v=4" class="js-avatar">
			</div>
			<hgroup>
			  <h1 class="header-author">Singh Wang</h1>
			</hgroup>
			
			<nav class="header-menu">
				<ul>
				
					<li><a href="/archives">所有文章</a></li>
		        
					<li><a href="/categories/容器云技术/">容器云技术</a></li>
		        
		        <div class="clearfix"></div>
				</ul>
			</nav>
			<nav class="header-nav">
				<div class="social">
					
						<a class="github" target="_blank" href="https://github.com/singhwang" title="github">github</a>
			        
				</div>
			</nav>
		</header>				
	</div>
</nav>
      <div class="body-wrap">
  
    <article id="post-kubernetes_trouble_shooting_001" class="article article-type-post" itemscope="" itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2018/11/16/kubernetes_trouble_shooting_001/" class="article-date">
  	<time datetime="2018-11-16T06:09:56.144Z" itemprop="datePublished">2018-11-16</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/11/16/kubernetes_trouble_shooting_001/">
        Kubernetes批量删除资源对象的注意事项：删除顺序和监测删除状态的重要性
        
      </a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="一、问题描述"><a href="#一、问题描述" class="headerlink" title="一、问题描述"></a>一、问题描述</h1><p>公司内部的某平台，底层基于Kubernetes实现（Kubernetes的存储部分采用动态存储供应对接NFS）。平台内部有一个逻辑单元，可以调用接口创建。该逻辑单元对应到Kubernetes层面，是一系列紧密相关的namespace、deployment、statefulset、job、persistentvolumeclaim和persistentvolume等资源对象的集合体，我们可以把这个逻辑单元理解为一个复杂的Kubernetes上的应用，该应用还是跨namespace的。</p>
<p>同事们平时开发、调试和运维该逻辑单元的时候，通常会这么做：</p>
<ol>
<li>开发和调试该逻辑单元的清理接口，直接调用Kubernetes API删除该逻辑单元对应的各种资源对象，删除过程就是直接删除，不控制顺序，不监测各个资源对象的删除状态；</li>
<li>运维该逻辑单元的清理操作，为了省事，直接使用kubectl清理该逻辑单元相关的namespace。</li>
</ol>
<p>近期发现线上环境，频繁发生Pod无法删除，一直处于Terminating状态。关于这个问题，我自己偶尔见到，也频繁有同事和我反应这个问题。于是，我定位了一下，到无法删除的Pod所在的宿主机节点上，查看kubelet日志，发现报错信息如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">。。。。。。</span><br><span class="line">11月 16 14:11:34 node06 kubelet[5505]: E1116 14:11:34.324703    5505 nestedpendingoperations.go:267] Operation for &quot;\&quot;kubernetes.io/nfs/9c7bb592-e883-11e8-aae0-0050568a2af3-pvc-9c75962b-e883-11e8-aae0-0050568a2af3\&quot; (\&quot;9c7bb592-e883-11e8-aae0-0050568a2af3\&quot;)&quot; failed. No retries permitted until 2018-11-16 14:13:36.324623633 +0800 CST m=+15413.721922139 (durationBeforeRetry 2m2s). Error: &quot;error cleaning subPath mounts for volume \&quot;pvc-9c75962b-e883-11e8-aae0-0050568a2af3\&quot; (UniqueName: \&quot;kubernetes.io/nfs/9c7bb592-e883-11e8-aae0-0050568a2af3-pvc-9c75962b-e883-11e8-aae0-0050568a2af3\&quot;) pod \&quot;9c7bb592-e883-11e8-aae0-0050568a2af3\&quot; (UID: \&quot;9c7bb592-e883-11e8-aae0-0050568a2af3\&quot;) : error reading /var/lib/kubelet/pods/9c7bb592-e883-11e8-aae0-0050568a2af3/volume-subpaths/pvc-9c75962b-e883-11e8-aae0-0050568a2af3/orderer1: lstat /var/lib/kubelet/pods/9c7bb592-e883-11e8-aae0-0050568a2af3/volume-subpaths/pvc-9c75962b-e883-11e8-aae0-0050568a2af3/orderer1/0: stale NFS file handle&quot;</span><br><span class="line">11月 16 14:11:34 node06 kubelet[5505]: E1116 14:11:34.324809    5505 nestedpendingoperations.go:267] Operation for &quot;\&quot;kubernetes.io/nfs/b46aa346-e71d-11e8-b49a-0050568a2af3-pvc-5f5024f7-e6ed-11e8-989d-0050568a2af3\&quot; (\&quot;b46aa346-e71d-11e8-b49a-0050568a2af3\&quot;)&quot; failed. No retries permitted until 2018-11-16 14:13:36.324727477 +0800 CST m=+15413.722025987 (durationBeforeRetry 2m2s). Error: &quot;error cleaning subPath mounts for volume \&quot;pvc-5f5024f7-e6ed-11e8-989d-0050568a2af3\&quot; (UniqueName: \&quot;kubernetes.io/nfs/b46aa346-e71d-11e8-b49a-0050568a2af3-pvc-5f5024f7-e6ed-11e8-989d-0050568a2af3\&quot;) pod \&quot;b46aa346-e71d-11e8-b49a-0050568a2af3\&quot; (UID: \&quot;b46aa346-e71d-11e8-b49a-0050568a2af3\&quot;) : error reading /var/lib/kubelet/pods/b46aa346-e71d-11e8-b49a-0050568a2af3/volume-subpaths/pvc-5f5024f7-e6ed-11e8-989d-0050568a2af3/orderer1: lstat /var/lib/kubelet/pods/b46aa346-e71d-11e8-b49a-0050568a2af3/volume-subpaths/pvc-5f5024f7-e6ed-11e8-989d-0050568a2af3/orderer1/0: stale NFS file handle&quot;</span><br><span class="line">11月 16 14:11:34 node06 kubelet[5505]: E1116 14:11:34.325743    5505 nestedpendingoperations.go:267] Operation for &quot;\&quot;kubernetes.io/nfs/9b2a49c7-e726-11e8-a7a5-0050568a2af3-pvc-9b07268f-e726-11e8-a7a5-0050568a2af3\&quot; (\&quot;9b2a49c7-e726-11e8-a7a5-0050568a2af3\&quot;)&quot; failed. No retries permitted until 2018-11-16 14:13:36.325669009 +0800 CST m=+15413.722967535 (durationBeforeRetry 2m2s). Error: &quot;error cleaning subPath mounts for volume \&quot;pvc-9b07268f-e726-11e8-a7a5-0050568a2af3\&quot; (UniqueName: \&quot;kubernetes.io/nfs/9b2a49c7-e726-11e8-a7a5-0050568a2af3-pvc-9b07268f-e726-11e8-a7a5-0050568a2af3\&quot;) pod \&quot;9b2a49c7-e726-11e8-a7a5-0050568a2af3\&quot; (UID: \&quot;9b2a49c7-e726-11e8-a7a5-0050568a2af3\&quot;) : error reading /var/lib/kubelet/pods/9b2a49c7-e726-11e8-a7a5-0050568a2af3/volume-subpaths/pvc-9b07268f-e726-11e8-a7a5-0050568a2af3/cli: lstat /var/lib/kubelet/pods/9b2a49c7-e726-11e8-a7a5-0050568a2af3/volume-subpaths/pvc-9b07268f-e726-11e8-a7a5-0050568a2af3/cli/1: stale NFS file handle&quot;</span><br><span class="line">11月 16 14:11:34 node06 kubelet[5505]: E1116 14:11:34.325843    5505 nestedpendingoperations.go:267] Operation for &quot;\&quot;kubernetes.io/nfs/dc5262e0-e710-11e8-989d-0050568a2af3-pvc-66a1068f-e22d-11e8-a331-0050568a2af3\&quot; (\&quot;dc5262e0-e710-11e8-989d-0050568a2af3\&quot;)&quot; failed. No retries permitted until 2018-11-16 14:13:36.325772394 +0800 CST m=+15413.723070969 (durationBeforeRetry 2m2s). Error: &quot;error cleaning subPath mounts for volume \&quot;pvc-66a1068f-e22d-11e8-a331-0050568a2af3\&quot; (UniqueName: \&quot;kubernetes.io/nfs/dc5262e0-e710-11e8-989d-0050568a2af3-pvc-66a1068f-e22d-11e8-a331-0050568a2af3\&quot;) pod \&quot;dc5262e0-e710-11e8-989d-0050568a2af3\&quot; (UID: \&quot;dc5262e0-e710-11e8-989d-0050568a2af3\&quot;) : error reading /var/lib/kubelet/pods/dc5262e0-e710-11e8-989d-0050568a2af3/volume-subpaths/pvc-66a1068f-e22d-11e8-a331-0050568a2af3/org1-1000: lstat /var/lib/kubelet/pods/dc5262e0-e710-11e8-989d-0050568a2af3/volume-subpaths/pvc-66a1068f-e22d-11e8-a331-0050568a2af3/org1-1000/1: stale NFS file handle&quot;</span><br><span class="line">。。。。。。</span><br></pre></td></tr></table></figure></p>
<h1 id="二、问题定位"><a href="#二、问题定位" class="headerlink" title="二、问题定位"></a>二、问题定位</h1><p>起初看到这段日志有点不知所云，Google了一下，看社区描述，有人说是Kuberentes的一个bug。尽管查阅到的资料如此显示，我还始终有个想法一致在脑海中游荡。那便是资源对象本身而言，有一种潜在的依赖关系存在。这种潜在的依赖关系可以简单描述为：对于某种具体的容器应用而言，某个deployment创建的pod是依赖于某个persistentvolumeclaim的。如果我删除这个容器应用，要是先把那个persistentvolumeclaim删除干净了，再去删除那个依赖它的deployment，Kuberentes回收资源就可能会发生上述问题，毕竟依赖的资源已经不存在了。后来经过一段时间的排查和定位，问题的本质原因正是如此。<br>因此该问题的本质原因可以用一句话简单概括：Kuberentes底层在真正做某个资源对象的删除操作时，发现该资源对象依赖另一个资源对象，需要解除二者的绑定关系，但是很可惜它依赖的那个资源对象已经先它一步被删除了，绑定关系解除还可能要做资源回收操作，资源不存在了，回收操作一直无法成功，目标资源对象也就一直无法成功删除。</p>
<p>为了便于理解我所述的这种依赖关系，给出相应的YAML，假设nginx的终止比较耗时，删除时如果不控制顺序，就可以模拟出相同的情况：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx</span><br><span class="line">  namespace: default</span><br><span class="line">  labels:</span><br><span class="line">    app: nginx</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: nginx</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: nginx</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">        image: nginx:1.15.3</span><br><span class="line">        imagePullPolicy: IfNotPresent</span><br><span class="line">        name: nginx</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 80</span><br><span class="line">          protocol: TCP</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - mountPath: /data/</span><br><span class="line">          name: data</span><br><span class="line">      restartPolicy: Always</span><br><span class="line">      volumes:</span><br><span class="line">      - name: data</span><br><span class="line">        persistentVolumeClaim:</span><br><span class="line">          claimName: nginx-pvc</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: PersistentVolumeClaim</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx-pvc</span><br><span class="line">  namespace: default</span><br><span class="line">spec:</span><br><span class="line">  accessModes:</span><br><span class="line">  - ReadWriteMany</span><br><span class="line">  resources:</span><br><span class="line">    requests:</span><br><span class="line">      storage: 1G</span><br><span class="line">  storageClassName: managed-nfs-storage</span><br></pre></td></tr></table></figure></p>
<h1 id="三、总结"><a href="#三、总结" class="headerlink" title="三、总结"></a>三、总结</h1><ol>
<li>以第二点中的YAML为例，就是说删除时，一定要先删除deployment，然后监测该deployment和其对应的pod副本都删除干净后，再去删除persistentvolumeclaim。否则一同提交给Kubernetes，如果该deployment和其对应的pod副本终止比较耗时，persistentvolumeclaim就会优先于deployment先完成删除，那么该问题就出现了。</li>
<li>对于deployment和job两种资源对象，检测其自身的删除状态应该就可以，实测发现自身删除了，对应的pod副本也就删除干净了；但是对于statefulset这种资源对象就不行，一定要检测对应pod副本的删除状态，实测自身删除了，对应的pod副本并没有删除干净，还要等待一会儿，才能删除干净。因此必须单独检测pod副本的删除状态，这点在写程序时，一定要格外注意。</li>
</ol>
<h1 id="四、代码示例：删除资源对象（Deployment）的同时，监测其删除情况"><a href="#四、代码示例：删除资源对象（Deployment）的同时，监测其删除情况" class="headerlink" title="四、代码示例：删除资源对象（Deployment）的同时，监测其删除情况"></a>四、代码示例：删除资源对象（Deployment）的同时，监测其删除情况</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line">type Metadata struct &#123;</span><br><span class="line">	Kind      string `json:&quot;kind&quot;`</span><br><span class="line">	Name      string `json:&quot;name&quot;`</span><br><span class="line">	Namespace string `json:&quot;namespace&quot;`</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">metadataDepList := make([]module.Metadata, 0)</span><br><span class="line"></span><br><span class="line">for i := 0; i &lt; len(metadataList); i++ &#123;</span><br><span class="line">	metadata := metadataList[i]</span><br><span class="line">	glog.Info(&quot;metadata: &quot;, metadata)</span><br><span class="line">	if metadata.Kind == ResourceKindDeployment &#123;</span><br><span class="line">		metadataDepList = append(metadataDepList, metadata)</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">for i := 0; i &lt; len(metadataDepList); i++ &#123;</span><br><span class="line">	metadataDep := metadataDepList[i]</span><br><span class="line">	dep, err := clientset.AppsV1beta1().Deployments(metadataDep.Namespace).Get(metadataDep.Name, v1.GetOptions&#123;&#125;)</span><br><span class="line">	if err != nil &#123;</span><br><span class="line">		return err</span><br><span class="line">	&#125;</span><br><span class="line">	labels := dep.Labels</span><br><span class="line"></span><br><span class="line">	sign := make(chan error, 1)</span><br><span class="line">	go func() &#123;</span><br><span class="line">		selector := pkglabels.FormatLabels(labels)</span><br><span class="line">		opts := v1.ListOptions&#123;</span><br><span class="line">			LabelSelector: selector,</span><br><span class="line">		&#125;</span><br><span class="line">		depWatch, err := clientset.AppsV1beta1().Deployments(metadataDep.Namespace).Watch(opts)</span><br><span class="line">		if err != nil &#123;</span><br><span class="line">			sign &lt;- err</span><br><span class="line">			return</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		deleteDepLoop:</span><br><span class="line">		for &#123;</span><br><span class="line">			select &#123;</span><br><span class="line">			case data := &lt;-depWatch.ResultChan():</span><br><span class="line">				glog.Infof(&quot;Deleted deployment.Name: %s. deployment.Namespace: %s. data.Type: %s&quot;, dep.Name, dep.Namespace, data.Type)</span><br><span class="line">				sign &lt;- nil</span><br><span class="line">				if data.Type == watch.Deleted &#123;</span><br><span class="line">					glog.Infof(&quot;Deleted deployment.Name: %s. deployment.Namespace: %s.&quot;, dep.Name, dep.Namespace)</span><br><span class="line">					break deleteDepLoop</span><br><span class="line">				&#125;</span><br><span class="line">			case &lt;-time.After(time.Duration(30) * time.Second):</span><br><span class="line">				sign &lt;- errors.New(&quot;delete deployment timeout. &quot;)</span><br><span class="line">				depWatch.Stop()</span><br><span class="line">				return</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;()</span><br><span class="line">	err = &lt;- sign</span><br><span class="line">	if err != nil &#123;</span><br><span class="line">		return err</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	err = clientset.AppsV1beta1().Deployments(metadataDep.Namespace).Delete(metadataDep.Name, &amp;v1.DeleteOptions&#123;</span><br><span class="line">		PropagationPolicy: &amp;deletePropagationBackground,</span><br><span class="line">	&#125;)</span><br><span class="line">	if err != nil &#123;</span><br><span class="line">		return err</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Docker/">Docker</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Kubernetes/">Kubernetes</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Trouble-Shooting/">Trouble Shooting</a></li></ul>
	</div>

      
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/容器云技术/">容器云技术</a>
	</div>


      
      <div class="clearfix"></div>
    </div>
      
    
  </div>
  
</article>







  
    <article id="post-docker_trouble_shooting_000" class="article article-type-post" itemscope="" itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2018/11/16/docker_trouble_shooting_000/" class="article-date">
  	<time datetime="2018-11-16T06:00:55.199Z" itemprop="datePublished">2018-11-16</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/11/16/docker_trouble_shooting_000/">
        删除Docker容器或者重启Docker Daemon时，遇到device or resource busy，该怎么办？
        
      </a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>前段时间，在内部的线上环境修复Kubernetes集群时，需要重启Docker Daemon，可以悲剧发生了，一重启就报错：device or resource busy。Google了好久，终于找到了类似的案例和解决方法。此时才知道，原来删除Docker容器，也可能会出现这个问题。这里简单记录一下，原创详见“参考资料”。</p>
<p>原文给出的脚本：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line"></span><br><span class="line">for i in $(curl -s --unix /var/run/docker.sock http://localhost/info | jq -r .DockerRootDir) /var/lib/docker /run /var/run; do</span><br><span class="line">    for m in $(tac /proc/mounts | awk &apos;&#123;print $2&#125;&apos; | grep ^$&#123;i&#125;/); do</span><br><span class="line">        umount $m || true</span><br><span class="line">    done</span><br><span class="line">done</span><br></pre></td></tr></table></figure></p>
<p>在我们内部的环境中，DockerRootDir是固定的，就在/var/lib/docker，为了避免安装jq依赖，调整为下面的脚本：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line"></span><br><span class="line">for i in /var/lib/docker /run /var/run; do</span><br><span class="line">    for m in $(tac /proc/mounts | awk &apos;&#123;print $2&#125;&apos; | grep ^$&#123;i&#125;/); do</span><br><span class="line">        umount $m || true</span><br><span class="line">    done</span><br><span class="line">done</span><br></pre></td></tr></table></figure></p>
<p>参考资料：<br><a href="http://niusmallnan.com/2016/12/27/docker-device-resource-busy/" target="_blank" rel="noopener">http://niusmallnan.com/2016/12/27/docker-device-resource-busy/</a></p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Docker/">Docker</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Trouble-Shooting/">Trouble Shooting</a></li></ul>
	</div>

      
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/容器云技术/">容器云技术</a>
	</div>


      
      <div class="clearfix"></div>
    </div>
      
    
  </div>
  
</article>







  
    <article id="post-manual_clean_logging" class="article article-type-post" itemscope="" itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2018/11/14/manual_clean_logging/" class="article-date">
  	<time datetime="2018-11-14T10:01:30.172Z" itemprop="datePublished">2018-11-14</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/11/14/manual_clean_logging/">
        手动清理Docker容器产生的日志
        
      </a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>实际工作中，发现有些同事会有裸跑Docker容器的用法，最主要的是用json-file的日志驱动，还不配置日志轮转清理，具体原因不详。应用产生的日志量也不小，一段时间后，有趣的事情发生了：Docker莫名其妙不好使了，一查原因日志报盘了。上网找了一下资料，找到了比较好用的手动快速清理日志的方法，这里记录一下，供日后查阅使用。原创地址详见“参考资料”。</p>
<h2 id="1-在Docker默认配置下，利用下面的命令查看各个容器的日志文件大小；"><a href="#1-在Docker默认配置下，利用下面的命令查看各个容器的日志文件大小；" class="headerlink" title="1. 在Docker默认配置下，利用下面的命令查看各个容器的日志文件大小；"></a>1. 在Docker默认配置下，利用下面的命令查看各个容器的日志文件大小；</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ls -lh $(find /var/lib/docker/containers/ -name *-json.log)</span><br></pre></td></tr></table></figure>
<h2 id="2-利用下面的脚本，可以手动清理宿主机上Docker容器产生的日志。"><a href="#2-利用下面的脚本，可以手动清理宿主机上Docker容器产生的日志。" class="headerlink" title="2. 利用下面的脚本，可以手动清理宿主机上Docker容器产生的日志。"></a>2. 利用下面的脚本，可以手动清理宿主机上Docker容器产生的日志。</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/sh</span><br><span class="line">echo &quot;==================== start clean docker containers logs ==========================&quot;</span><br><span class="line"> </span><br><span class="line">logs=$(find /var/lib/docker/containers/ -name *-json.log)</span><br><span class="line"> </span><br><span class="line">for log in $logs</span><br><span class="line">        do</span><br><span class="line">                echo &quot;clean logs : $log&quot;</span><br><span class="line">                cat /dev/null &gt; $log</span><br><span class="line">        done</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">echo &quot;==================== end clean docker containers logs   ==========================&quot;</span><br></pre></td></tr></table></figure>
<p>参考资料：<br><a href="https://blog.csdn.net/xunzhaoyao/article/details/72959917" target="_blank" rel="noopener">https://blog.csdn.net/xunzhaoyao/article/details/72959917</a></p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Docker/">Docker</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Logging/">Logging</a></li></ul>
	</div>

      
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/容器云技术/">容器云技术</a>
	</div>


      
      <div class="clearfix"></div>
    </div>
      
    
  </div>
  
</article>







  
    <article id="post-verify_network" class="article article-type-post" itemscope="" itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2018/11/14/verify_network/" class="article-date">
  	<time datetime="2018-11-14T06:19:59.861Z" itemprop="datePublished">2018-11-14</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/11/14/verify_network/">
        Kubernetes集群中验证集群网络
        
      </a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>在Kubernetes集群中验证网络是否好用，一般从以下几个方面入手：<br>1.相同主机上的不同Pod之间的网络连通性；<br>2.不同主机上的不同Pod之间的网络连通性；<br>3.不同主机上的Pod中能否解析Kubernetes集群中的DNS记录。</p>
<p>为了顺利完成上述验证，需要准备一个验证环境。下面先介绍一下，如何构建这样一个网络验证环境，然后再介绍如何验证网络。</p>
<h1 id="一、构建集群网络验证环境"><a href="#一、构建集群网络验证环境" class="headerlink" title="一、构建集群网络验证环境"></a>一、构建集群网络验证环境</h1><h2 id="1-构建网络验证环境基础镜像"><a href="#1-构建网络验证环境基础镜像" class="headerlink" title="1. 构建网络验证环境基础镜像"></a>1. 构建网络验证环境基础镜像</h2><h3 id="Alpine-3-8-Dockerfile-Example"><a href="#Alpine-3-8-Dockerfile-Example" class="headerlink" title="Alpine 3.8 Dockerfile Example"></a>Alpine 3.8 Dockerfile Example</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">FROM alpine:3.8</span><br><span class="line"></span><br><span class="line">MAINTAINER wangxin_0611@126.com</span><br><span class="line"></span><br><span class="line">RUN apk add --no-cache ca-certificates bind-tools iputils iproute2 net-tools tcpdump</span><br></pre></td></tr></table></figure>
<h3 id="Ubuntu-16-04-Dockerfile-Example"><a href="#Ubuntu-16-04-Dockerfile-Example" class="headerlink" title="Ubuntu 16.04 Dockerfile Example"></a>Ubuntu 16.04 Dockerfile Example</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">FROM ubuntu:16.04</span><br><span class="line"></span><br><span class="line">MAINTAINER wangxin_0611@126.com</span><br><span class="line"></span><br><span class="line">RUN apt-get update &amp;&amp; \</span><br><span class="line">    apt-get install -y iproute2 &amp;&amp; \</span><br><span class="line">    apt-get install -y dnsutils &amp;&amp; \</span><br><span class="line">    apt-get install -y net-tools &amp;&amp; \</span><br><span class="line">    apt-get install -y iputils-ping &amp;&amp; \</span><br><span class="line">    apt-get install -y tcpdump</span><br></pre></td></tr></table></figure>
<h3 id="CentOS-7-5-1804-Dockerfile-Example"><a href="#CentOS-7-5-1804-Dockerfile-Example" class="headerlink" title="CentOS 7.5.1804 Dockerfile Example"></a>CentOS 7.5.1804 Dockerfile Example</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">FROM centos:7.5.1804</span><br><span class="line"></span><br><span class="line">MAINTAINER wangxin_0611@126.com</span><br><span class="line"></span><br><span class="line">RUN yum makecache fast &amp;&amp; \</span><br><span class="line">    yum install -y iproute &amp;&amp; \</span><br><span class="line">    yum install -y bind-utils &amp;&amp; \</span><br><span class="line">    yum install -y net-tools &amp;&amp; \</span><br><span class="line">    yum install -y iputils &amp;&amp; \</span><br><span class="line">    yum install -y tcpdump</span><br></pre></td></tr></table></figure>
<h2 id="2-利用基础镜像在各个宿主机上部署一个Pod，对于该种情况，利用DaemonSet实现最为合适。"><a href="#2-利用基础镜像在各个宿主机上部署一个Pod，对于该种情况，利用DaemonSet实现最为合适。" class="headerlink" title="2. 利用基础镜像在各个宿主机上部署一个Pod，对于该种情况，利用DaemonSet实现最为合适。"></a>2. 利用基础镜像在各个宿主机上部署一个Pod，对于该种情况，利用DaemonSet实现最为合适。</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: DaemonSet</span><br><span class="line">metadata:</span><br><span class="line">  name: network</span><br><span class="line">  namespace: default</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: network</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: network</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: network</span><br><span class="line">        image: 10.0.55.126/base/alpine:3.8-network</span><br><span class="line">        imagePullPolicy: IfNotPresent</span><br><span class="line">        command:</span><br><span class="line">        - sleep</span><br><span class="line">        - &quot;3600&quot;</span><br><span class="line">      restartPolicy: Always</span><br><span class="line">      tolerations:</span><br><span class="line">      - effect: NoSchedule</span><br><span class="line">        operator: Exists</span><br></pre></td></tr></table></figure>
<p>创建后，查看DaemonSet和其对应的Pod信息如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[root@master alpine]# kubectl get daemonsets</span><br><span class="line">NAME             DESIRED   CURRENT   READY     UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE</span><br><span class="line">network          9         9         9         9            9           &lt;none&gt;          1m</span><br><span class="line">[root@master alpine]# kubectl get pods -o wide</span><br><span class="line">NAME                   READY     STATUS    RESTARTS   AGE       IP              NODE</span><br><span class="line">network-76xzk          1/1       Running   0          1m        10.211.3.42     node03</span><br><span class="line">network-79dzf          1/1       Running   0          1m        10.211.2.195    node02</span><br><span class="line">network-ftn7g          1/1       Running   0          1m        10.211.4.25     node04</span><br><span class="line">network-jbr8g          1/1       Running   0          1m        10.211.13.187   node07</span><br><span class="line">network-kflgv          1/1       Running   0          1m        10.211.0.153    master</span><br><span class="line">network-mvqlx          1/1       Running   0          1m        10.211.14.97    node08</span><br><span class="line">network-nbzsc          1/1       Running   0          1m        10.211.12.94    node06</span><br><span class="line">network-rxc2f          1/1       Running   0          1m        10.211.6.5      node05</span><br><span class="line">network-w89xg          1/1       Running   0          1m        10.211.1.240    node01</span><br></pre></td></tr></table></figure></p>
<h1 id="二、验证集群网络"><a href="#二、验证集群网络" class="headerlink" title="二、验证集群网络"></a>二、验证集群网络</h1><h2 id="1-进入master上对应的Pod后，ping各个Node上对应的Pod的IP地址，以此验证连通性；"><a href="#1-进入master上对应的Pod后，ping各个Node上对应的Pod的IP地址，以此验证连通性；" class="headerlink" title="1. 进入master上对应的Pod后，ping各个Node上对应的Pod的IP地址，以此验证连通性；"></a>1. 进入master上对应的Pod后，ping各个Node上对应的Pod的IP地址，以此验证连通性；</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">[root@master alpine]# kubectl exec -it network-kflgv /bin/sh</span><br><span class="line">/ # ping -c 4 10.211.1.240</span><br><span class="line">PING 10.211.1.240 (10.211.1.240) 56(84) bytes of data.</span><br><span class="line">64 bytes from 10.211.1.240: icmp_seq=1 ttl=62 time=0.575 ms</span><br><span class="line">64 bytes from 10.211.1.240: icmp_seq=2 ttl=62 time=0.374 ms</span><br><span class="line">64 bytes from 10.211.1.240: icmp_seq=3 ttl=62 time=0.445 ms</span><br><span class="line">64 bytes from 10.211.1.240: icmp_seq=4 ttl=62 time=0.380 ms</span><br><span class="line"></span><br><span class="line">--- 10.211.1.240 ping statistics ---</span><br><span class="line">4 packets transmitted, 4 received, 0% packet loss, time 3103ms</span><br><span class="line">rtt min/avg/max/mdev = 0.374/0.443/0.575/0.083 ms</span><br><span class="line">/ # ping -c 4 10.211.2.195</span><br><span class="line">PING 10.211.2.195 (10.211.2.195) 56(84) bytes of data.</span><br><span class="line">64 bytes from 10.211.2.195: icmp_seq=1 ttl=62 time=0.390 ms</span><br><span class="line">64 bytes from 10.211.2.195: icmp_seq=2 ttl=62 time=0.544 ms</span><br><span class="line">64 bytes from 10.211.2.195: icmp_seq=3 ttl=62 time=0.460 ms</span><br><span class="line">64 bytes from 10.211.2.195: icmp_seq=4 ttl=62 time=0.483 ms</span><br><span class="line"></span><br><span class="line">--- 10.211.2.195 ping statistics ---</span><br><span class="line">4 packets transmitted, 4 received, 0% packet loss, time 3064ms</span><br><span class="line">rtt min/avg/max/mdev = 0.390/0.469/0.544/0.057 ms</span><br><span class="line">/ # ping -c 4 10.211.3.42</span><br><span class="line">PING 10.211.3.42 (10.211.3.42) 56(84) bytes of data.</span><br><span class="line">64 bytes from 10.211.3.42: icmp_seq=1 ttl=62 time=0.598 ms</span><br><span class="line">64 bytes from 10.211.3.42: icmp_seq=2 ttl=62 time=0.463 ms</span><br><span class="line">64 bytes from 10.211.3.42: icmp_seq=3 ttl=62 time=0.530 ms</span><br><span class="line">64 bytes from 10.211.3.42: icmp_seq=4 ttl=62 time=0.426 ms</span><br><span class="line"></span><br><span class="line">以此类推 。。。。。。</span><br></pre></td></tr></table></figure>
<h2 id="2-验证各个Pod中能否解析Kubernetes集群中的DNS记录。"><a href="#2-验证各个Pod中能否解析Kubernetes集群中的DNS记录。" class="headerlink" title="2. 验证各个Pod中能否解析Kubernetes集群中的DNS记录。"></a>2. 验证各个Pod中能否解析Kubernetes集群中的DNS记录。</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">[root@master alpine]# kubectl exec -it network-kflgv /bin/sh</span><br><span class="line">/ # nslookup kubernetes.default</span><br><span class="line">Server:		10.96.0.10</span><br><span class="line">Address:	10.96.0.10#53</span><br><span class="line"></span><br><span class="line">Name:	kubernetes.default.svc.cluster.local</span><br><span class="line">Address: 10.96.0.1</span><br><span class="line"></span><br><span class="line">[root@master alpine]# kubectl exec -it network-w89xg /bin/sh</span><br><span class="line">/ # nslookup kubernetes.default</span><br><span class="line">Server:		10.96.0.10</span><br><span class="line">Address:	10.96.0.10#53</span><br><span class="line"></span><br><span class="line">Name:	kubernetes.default.svc.cluster.local</span><br><span class="line">Address: 10.96.0.1</span><br><span class="line"></span><br><span class="line">[root@master alpine]# kubectl exec -it network-79dzf /bin/sh</span><br><span class="line">/ # nslookup kubernetes.default</span><br><span class="line">Server:		10.96.0.10</span><br><span class="line">Address:	10.96.0.10#53</span><br><span class="line"></span><br><span class="line">Name:	kubernetes.default.svc.cluster.local</span><br><span class="line">Address: 10.96.0.1</span><br><span class="line"></span><br><span class="line">[root@master alpine]# kubectl exec -it network-76xzk /bin/sh</span><br><span class="line">/ # nslookup kubernetes.default</span><br><span class="line">Server:		10.96.0.10</span><br><span class="line">Address:	10.96.0.10#53</span><br><span class="line"></span><br><span class="line">Name:	kubernetes.default.svc.cluster.local</span><br><span class="line">Address: 10.96.0.1</span><br><span class="line"></span><br><span class="line">以此类推 。。。。。。</span><br></pre></td></tr></table></figure>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Docker/">Docker</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Kubernetes/">Kubernetes</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Network/">Network</a></li></ul>
	</div>

      
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/容器云技术/">容器云技术</a>
	</div>


      
      <div class="clearfix"></div>
    </div>
      
    
  </div>
  
</article>







  
    <article id="post-timezone" class="article article-type-post" itemscope="" itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2018/11/12/timezone/" class="article-date">
  	<time datetime="2018-11-12T04:48:47.232Z" itemprop="datePublished">2018-11-12</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/11/12/timezone/">
        Docker容器的时区设置
        
      </a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Docker容器的时区设置，一直以来都是个简单而且重要的问题。下面笔者以CentOS 7.5.1804作为容器宿主机为例，分别介绍如何在原生Docker容器和Kubernetes的Pod中正确设置时区。</p>
<h1 id="Node设置正确时区（以CentOS-7-5-1804-为例）"><a href="#Node设置正确时区（以CentOS-7-5-1804-为例）" class="headerlink" title="Node设置正确时区（以CentOS 7.5.1804 为例）"></a>Node设置正确时区（以CentOS 7.5.1804 为例）</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">timedatectl list-timezones</span><br><span class="line">timedatectl set-timezone Asia/Shanghai</span><br><span class="line">timedatectl status | grep &apos;Time zone&apos;</span><br></pre></td></tr></table></figure>
<p>提示：这里相当于为Docker Container和Kubernetes Pod的宿主机设置正确的时区，需要优先配置完成。</p>
<h1 id="Docker-Container-与-Node同步时区设置"><a href="#Docker-Container-与-Node同步时区设置" class="headerlink" title="Docker Container 与 Node同步时区设置"></a>Docker Container 与 Node同步时区设置</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -it -v /etc/localtime:/etc/localtime --rm alpine:3.8 /bin/sh</span><br></pre></td></tr></table></figure>
<p>提示：上述命令注意-v参数的部分。<br>总结：经测试验证，alpine:3.8、centos:7.5.1804和ubuntu:16.04处理方式相同。</p>
<h1 id="Kubernetes-Pod-与-Node同步时区设置"><a href="#Kubernetes-Pod-与-Node同步时区设置" class="headerlink" title="Kubernetes Pod 与 Node同步时区设置"></a>Kubernetes Pod 与 Node同步时区设置</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: alpine</span><br><span class="line">  labels:</span><br><span class="line">    app: alpine</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - image: alpine:3.8</span><br><span class="line">    imagePullPolicy: IfNotPresent</span><br><span class="line">    name: alpine</span><br><span class="line">    command:</span><br><span class="line">      - sleep</span><br><span class="line">      - &quot;3600&quot;</span><br><span class="line">    volumeMounts:</span><br><span class="line">     - name: tz-config</span><br><span class="line">       mountPath: /etc/localtime</span><br><span class="line">       readOnly: true</span><br><span class="line">  restartPolicy: Always</span><br><span class="line">  volumes:</span><br><span class="line">    - name: tz-config</span><br><span class="line">      hostPath:</span><br><span class="line">        path: /etc/localtime</span><br></pre></td></tr></table></figure>
<p>提示：上述YAML注意volumes和volumeMounts部分。<br>总结：经测试验证，alpine:3.8、centos:7.5.1804和ubuntu:16.04处理方式相同。</p>
<h1 id="Docker-Container-和-Kubernetes-Pod-通用-与-Node同步时区设置"><a href="#Docker-Container-和-Kubernetes-Pod-通用-与-Node同步时区设置" class="headerlink" title="Docker Container 和 Kubernetes Pod 通用 与 Node同步时区设置"></a>Docker Container 和 Kubernetes Pod 通用 与 Node同步时区设置</h1><p>该方式在需要构建Docker Image的时候，即修改Docker Image的默认时区设置。</p>
<h2 id="Alpine-Linux-3-8-Dockerfile-Example"><a href="#Alpine-Linux-3-8-Dockerfile-Example" class="headerlink" title="Alpine Linux 3.8 Dockerfile Example"></a>Alpine Linux 3.8 Dockerfile Example</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">FROM alpine:3.8</span><br><span class="line"></span><br><span class="line">MAINTAINER wangxin_0611@126.com</span><br><span class="line"></span><br><span class="line">RUN apk --no-cache add tzdata  &amp;&amp; \</span><br><span class="line">    ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime</span><br></pre></td></tr></table></figure>
<h2 id="Ubuntu-Linux-16-04-Dockerfile-Example"><a href="#Ubuntu-Linux-16-04-Dockerfile-Example" class="headerlink" title="Ubuntu Linux 16.04 Dockerfile Example"></a>Ubuntu Linux 16.04 Dockerfile Example</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">FROM ubuntu:16.04</span><br><span class="line"></span><br><span class="line">MAINTAINER wangxin_0611@126.com</span><br><span class="line"></span><br><span class="line">RUN apt-get update &amp;&amp; \</span><br><span class="line">    apt-get install -y tzdata &amp;&amp; \</span><br><span class="line">    ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime</span><br></pre></td></tr></table></figure>
<h2 id="CenOS-Linux-7-5-1804-Dockerfile-Example"><a href="#CenOS-Linux-7-5-1804-Dockerfile-Example" class="headerlink" title="CenOS Linux 7.5.1804 Dockerfile Example"></a>CenOS Linux 7.5.1804 Dockerfile Example</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">FROM centos:7.5.1804</span><br><span class="line"></span><br><span class="line">MAINTAINER wangxin_0611@126.com</span><br><span class="line"></span><br><span class="line">RUN ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime</span><br></pre></td></tr></table></figure>
<p>参考资料：<br><a href="https://blog.csdn.net/qq_34924407/article/details/82057080" target="_blank" rel="noopener">https://blog.csdn.net/qq_34924407/article/details/82057080</a><br><a href="https://blog.csdn.net/u013201439/article/details/79436413" target="_blank" rel="noopener">https://blog.csdn.net/u013201439/article/details/79436413</a></p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Docker/">Docker</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Kubernetes/">Kubernetes</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Logging/">Logging</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/TimeZone/">TimeZone</a></li></ul>
	</div>

      
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/容器云技术/">容器云技术</a>
	</div>


      
      <div class="clearfix"></div>
    </div>
      
    
  </div>
  
</article>







  
  
    <nav id="page-nav">
      <a class="extend prev" rel="prev" href="/">&laquo; Prev</a><a class="page-number" href="/">1</a><span class="page-number current">2</span>
    </nav>
  
</div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
      <div class="footer-left">
        &copy; 2019 Singh Wang
      </div>
        <div class="footer-right">
          <a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="https://github.com/smackgg/hexo-theme-smackdown" target="_blank">Smackdown</a>
        </div>
    </div>
  </div>
</footer>
    </div>
    
  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">


<script>
	var yiliaConfig = {
		fancybox: true,
		mathjax: true,
		animate: true,
		isHome: true,
		isPost: false,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: false
	}
</script>
<script src="/js/main.js"></script>



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js"></script>


  </div>
</body>
</html>